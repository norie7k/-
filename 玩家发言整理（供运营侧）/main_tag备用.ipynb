{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a270f7e-1cbc-488e-b78b-d113cf2b2146",
   "metadata": {},
   "source": [
    "## æ•°æ®å¤„ç†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9bcb45d8-1ccc-4600-b1fb-9e30f9b83c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "from typing import List, Union, Optional\n",
    "from datetime import datetime\n",
    "\n",
    "import os, re, json, time\n",
    "import typing as T\n",
    "import requests\n",
    "from pathlib import Path\n",
    "from openpyxl import Workbook, load_workbook\n",
    "\n",
    "from openpyxl.utils import get_column_letter\n",
    "from openpyxl.utils import get_column_letter\n",
    "from openpyxl.styles import Font, Alignment, Border, Side, PatternFill\n",
    "from data_processing import load_and_process,build_jsonl_for_range, save_jsonl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f289cc4f-5fbb-4e00-bf55-1bd0fe391231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2779 lines\n",
      "{\"å‘è¨€æ—¥æœŸ\": \"2025-10-23\", \"å‘è¨€æ—¶é—´\": \"00:00:00\", \"ç©å®¶ID\": \"UKING(3155443546)\", \"ç©å®¶æ¶ˆæ¯\": \"æ‰€ä»¥èƒ½é€‰äºŒçº§å°±äºŒçº§æ˜¯å—ï¼Ÿ\"}\n"
     ]
    }
   ],
   "source": [
    "## ç ”å‘å­—å…¸\n",
    "speaker_map = {\n",
    "    \"16186514\":   \"ç ”å‘peteræœ¬å°Š\",\n",
    "    \"1655611808\": \"è¿è¥ç»¾ç»¾\",\n",
    "    \"2073820674\": \"æ²™åˆ©æ–‡è€å¸ˆ\",\n",
    "}\n",
    "## å®¢æœå­—å…¸\n",
    "MAPPING_FILE = \"mappingåœ°çƒ1.xlsx\"\n",
    "\n",
    "##QQçš„txtæ–‡ä»¶\n",
    "pathtxt      = \"1114ã€Šæ¬¢è¿æ¥åˆ°åœ°çƒã€‹æµ‹è¯•1ç¾¤.txt\"\n",
    "\n",
    "# è®¾å®šæ—¶é—´èŒƒå›´\n",
    "start_time = \"2025-10-23 00:00:00\"\n",
    "end_time   = \"2025-10-24 00:00:00\"\n",
    "\n",
    "# 1) æ‹¿åˆ° JSONLï¼ˆåˆ—è¡¨ï¼‰\n",
    "jsonl_lines01 = build_jsonl_for_range(\n",
    "    pathtxt=pathtxt,\n",
    "    mapping_file=MAPPING_FILE,\n",
    "    speaker_map=speaker_map,\n",
    "    start_time=start_time,\n",
    "    end_time=end_time,\n",
    "    return_str=False,   # è¿”å› list[str]\n",
    ")\n",
    "\n",
    "print(len(jsonl_lines01), \"lines\")\n",
    "print(jsonl_lines01[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840c1e89-cc08-4532-bc6b-1842742fce13",
   "metadata": {},
   "source": [
    "## å¤§æ¨¡å‹åˆ†ç±»"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d8e640-2974-47ea-a008-6c08e71b46bd",
   "metadata": {},
   "source": [
    "## å®šä¹‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e952a6ae-48c3-49f3-9b91-d867f416c4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "æ‰¹å¤„ç† 10000 æ¡èŠå¤©æ•°æ®ï¼ˆæ¯æ‰¹ 100 æ¡ï¼‰ï¼š\n",
    "- æ¨¡å‹#1ï¼šè¿‡æ»¤éæ¸¸æˆç›¸å…³ï¼ˆåªä¿ç•™ç›¸å…³ JSON è¡Œï¼ŒåŸæ ·è¾“å‡ºï¼‰\n",
    "- æ¨¡å‹#2ï¼šæå–é«˜è®¨è®ºçš„å‘è¨€å¹¶åˆ†æ\n",
    "- ç»“æœæŒ‰wordæ ¼å¼æ–‡æ¡£è¾“å‡º\n",
    "\"\"\"\n",
    "from model_classifyV1_Copy1_Copy1 import (\n",
    "    load_system_prompt,\n",
    "    build_user_prompt_filter,build_user_prompt_discuss,build_user_prompt_emotion,\n",
    "    build_ingame_special,build_outgame_special,\n",
    "    call_ark_chat_completions,  \n",
    "    create_word_report_all, append_hot_grouped,append_emotion_grouped,insert_paragraph_after,\n",
    "    append_ingame_special,append_outgame_special\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b7b9c0-b495-4640-b7d1-2c31ef371d3d",
   "metadata": {},
   "source": [
    "## è®¾ç½®å‚æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "70d36c9f-a439-4597-b52a-ca091439031b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============= ä½ çš„æ¨¡å‹ä¸æ–‡ä»¶é…ç½®ï¼ˆæ”¹è¿™é‡Œï¼‰ =============\n",
    "API_URL   = \"https://ark.cn-beijing.volces.com/api/v3/chat/completions\" \n",
    "API_KEY = \"de91deb0-aae6-46cb-bac0-17ac3b6107f5\" #API\n",
    "V3_MODEL_ID= \"ep-20251020160142-5d7hp\"#æ¥å…¥ç‚¹\n",
    "V3_1_MODEL_ID = \"ep-20251020160025-9p5tj\"#æ¥å…¥ç‚¹\n",
    "R1_MODEL_ID = \"ep-20251020160103-5n6g2\"#æ¥å…¥ç‚¹\n",
    "\n",
    "PROMPT_MD_PATH01 = Path(\"æç¤ºè¯1.md\")      # æ¨¡å‹#1 system æç¤ºè¯ï¼ˆç­›ç›¸å…³ï¼‰\n",
    "PROMPT_MD_PATH02 = Path(\"1çƒ­åº¦è®¨è®º.md\")      # æ¨¡å‹#2 system æç¤ºè¯ï¼ˆçƒ­åº¦äº‹ä»¶åˆ†æï¼‰\n",
    "PROMPT_MD_PATH03 = Path(\"2æƒ…ç»ªæ³¢åŠ¨.md\")      # æ¨¡å‹#3 system æç¤ºè¯ï¼ˆæƒ…ç»ªé«˜æ¶¨äº‹ä»¶åˆ†æï¼‰\n",
    "PROMPT_MD_PATH04 = Path(\"3å…¬å…±äº‹ä»¶_æ¸¸æˆç›¸å…³.md\")      # æ¨¡å‹#4 system æç¤ºè¯ï¼ˆæ¸¸æˆå†…ç‰¹æ®Šäº‹ä»¶åˆ†æï¼‰\n",
    "PROMPT_MD_PATH05 = Path(\"4å…¬å…±äº‹ä»¶_éæ¸¸æˆ.md\")      # æ¨¡å‹#5 system æç¤ºè¯ï¼ˆæ¸¸æˆå¤–ç‰¹æ®Šäº‹ä»¶åˆ†æï¼‰\n",
    "WORD_FILE       = Path(\"äº‹ä»¶åˆ†æ10232.docx\")   # è¾“å‡º Excel\n",
    "BATCH_SIZE       = 250\n",
    "SLEEP_BETWEEN    = 1   # æ¯æ‰¹ä¹‹é—´çš„é—´éš”ï¼Œé˜²æ­¢QPSè§¦å‘é™æµï¼›æŒ‰éœ€è°ƒæ•´\n",
    "RETRIES          = 2\n",
    "TEMPERATURE      = 0.20\n",
    "MAX_TOKENS       = 16384\n",
    "TIMEOUT_SEC      = 600\n",
    "# ====================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e99015f-028b-4df0-b3f0-228f671cacfa",
   "metadata": {},
   "source": [
    "## å¼€å§‹è¿è¡Œ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d24a57-f3a0-4db2-a403-3c113742ff50",
   "metadata": {},
   "source": [
    "# ç‰¹æ®Šäº‹ä»¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca48c387-5942-4d70-bc1e-15d3c6572979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å‡†å¤‡å¤„ç† 376 æ¡ï¼Œå…± 2 æ‰¹ã€‚\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ”¥ æ‰¹å¤„ç†è¿›åº¦:   0%|                                                                                                                                     | 0/2 [00:00<?, ?æ‰¹/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "ğŸ® æ‰¹æ¬¡ 1 â€”â€” æ¸¸æˆç›¸å…³ç‰¹æ®Šäº‹ä»¶\n",
      "==============================\n",
      "[\n",
      "  {\n",
      "    \"äº‹ä»¶åç§°\": \"è¢«è¿«å®³å¦„æƒ³æŠ€èƒ½ç¬¬ä¸€å›åˆæœªç”Ÿæ•ˆBUG\",\n",
      "    \"äº‹ä»¶æ‘˜è¦\": \"å¤šåç©å®¶åé¦ˆå¤§è´è¶æ®–è£…çš„è¢«è¿«å®³å¦„æƒ³æŠ€èƒ½æè¿°ä¸ºç¬¬ä¸€å›åˆé‡Šæ”¾ä½†å®é™…æœªç”Ÿæ•ˆï¼Œå®¢æœç¡®è®¤å¹¶åé¦ˆé—®é¢˜\",\n",
      "    \"ç©å®¶å…±è¯†\": \"ç©å®¶æ™®éè®¤ä¸ºè¿™æ˜¯æŠ€èƒ½æè¿°ä¸å®é™…æ•ˆæœä¸ç¬¦çš„å¼‚å¸¸æƒ…å†µï¼Œéœ€è¦ä¿®å¤\",\n",
      "    \"äº‹ä»¶å½±å“\": \"ç©å®¶æŠ€èƒ½ç­–ç•¥å¤±æ•ˆï¼Œéœ€è¦é‡æ–°è°ƒæ•´æˆ˜æ–—éƒ¨ç½²ï¼Œå®¢æœä»‹å…¥æ”¶é›†ä¿¡æ¯è¿›è¡Œä¿®å¤\",\n",
      "    \"è®¨è®ºçƒ­åº¦ï¼ˆé‡åŒ–ï¼‰\": \"å‘è¨€ç©å®¶æ€»æ•°ï¼š3 ä½ï¼Œå‘è¨€æ€»é‡ï¼š5 æ¡\"\n",
      "  },\n",
      "  {\n",
      "    \"äº‹ä»¶åç§°\": \"è¿œå¤BUGå¯¼è‡´æ¸¸æˆå¼€å±€é»‘å±å¡æ­»\",\n",
      "    \"äº‹ä»¶æ‘˜è¦\": \"ç©å®¶åé¦ˆå¼€å±€é­é‡é»‘å±å¡æ­»é—®é¢˜ï¼Œé‡å¯æ— æ•ˆï¼Œå®¢æœå»ºè®®é‡å¯ä½†é—®é¢˜æœªè§£å†³\",\n",
      "    \"ç©å®¶å…±è¯†\": \"ç©å®¶è®¤ä¸ºè¿™æ˜¯å·²çŸ¥çš„è¿œå¤BUGï¼Œå½±å“æ¸¸æˆæ­£å¸¸è¿›è¡Œï¼Œéœ€è¦ç´§æ€¥ä¿®å¤\",\n",
      "    \"äº‹ä»¶å½±å“\": \"ç©å®¶æ— æ³•æ­£å¸¸è¿›è¡Œæ¸¸æˆï¼Œéƒ¨åˆ†ç©å®¶é€‰æ‹©æš‚åœæ¸¸ç©ç­‰å¾…æ›´æ–°ä¿®å¤\",\n",
      "    \"è®¨è®ºçƒ­åº¦ï¼ˆé‡åŒ–ï¼‰\": \"å‘è¨€ç©å®¶æ€»æ•°ï¼š2 ä½ï¼Œå‘è¨€æ€»é‡ï¼š4 æ¡\"\n",
      "  }\n",
      "]\n",
      "\n",
      "==============================\n",
      "ğŸŒ æ‰¹æ¬¡ 1 â€”â€” éæ¸¸æˆç›¸å…³ç‰¹æ®Šäº‹ä»¶\n",
      "==============================\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ”¥ æ‰¹å¤„ç†è¿›åº¦:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                              | 1/2 [05:15<05:15, 315.68s/æ‰¹]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "ğŸ® æ‰¹æ¬¡ 2 â€”â€” æ¸¸æˆç›¸å…³ç‰¹æ®Šäº‹ä»¶\n",
      "==============================\n",
      "[]\n",
      "\n",
      "==============================\n",
      "ğŸŒ æ‰¹æ¬¡ 2 â€”â€” éæ¸¸æˆç›¸å…³ç‰¹æ®Šäº‹ä»¶\n",
      "==============================\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ”¥ æ‰¹å¤„ç†è¿›åº¦: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [08:02<00:00, 241.46s/æ‰¹]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# ===== åŠ è½½æç¤ºè¯ =====\n",
    "system_prompt01 = load_system_prompt(PROMPT_MD_PATH01)               # ç­›ç›¸å…³\n",
    "system_prompt04 = load_system_prompt(PROMPT_MD_PATH04)      # æ¸¸æˆç›¸å…³ç‰¹æ®Šäº‹ä»¶\n",
    "system_prompt05 = load_system_prompt(PROMPT_MD_PATH05)      # éæ¸¸æˆç›¸å…³äº‹ä»¶\n",
    "\n",
    "total = len(jsonl_lines01)\n",
    "total_batches = (total + BATCH_SIZE - 1) // BATCH_SIZE\n",
    "print(f\"å‡†å¤‡å¤„ç† {total} æ¡ï¼Œå…± {total_batches} æ‰¹ã€‚\")\n",
    "\n",
    "for b in tqdm(range(total_batches), desc=\"ğŸ”¥ æ‰¹å¤„ç†è¿›åº¦\", unit=\"æ‰¹\"):\n",
    "\n",
    "    # === å–æœ¬æ‰¹ JSONLinesï¼ˆè¿˜æ˜¯ list[str]ï¼‰ ===\n",
    "    start = b * BATCH_SIZE\n",
    "    end = min(start + BATCH_SIZE, total)\n",
    "    batch_lines = jsonl_lines01[start:end]\n",
    "\n",
    "    # è½¬æˆ JSONL æ–‡æœ¬å—\n",
    "    batch_jsonl = \"\\n\".join(batch_lines)\n",
    "\n",
    "    # ==========================================================\n",
    "    # ğŸŸ¦ æ™ºèƒ½ä½“ #1ï¼šç­›ç›¸å…³ â†’ output_filterï¼ˆä»ç„¶æ˜¯ä¸€ä¸ª JSONL æ–‡æœ¬å—ï¼‰\n",
    "    # ==========================================================\n",
    "    user_prompt1 = build_user_prompt_filter(batch_lines)\n",
    "\n",
    "    output_filter = call_ark_chat_completions(\n",
    "        api_url=API_URL,\n",
    "        api_key=API_KEY,\n",
    "        model=V3_MODEL_ID,\n",
    "        system_prompt=system_prompt01,\n",
    "        user_prompt=user_prompt1,\n",
    "        temperature=TEMPERATURE,\n",
    "        max_tokens=MAX_TOKENS,\n",
    "        timeout=TIMEOUT_SEC,\n",
    "    )\n",
    "\n",
    "    if not output_filter:\n",
    "        print(f\"[æ‰¹æ¬¡ {b+1}] âŒ ç­›ç›¸å…³æ— ç»“æœ\")\n",
    "        continue\n",
    "\n",
    "    # ==========================================================\n",
    "    # ğŸŸ§ è®¡ç®—éç›¸å…³äº‹ä»¶è¾“å…¥ï¼ˆä¿æŒ JSON æ ¼å¼ï¼‰\n",
    "    # ==========================================================\n",
    "\n",
    "    # å°† output_filter ä¹ŸæŒ‰è¡Œåˆ‡å¼€ï¼Œä½†ä¿æŒ JSON æ–‡æœ¬\n",
    "    filtered_lines = output_filter.split(\"\\n\")\n",
    "    # åˆ æ‰ç©ºè¡Œ\n",
    "    filtered_lines = [l for l in filtered_lines if l.strip()]\n",
    "    # ç”¨å­—ç¬¦ä¸²å·®é›†æ‰¾åˆ°â€œéæ¸¸æˆç›¸å…³â€æ–‡æœ¬\n",
    "    # ï¼ˆæ³¨æ„ï¼šä¿æŒ JSON æ ¼å¼ï¼Œä¸ç ´åç»“æ„ï¼‰\n",
    "    non_related_lines = [l for l in batch_lines if l not in filtered_lines]\n",
    "    non_related_jsonl = \"\\n\".join(non_related_lines)\n",
    "\n",
    "    # ==========================================================\n",
    "    # ğŸŸ¥ æ™ºèƒ½ä½“ #2ï¼šæ¸¸æˆç›¸å…³ç‰¹æ®Šäº‹ä»¶ï¼ˆè¾“å…¥ = output_filterï¼‰\n",
    "    # ==========================================================\n",
    "    user_prompt4 = build_ingame_special(output_filter)\n",
    "\n",
    "    output_ingame_special = call_ark_chat_completions(\n",
    "        api_url=API_URL,\n",
    "        api_key=API_KEY,\n",
    "        model=V3_1_MODEL_ID,\n",
    "        system_prompt=system_prompt04,\n",
    "        user_prompt=user_prompt4,\n",
    "        temperature=TEMPERATURE,\n",
    "        max_tokens=MAX_TOKENS,\n",
    "        timeout=TIMEOUT_SEC,\n",
    "    )\n",
    "\n",
    "    print(\"\\n==============================\")\n",
    "    print(f\"ğŸ® æ‰¹æ¬¡ {b+1} â€”â€” æ¸¸æˆç›¸å…³ç‰¹æ®Šäº‹ä»¶\")\n",
    "    print(\"==============================\")\n",
    "    print(output_ingame_special)\n",
    "\n",
    "    # ==========================================================\n",
    "    # ğŸŸ© æ™ºèƒ½ä½“ #3ï¼šéæ¸¸æˆç›¸å…³ç‰¹æ®Šäº‹ä»¶ï¼ˆè¾“å…¥ = non_related_jsonlï¼‰\n",
    "    # ==========================================================\n",
    "    if non_related_jsonl.strip():\n",
    "        user_prompt5= build_outgame_special(non_related_jsonl)\n",
    "\n",
    "        output_outgame_special = call_ark_chat_completions(\n",
    "            api_url=API_URL,\n",
    "            api_key=API_KEY,\n",
    "            model=V3_1_MODEL_ID,\n",
    "            system_prompt=system_prompt05,\n",
    "            user_prompt=user_prompt5,\n",
    "            temperature=TEMPERATURE,\n",
    "            max_tokens=MAX_TOKENS,\n",
    "            timeout=TIMEOUT_SEC,\n",
    "        )\n",
    "\n",
    "        print(\"\\n==============================\")\n",
    "        print(f\"ğŸŒ æ‰¹æ¬¡ {b+1} â€”â€” éæ¸¸æˆç›¸å…³ç‰¹æ®Šäº‹ä»¶\")\n",
    "        print(\"==============================\")\n",
    "        print(output_outgame_special)\n",
    "\n",
    "    else:\n",
    "        print(f\"\\nğŸŒ æ‰¹æ¬¡ {b+1} â€”â€” æ²¡æœ‰éæ¸¸æˆç›¸å…³å†…å®¹\")\n",
    "\n",
    "    time.sleep(SLEEP_BETWEEN)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e908989-1a6b-41c1-b3d1-45b507839ddb",
   "metadata": {},
   "source": [
    "# æ¨¡å‹äºŒ æƒ…ç»ªé«˜ç‚¹äº‹ä»¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5106efd-2a1f-4306-a3f2-afe555a02e51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å‡†å¤‡å¤„ç† 376 æ¡ï¼Œå…± 2 æ‰¹ï¼ˆæ¯æ‰¹ 250 æ¡ï¼‰ã€‚\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ”¥ æ‰¹å¤„ç†è¿›åº¦:   0%|                                                                                                                                     | 0/2 [00:00<?, ?æ‰¹/s]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# ... å‰ç½®ï¼šç³»ç»Ÿæç¤ºã€create_intent_excel_styled(EXCEL_FILE)ã€jsonl_lines01 ç­‰\n",
    "\n",
    "system_prompt01 = load_system_prompt(PROMPT_MD_PATH01)  # ç­›ç›¸å…³\n",
    "system_prompt02 = load_system_prompt(PROMPT_MD_PATH02)  # çƒ­åº¦äº‹ä»¶åˆ†æ\n",
    "system_prompt03 = load_system_prompt(PROMPT_MD_PATH03)  # æƒ…ç»ªé«˜ç‚¹åˆ†æ\n",
    "\n",
    "\n",
    "total = len(jsonl_lines01)\n",
    "if total == 0:\n",
    "    print(\"æ²¡æœ‰å¯å¤„ç†çš„æ•°æ®ã€‚\")\n",
    "else:\n",
    "    total_batches = (total + BATCH_SIZE - 1) // BATCH_SIZE\n",
    "    print(f\"å‡†å¤‡å¤„ç† {total} æ¡ï¼Œå…± {total_batches} æ‰¹ï¼ˆæ¯æ‰¹ {BATCH_SIZE} æ¡ï¼‰ã€‚\")\n",
    "\n",
    "\n",
    "for b in tqdm(range(total_batches), desc=\"ğŸ”¥ æ‰¹å¤„ç†è¿›åº¦\", unit=\"æ‰¹\"):\n",
    "    start = b * BATCH_SIZE\n",
    "    end = min(start + BATCH_SIZE, total)\n",
    "    batch_lines = jsonl_lines01[start:end]\n",
    "\n",
    "    # --- æ¨¡å‹ #1ï¼šç­›ç›¸å…³ ---\n",
    "    user_prompt1 = build_user_prompt_filter(batch_lines)\n",
    "    output_filter = call_ark_chat_completions(\n",
    "        api_url=API_URL,\n",
    "        api_key=API_KEY,\n",
    "        model=V3_MODEL_ID,\n",
    "        system_prompt=system_prompt01,\n",
    "        user_prompt=user_prompt1,\n",
    "        temperature=TEMPERATURE,\n",
    "        max_tokens=MAX_TOKENS,\n",
    "        timeout=TIMEOUT_SEC,\n",
    "        retries=RETRIES,\n",
    "    )\n",
    "\n",
    "    if not output_filter:\n",
    "        tqdm.write(f\"[æ‰¹æ¬¡ {b+1}] æ¨¡å‹#1 æ— æœ‰æ•ˆè¾“å‡ºï¼Œè·³è¿‡ã€‚\")\n",
    "        continue\n",
    "\n",
    "    # --- æ¨¡å‹ #3ï¼šæƒ…ç»ªé«˜ç‚¹åˆ†æ ---\n",
    "    user_prompt3 = build_user_prompt_emotion(output_filter)\n",
    "    output_emotion = call_ark_chat_completions(\n",
    "        api_url=API_URL,\n",
    "        api_key=API_KEY,\n",
    "        model=V3_MODEL_ID,\n",
    "        system_prompt=system_prompt03,\n",
    "        user_prompt=user_prompt3,\n",
    "        temperature=TEMPERATURE,\n",
    "        max_tokens=MAX_TOKENS,\n",
    "        timeout=TIMEOUT_SEC,\n",
    "        retries=RETRIES,\n",
    "    )\n",
    "\n",
    "    # â­â­â­ æ‰“å°è¾“å‡º â­â­â­\n",
    "    print(\"\\n=========================\")\n",
    "    print(f\"ğŸ”¥ æ‰¹æ¬¡ {b+1} æ¨¡å‹ #3ï¼ˆæƒ…ç»ªé«˜ç‚¹åˆ†æï¼‰è¾“å‡º\")\n",
    "    print(\"=========================\\n\")\n",
    "    print(output_emotion)\n",
    "\n",
    "    # é˜²æ­¢ API é™æµ\n",
    "    time.sleep(SLEEP_BETWEEN)\n",
    "\n",
    "print(\"\\nâœ… å…¨éƒ¨æ‰¹æ¬¡å¤„ç†å®Œæˆï¼\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74474fb7-31b6-487d-8276-5dcf057a0079",
   "metadata": {},
   "source": [
    "# æœ€ç»ˆä¸»å¾ªç¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5fecc1e6-0d96-49d7-a90a-270ff1c17cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å‡†å¤‡å¤„ç† 376 æ¡ï¼Œå…± 2 æ‰¹ã€‚\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ”¥ æ‰¹å¤„ç†è¿›åº¦: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [09:15<00:00, 277.94s/æ‰¹]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ‰ å…¨éƒ¨æ‰¹æ¬¡å¤„ç†å®Œæˆï¼\n",
      "ğŸ“„ Word æ–‡ä»¶å·²ç”Ÿæˆï¼šäº‹ä»¶åˆ†æ.docx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "system_prompt01 = load_system_prompt(PROMPT_MD_PATH01)  # ç­›ç›¸å…³\n",
    "system_prompt02 = load_system_prompt(PROMPT_MD_PATH02)  # çƒ­åº¦äº‹ä»¶åˆ†æ\n",
    "system_prompt03 = load_system_prompt(PROMPT_MD_PATH03)  # æƒ…ç»ªé«˜ç‚¹åˆ†æ\n",
    "\n",
    "create_word_report_grouped(WORD_FILE)  # åªåˆ›å»ºä¸€æ¬¡\n",
    "\n",
    "total = len(jsonl_lines01)\n",
    "if total == 0:\n",
    "    print(\"æ²¡æœ‰å¯å¤„ç†çš„æ•°æ®ã€‚\")\n",
    "else:\n",
    "    total_batches = (total + BATCH_SIZE - 1) // BATCH_SIZE\n",
    "    print(f\"å‡†å¤‡å¤„ç† {total} æ¡ï¼Œå…± {total_batches} æ‰¹ã€‚\")\n",
    "\n",
    "for b in tqdm(range(total_batches), desc=\"ğŸ”¥ æ‰¹å¤„ç†è¿›åº¦\", unit=\"æ‰¹\"):\n",
    "    \n",
    "    # === å–æœ¬æ‰¹æ•°æ® ===\n",
    "    start = b * BATCH_SIZE\n",
    "    end = min(start + BATCH_SIZE, total)\n",
    "    batch_lines = jsonl_lines01[start:end]\n",
    "\n",
    "    # === æ¨¡å‹ #1ï¼šç­›ç›¸å…³ ===\n",
    "    output_filter = call_ark_chat_completions(\n",
    "        api_url=API_URL,\n",
    "        api_key=API_KEY,\n",
    "        model=V3_MODEL_ID,\n",
    "        system_prompt=system_prompt01,\n",
    "        user_prompt=build_user_prompt_filter(batch_lines),\n",
    "        temperature=TEMPERATURE,\n",
    "        max_tokens=MAX_TOKENS,\n",
    "        timeout=TIMEOUT_SEC,\n",
    "        retries=RETRIES,\n",
    "    )\n",
    "\n",
    "    if not output_filter:\n",
    "        tqdm.write(f\"[æ‰¹æ¬¡ {b+1}] æ¨¡å‹ #1 æ— è¾“å‡ºï¼Œè·³è¿‡ã€‚\")\n",
    "        continue\n",
    "\n",
    "    # === æ¨¡å‹ #2ï¼šçƒ­åº¦åˆ†æ ===\n",
    "    user_prompt2 = build_user_prompt_discuss(output_filter)\n",
    "    output_discussion = call_ark_chat_completions(\n",
    "        api_url=API_URL,\n",
    "        api_key=API_KEY,\n",
    "        model=V3_1_MODEL_ID,\n",
    "        system_prompt=system_prompt02,\n",
    "        user_prompt=user_prompt2,\n",
    "        temperature=TEMPERATURE,\n",
    "        max_tokens=MAX_TOKENS,\n",
    "        timeout=TIMEOUT_SEC,\n",
    "        retries=RETRIES,\n",
    "    )\n",
    "\n",
    "    # === æ¨¡å‹ #3ï¼šæƒ…ç»ªé«˜ç‚¹åˆ†æ ===\n",
    "    user_prompt3 = build_user_prompt_emotion(output_filter)\n",
    "    output_emotion = call_ark_chat_completions(\n",
    "        api_url=API_URL,\n",
    "        api_key=API_KEY,\n",
    "        model=V3_MODEL_ID,\n",
    "        system_prompt=system_prompt03,\n",
    "        user_prompt=user_prompt3,\n",
    "        temperature=TEMPERATURE,\n",
    "        max_tokens=MAX_TOKENS,\n",
    "        timeout=TIMEOUT_SEC,\n",
    "        retries=RETRIES,\n",
    "    )\n",
    "\n",
    "    # === å†™å…¥ Wordï¼ˆæŒ‰ä½ çš„æ ¼å¼ï¼‰ ===\n",
    "    append_hot_grouped(WORD_FILE, output_discussion)\n",
    "    append_emotion_grouped(WORD_FILE, output_emotion)\n",
    "\n",
    "    time.sleep(SLEEP_BETWEEN)\n",
    "\n",
    "\n",
    "print(\"\\nğŸ‰ å…¨éƒ¨æ‰¹æ¬¡å¤„ç†å®Œæˆï¼\")\n",
    "print(f\"ğŸ“„ Word æ–‡ä»¶å·²ç”Ÿæˆï¼š{WORD_FILE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf2c1ca-4179-41e7-ae2c-8f995f2a8b50",
   "metadata": {},
   "source": [
    "# æœ€ç»ˆä¸»å¾ªç¯ï¼ˆçƒ­åº¦+æƒ…ç»ªé«˜ç‚¹+æ¸¸æˆå†…å¤–ç‰¹æ®Šäº‹ä»¶ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "89a28da1-3959-49be-9b7b-9c5c181fa1ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å‡†å¤‡å¤„ç† 2779 æ¡ï¼Œå…± 12 æ‰¹ã€‚\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ”¥ æ‰¹å¤„ç†è¿›åº¦: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [1:12:13<00:00, 361.15s/æ‰¹]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ‰ å…¨éƒ¨æ‰¹æ¬¡å¤„ç†å®Œæˆï¼\n",
      "ğŸ“„ Word æ–‡ä»¶å·²ç”Ÿæˆï¼šäº‹ä»¶åˆ†æ10232.docx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "system_prompt01 = load_system_prompt(PROMPT_MD_PATH01)  # ç­›ç›¸å…³\n",
    "system_prompt02 = load_system_prompt(PROMPT_MD_PATH02)  # çƒ­åº¦äº‹ä»¶åˆ†æ\n",
    "system_prompt03 = load_system_prompt(PROMPT_MD_PATH03)  # æƒ…ç»ªé«˜ç‚¹åˆ†æ\n",
    "system_prompt04 = load_system_prompt(PROMPT_MD_PATH04)  # æ¸¸æˆå†…ç‰¹æ®Šäº‹ä»¶\n",
    "system_prompt05 = load_system_prompt(PROMPT_MD_PATH05)  # æ¸¸æˆå¤–ç‰¹æ®Šäº‹ä»¶\n",
    "\n",
    "create_word_report_all(WORD_FILE)  # åªåˆ›å»ºä¸€æ¬¡\n",
    "\n",
    "total = len(jsonl_lines01)\n",
    "if total == 0:\n",
    "    print(\"æ²¡æœ‰å¯å¤„ç†çš„æ•°æ®ã€‚\")\n",
    "else:\n",
    "    total_batches = (total + BATCH_SIZE - 1) // BATCH_SIZE\n",
    "    print(f\"å‡†å¤‡å¤„ç† {total} æ¡ï¼Œå…± {total_batches} æ‰¹ã€‚\")\n",
    "\n",
    "for b in tqdm(range(total_batches), desc=\"ğŸ”¥ æ‰¹å¤„ç†è¿›åº¦\", unit=\"æ‰¹\"):\n",
    "    \n",
    "    # === æ¯æ‰¹å¼€å§‹æ—¶é‡ç½®è¿™ä¸ªå˜é‡ï¼Œé¿å…æ²¿ç”¨ä¸Šä¸€æ¬¡çš„å€¼ \n",
    "    output_outgame_special = None\n",
    "\n",
    "    # === å–æœ¬æ‰¹æ•°æ® ===\n",
    "    start = b * BATCH_SIZE\n",
    "    end = min(start + BATCH_SIZE, total)\n",
    "    batch_lines = jsonl_lines01[start:end]\n",
    "\n",
    "    # === æ¨¡å‹ #1ï¼šç­›ç›¸å…³ ===\n",
    "    output_filter = call_ark_chat_completions(\n",
    "        api_url=API_URL,\n",
    "        api_key=API_KEY,\n",
    "        model=V3_MODEL_ID,\n",
    "        system_prompt=system_prompt01,\n",
    "        user_prompt=build_user_prompt_filter(batch_lines),\n",
    "        temperature=TEMPERATURE,\n",
    "        max_tokens=MAX_TOKENS,\n",
    "        timeout=TIMEOUT_SEC,\n",
    "        retries=RETRIES,\n",
    "    )\n",
    "\n",
    "    if not output_filter:\n",
    "        tqdm.write(f\"[æ‰¹æ¬¡ {b+1}] æ¨¡å‹ #1 æ— è¾“å‡ºï¼Œè·³è¿‡ã€‚\")\n",
    "        continue\n",
    "\n",
    "    # === æ¨¡å‹ #2ï¼šçƒ­åº¦åˆ†æ ===\n",
    "    user_prompt2 = build_user_prompt_discuss(output_filter)\n",
    "    output_discussion = call_ark_chat_completions(\n",
    "        api_url=API_URL,\n",
    "        api_key=API_KEY,\n",
    "        model=V3_1_MODEL_ID,\n",
    "        system_prompt=system_prompt02,\n",
    "        user_prompt=user_prompt2,\n",
    "        temperature=TEMPERATURE,\n",
    "        max_tokens=MAX_TOKENS,\n",
    "        timeout=TIMEOUT_SEC,\n",
    "        retries=RETRIES,\n",
    "    )\n",
    "   \n",
    "\n",
    "    # === æ¨¡å‹ #3ï¼šæƒ…ç»ªé«˜ç‚¹åˆ†æ ===\n",
    "    user_prompt3 = build_user_prompt_emotion(output_filter)\n",
    "    output_emotion = call_ark_chat_completions(\n",
    "        api_url=API_URL,\n",
    "        api_key=API_KEY,\n",
    "        model=V3_MODEL_ID,\n",
    "        system_prompt=system_prompt03,\n",
    "        user_prompt=user_prompt3,\n",
    "        temperature=TEMPERATURE,\n",
    "        max_tokens=MAX_TOKENS,\n",
    "        timeout=TIMEOUT_SEC,\n",
    "        retries=RETRIES,\n",
    "    )\n",
    "    \n",
    "    # === ä»£ç ï¼šéæ¸¸æˆç›¸å…³å‘è¨€æå– ===\n",
    "    # å°† output_filter ä¹ŸæŒ‰è¡Œåˆ‡å¼€ï¼Œä½†ä¿æŒ JSON æ–‡æœ¬\n",
    "    filtered_lines = output_filter.split(\"\\n\")\n",
    "    # åˆ æ‰ç©ºè¡Œ\n",
    "    filtered_lines = [l for l in filtered_lines if l.strip()]\n",
    "    # ç”¨å­—ç¬¦ä¸²å·®é›†æ‰¾åˆ°â€œéæ¸¸æˆç›¸å…³â€æ–‡æœ¬\n",
    "    # ï¼ˆæ³¨æ„ï¼šä¿æŒ JSON æ ¼å¼ï¼Œä¸ç ´åç»“æ„ï¼‰\n",
    "    non_related_lines = [l for l in batch_lines if l not in filtered_lines]\n",
    "    non_related_jsonl = \"\\n\".join(non_related_lines)\n",
    "    \n",
    "    # === æ¨¡å‹ #4ï¼šæ¸¸æˆå†…ç‰¹æ®Šäº‹ä»¶åˆ†æ ===\n",
    "    user_prompt4 = build_ingame_special(output_filter)\n",
    "    output_ingame_special = call_ark_chat_completions(\n",
    "        api_url=API_URL,\n",
    "        api_key=API_KEY,\n",
    "        model=V3_MODEL_ID,\n",
    "        system_prompt=system_prompt04,\n",
    "        user_prompt=user_prompt4,\n",
    "        temperature=TEMPERATURE,\n",
    "        max_tokens=MAX_TOKENS,\n",
    "        timeout=TIMEOUT_SEC,\n",
    "    )\n",
    "    # === æ¨¡å‹ #5ï¼šæ¸¸æˆå¤–ç‰¹æ®Šäº‹ä»¶åˆ†æ ===\n",
    "    if non_related_jsonl.strip():\n",
    "        user_prompt5= build_outgame_special(non_related_jsonl)\n",
    "        output_outgame_special = call_ark_chat_completions(\n",
    "            api_url=API_URL,\n",
    "            api_key=API_KEY,\n",
    "            model=V3_1_MODEL_ID,\n",
    "            system_prompt=system_prompt05,\n",
    "            user_prompt=user_prompt5,\n",
    "            temperature=TEMPERATURE,\n",
    "            max_tokens=MAX_TOKENS,\n",
    "            timeout=TIMEOUT_SEC,\n",
    "        )\n",
    "    # === å†™å…¥ Wordï¼ˆæŒ‰ä½ çš„æ ¼å¼ï¼‰ ===\n",
    "    if output_discussion:\n",
    "        append_hot_grouped(WORD_FILE, output_discussion)\n",
    "\n",
    "    if output_emotion:\n",
    "        append_emotion_grouped(WORD_FILE, output_emotion)\n",
    "\n",
    "    if output_ingame_special:\n",
    "        append_ingame_special(WORD_FILE, output_ingame_special)\n",
    "\n",
    "    if output_outgame_special:\n",
    "        append_outgame_special(WORD_FILE, output_outgame_special)\n",
    "\n",
    "        \n",
    "    time.sleep(SLEEP_BETWEEN)\n",
    "\n",
    "\n",
    "print(\"\\nğŸ‰ å…¨éƒ¨æ‰¹æ¬¡å¤„ç†å®Œæˆï¼\")\n",
    "print(f\"ğŸ“„ Word æ–‡ä»¶å·²ç”Ÿæˆï¼š{WORD_FILE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d5cb95-f65c-4e48-8a87-e315632540bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
