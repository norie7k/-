{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a270f7e-1cbc-488e-b78b-d113cf2b2146",
   "metadata": {},
   "source": [
    "## æ•°æ®å¤„ç†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bcb45d8-1ccc-4600-b1fb-9e30f9b83c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "from typing import List, Union, Optional\n",
    "from datetime import datetime\n",
    "\n",
    "import os, re, json, time\n",
    "import typing as T\n",
    "import requests\n",
    "\n",
    "from pathlib import Path\n",
    "from openpyxl import Workbook, load_workbook\n",
    "\n",
    "from openpyxl.utils import get_column_letter\n",
    "from openpyxl.utils import get_column_letter\n",
    "from openpyxl.styles import Font, Alignment, Border, Side, PatternFill\n",
    "from data_processing import load_and_process,build_jsonl_for_range, save_jsonl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f289cc4f-5fbb-4e00-bf55-1bd0fe391231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1201 lines\n",
      "{\"å‘è¨€æ—¥æœŸ\": \"2025-12-07\", \"å‘è¨€æ—¶é—´\": \"00:09:54\", \"ç©å®¶ID\": \"â€œå¾å‡¤å¹´â€(2780439644)\", \"ç©å®¶æ¶ˆæ¯\": \"å¼€è½¦\"}\n"
     ]
    }
   ],
   "source": [
    "## ç ”å‘å­—å…¸\n",
    "speaker_map = {\n",
    "    \"16186514\":   \"peteræœ¬å°Š\",\n",
    "    \"1655611808\": \"è¿è¥ç»¾ç»¾\",\n",
    "    \"2073820674\": \"æ²™åˆ©æ–‡è€å¸ˆ\",\n",
    "    \"2726067525\": \"milissa\",\n",
    "}\n",
    "## å®¢æœå­—å…¸\n",
    "MAPPING_FILE = \"mappingåœ°çƒ1.xlsx\"\n",
    "\n",
    "##QQçš„txtæ–‡ä»¶\n",
    "pathtxt   = \"1209ã€Šæ¬¢è¿æ¥åˆ°åœ°çƒã€‹æµ‹è¯•2ç¾¤.txt\"\n",
    "\n",
    "# è®¾å®šæ—¶é—´èŒƒå›´\n",
    "start_time = \"2025-12-07 00:00:00\"\n",
    "end_time   = \"2025-12-08 00:00:00\"\n",
    "\n",
    "\n",
    "# 1) æ‹¿åˆ° JSONLï¼ˆåˆ—è¡¨ï¼‰\n",
    "jsonl_lines01 = build_jsonl_for_range(\n",
    "    pathtxt=pathtxt,\n",
    "    mapping_file=MAPPING_FILE,\n",
    "    speaker_map=speaker_map,\n",
    "    start_time=start_time,\n",
    "    end_time=end_time,\n",
    "    return_str=False,   # è¿”å› list[str]\n",
    ")\n",
    "\n",
    "print(len(jsonl_lines01), \"lines\")\n",
    "print(jsonl_lines01[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840c1e89-cc08-4532-bc6b-1842742fce13",
   "metadata": {},
   "source": [
    "## å¤§æ¨¡å‹åˆ†ç±»"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d8e640-2974-47ea-a008-6c08e71b46bd",
   "metadata": {},
   "source": [
    "## å®šä¹‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e952a6ae-48c3-49f3-9b91-d867f416c4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "æ‰¹å¤„ç† 10000 æ¡èŠå¤©æ•°æ®ï¼ˆæ¯æ‰¹ 100 æ¡ï¼‰ï¼š\n",
    "- æ¨¡å‹#1ï¼šè¿‡æ»¤éæ¸¸æˆç›¸å…³ï¼ˆåªä¿ç•™ç›¸å…³ JSON è¡Œï¼ŒåŸæ ·è¾“å‡ºï¼‰\n",
    "- æ¨¡å‹#2ï¼šæå–é«˜è®¨è®ºçš„å‘è¨€å¹¶åˆ†æ\n",
    "- ç»“æœæŒ‰wordæ ¼å¼æ–‡æ¡£è¾“å‡º\n",
    "\"\"\"\n",
    "from model_classifyV1_Copy1_Copy1 import (\n",
    "    load_system_prompt,\n",
    "    build_user_prompt_filter,build_user_prompt_clsuter,call_ark_chat_completions,\n",
    "    extract_valid_json_lines,add_index_to_jsonl_lines,count_output_filter_stats,get_covered_indices_from_cluster_output,\n",
    "    aggregate_cluster_outputs,build_user_prompt_cluster_agg,assign_global_cluster_ids,\n",
    "    extract_top5_heat_clusters,attach_discussion_points,extract_cluster_stats,append_daily_top5_to_version_jsonl,infer_date_for_batch,\n",
    "    match_dialogs_by_time,build_user_prompt_subcluster_opinion,extract_time_axis_from_title,\n",
    "    parse_and_normalize_opinion_output,build_daily_top5_opinion_records,build_user_prompt_version_agg,parse_model2_output_to_json_list,normalize_model3_clusters,\n",
    "    read_jsonl_file,build_version_agg_input_jsonl_text,compute_version_heat_topk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b7b9c0-b495-4640-b7d1-2c31ef371d3d",
   "metadata": {},
   "source": [
    "## è®¾ç½®å‚æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70d36c9f-a439-4597-b52a-ca091439031b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============= ä½ çš„æ¨¡å‹ä¸æ–‡ä»¶é…ç½®ï¼ˆæ”¹è¿™é‡Œï¼‰ =============\n",
    "API_URL   = \"https://ark.cn-beijing.volces.com/api/v3/chat/completions\" \n",
    "API_KEY = \"de91deb0-aae6-46cb-bac0-17ac3b6107f5\" #API\n",
    "V3_MODEL_ID= \"ep-20251020160142-5d7hp\"#æ¥å…¥ç‚¹\n",
    "V3_1_MODEL_ID = \"ep-20251020160025-9p5tj\"#æ¥å…¥ç‚¹\n",
    "R1_MODEL_ID = \"ep-20251020160103-5n6g2\"#æ¥å…¥ç‚¹\n",
    "\n",
    "PROMPT_MD_PATH01 = Path(\"æç¤ºè¯1.md\") # æ¨¡å‹#1 system æç¤ºè¯ï¼ˆç­›ç›¸å…³ï¼‰\n",
    "PROMPT_MD_PATH02 = Path(\"2è¯é¢˜åˆ†ç±».md\") # æ¨¡å‹#2 system æç¤ºè¯ï¼ˆåˆ†è¯é¢˜ï¼‰\n",
    "PROMPT_MD_PATH03 = Path(\"3æ—¥èšåˆ.md\") # æ¨¡å‹#3 system æç¤ºè¯ï¼ˆæ—¥èšåˆï¼‰\n",
    "PROMPT_MD_PATH04 = Path(\"ç‰ˆæœ¬èšåˆ.md\") #æ¨¡å‹#4 system æç¤ºè¯ï¼ˆè§‚ç‚¹åˆ†æï¼‰\n",
    "VERSION_TOP5_JSONL = \"test_top5.jsonl\"\n",
    "BATCH_SIZE       = 300\n",
    "SLEEP_BETWEEN    = 1   # æ¯æ‰¹ä¹‹é—´çš„é—´éš”ï¼Œé˜²æ­¢QPSè§¦å‘é™æµï¼›æŒ‰éœ€è°ƒæ•´\n",
    "RETRIES          = 2\n",
    "TEMPERATURE      = 0.20\n",
    "MAX_TOKENS       = 16384\n",
    "TIMEOUT_SEC      = 600\n",
    "# ====================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3b2dc1-1a41-4ca6-9959-cccbb22adb86",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 1.æ£€éªŒæ¯æ—¥è¯æç°‡åˆ†ç±»è¾“å‡º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "80ca2f9f-62ca-4df1-aeae-2ead09fb39de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å‡†å¤‡å¤„ç† 141 æ¡ï¼Œå…± 1 æ‰¹ï¼ˆæ¯æ‰¹ 300 æ¡ï¼‰ã€‚\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ”¥ æ‰¹å¤„ç†è¿›åº¦:   0%|                                                                                                                                     | 0/1 [02:39<?, ?æ‰¹/s]      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[æ‰¹æ¬¡ 1] æ¨¡å‹#1 è¾“å‡ºæ€»è¡Œæ•°ï¼š89ï¼Œå…¶ä¸­ç©å®¶å‘è¨€ï¼š89 æ¡ï¼ˆä¸å»é‡ï¼‰\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ”¥ æ‰¹å¤„ç†è¿›åº¦:   0%|                                                                                                                                     | 0/1 [02:46<?, ?æ‰¹/s]      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== æ‰¹æ¬¡ 1/1 è¯é¢˜ç°‡è¾“å‡º =====\n",
      "{\"è¯é¢˜ç°‡\":\"åœæœç»´æŠ¤è¡¥å¿è®¨è®ºï¼ˆ2025-11-19 15:02:03-15:11:27ï¼‰\",\"æ ¸å¿ƒå¯¹è±¡/æœºåˆ¶\":\"åœæœç»´æŠ¤è¡¥å¿æœºåˆ¶ï¼Œç©å®¶è®¨è®ºç»´æŠ¤æ—¶é•¿ä¸è¡¥å¿æœŸæœ›ï¼ˆ100æŠ½ã€50æŠ½ã€çŸ³å¸ã€ä»£å¸ç­‰ï¼‰\"}\n",
      "{\"è¯é¢˜ç°‡\":\"æ¸¸æˆä¸‹è½½ä¸å®‰è£…é—®é¢˜ï¼ˆ2025-11-19 15:02:22-15:13:20ï¼‰\",\"æ ¸å¿ƒå¯¹è±¡/æœºåˆ¶\":\"æ¸¸æˆå®‰è£…åŒ…ä¸‹è½½ä¸æ›´æ–°æœºåˆ¶ï¼Œç©å®¶è¯¢é—®ä¸‹è½½é“¾æ¥ã€æ˜¯å¦éœ€è¦é‡æ–°ä¸‹è½½ç­‰é—®é¢˜\"}\n",
      "{\"è¯é¢˜ç°‡\":\"è§’è‰²æŠ€èƒ½æ›´æ–°è®¨è®ºï¼ˆ2025-11-19 15:02:58-15:04:02ï¼‰\",\"æ ¸å¿ƒå¯¹è±¡/æœºåˆ¶\":\"çŒ›çŠ¸è±¡å’Œä»™äººæŒè§’è‰²çš„PTSDä¸å¼ºè¿«ç—‡è¢«åŠ¨æŠ€èƒ½æ›´æ–°å®è£…æƒ…å†µ\"}\n",
      "{\"è¯é¢˜ç°‡\":\"å®¢æœäº’åŠ¨ä¸è°ƒä¾ƒï¼ˆ2025-11-19 15:07:27-15:14:50ï¼‰\",\"æ ¸å¿ƒå¯¹è±¡/æœºåˆ¶\":\"å®¢æœæœåŠ¡ä½“éªŒï¼Œç©å®¶ä¸å®¢æœè–ç±³ã€è“æ¡‰çš„äº’åŠ¨è°ƒä¾ƒåŠæ— å…³æ¸¸æˆå†…å®¹çš„é—²èŠ\"}\n",
      "===========================================\n",
      "\n",
      "[æ‰¹æ¬¡ 1] è¯é¢˜ç°‡è¦†ç›–åŸå§‹å‘è¨€æ¡æ•°ï¼š0ï¼Œæœªè¢«è¦†ç›–æ¡æ•°ï¼š141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ”¥ æ‰¹å¤„ç†è¿›åº¦: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:47<00:00, 167.86s/æ‰¹]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… å…¨éƒ¨æ‰¹æ¬¡å¤„ç†å®Œæˆï¼\n",
      "åŸå§‹è¾“å…¥æ€»æ•°ï¼š141\n",
      "æ¨¡å‹#1 ç­›ç›¸å…³åæ€»è¡Œæ•°ï¼š89ï¼Œå…¶ä¸­ç©å®¶å‘è¨€ï¼š89 æ¡\n",
      "æ¨¡å‹#2 è¯é¢˜ç°‡ç´¯è®¡è¦†ç›–åŸå§‹å‘è¨€æ¡æ•°ï¼š0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "# ===========================================================\n",
    "# =============== ä¸»å¾ªç¯ï¼šæ¨¡å‹#1 + æ¨¡å‹#2 ====================\n",
    "# ===========================================================\n",
    "\n",
    "# è¯»å–ç³»ç»Ÿæç¤º\n",
    "system_prompt01 = load_system_prompt(PROMPT_MD_PATH01)  # ç­›ç›¸å…³\n",
    "system_prompt02 = load_system_prompt(PROMPT_MD_PATH02)  # åšè¯é¢˜ç°‡\n",
    "# 1âƒ£ ç»™åŸå§‹ jsonl æ¯æ¡åŠ  _idx\n",
    "jsonl_lines01_indexed = add_index_to_jsonl_lines(jsonl_lines01)\n",
    "\n",
    "total = len(jsonl_lines01_indexed)\n",
    "\n",
    "PRINT_UNCLUSTERED = False\n",
    "if total == 0:\n",
    "    print(\"æ²¡æœ‰å¯å¤„ç†çš„æ•°æ®ã€‚\")\n",
    "else:\n",
    "    total_batches = (total + BATCH_SIZE - 1) // BATCH_SIZE\n",
    "    print(f\"å‡†å¤‡å¤„ç† {total} æ¡ï¼Œå…± {total_batches} æ‰¹ï¼ˆæ¯æ‰¹ {BATCH_SIZE} æ¡ï¼‰ã€‚\")\n",
    "\n",
    "# ç»Ÿè®¡æ€»é‡ç”¨çš„ï¼ˆå¯é€‰ï¼‰\n",
    "total_filtered_lines = 0         # æ¨¡å‹#1 è¾“å‡ºæ€»è¡Œæ•°ä¹‹å’Œï¼ˆå«å®¢æœï¼‰\n",
    "total_filtered_player_lines = 0  # æ¨¡å‹#1 è¾“å‡ºç©å®¶è¡Œæ•°ä¹‹å’Œ\n",
    "total_covered_idx = 0            # è¢«è¯é¢˜ç°‡è¦†ç›–çš„åŸå§‹å‘è¨€æ€»æ•°ï¼ˆæŒ‰ _idx å»é‡ï¼‰\n",
    "\n",
    "\n",
    "for b in tqdm(range(total_batches), desc=\"ğŸ”¥ æ‰¹å¤„ç†è¿›åº¦\", unit=\"æ‰¹\"):\n",
    "    start = b * BATCH_SIZE\n",
    "    end = min(start + BATCH_SIZE, total)\n",
    "    # æœ¬æ‰¹åŸå§‹å‘è¨€ï¼ˆå·²å¸¦ _idxï¼‰\n",
    "    batch_lines = jsonl_lines01_indexed[start:end]\n",
    "\n",
    "    # æœ¬æ‰¹åŸå§‹ _idx é›†åˆï¼Œç”¨æ¥å’Œè¯é¢˜ç°‡è¦†ç›–åšå·®é›†\n",
    "    batch_original_idx = set()\n",
    "    for line in batch_lines:\n",
    "        try:\n",
    "            obj = json.loads(line)\n",
    "            batch_original_idx.add(int(obj[\"_idx\"]))\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    try:\n",
    "        # ========== æ¨¡å‹ #1ï¼šç­›ç›¸å…³ ==========\n",
    "        user_prompt1 = build_user_prompt_filter(batch_lines)\n",
    "        output_filter = call_ark_chat_completions(\n",
    "            api_url=API_URL,\n",
    "            api_key=API_KEY,\n",
    "            model=V3_MODEL_ID,\n",
    "            system_prompt=system_prompt01,\n",
    "            user_prompt=user_prompt1,\n",
    "            temperature=TEMPERATURE,\n",
    "            max_tokens=MAX_TOKENS,\n",
    "            timeout=TIMEOUT_SEC,\n",
    "            retries=RETRIES,\n",
    "        )\n",
    "        if not output_filter:\n",
    "            tqdm.write(f\"[æ‰¹æ¬¡ {b+1}] æ¨¡å‹#1 æ— æœ‰æ•ˆè¾“å‡ºï¼Œè·³è¿‡ã€‚\")\n",
    "            continue\n",
    "\n",
    "        # ç»Ÿè®¡ç­›ç›¸å…³ä¹‹åçš„è¡Œæ•°ï¼šæ€»è¡Œæ•° & ç©å®¶è¡Œæ•°\n",
    "        filter_total_lines, filter_player_lines = count_output_filter_stats(output_filter)\n",
    "        total_filtered_lines += filter_total_lines\n",
    "        total_filtered_player_lines += filter_player_lines\n",
    "\n",
    "        tqdm.write(\n",
    "            f\"[æ‰¹æ¬¡ {b+1}] æ¨¡å‹#1 è¾“å‡ºæ€»è¡Œæ•°ï¼š{filter_total_lines}ï¼Œ\"\n",
    "            f\"å…¶ä¸­ç©å®¶å‘è¨€ï¼š{filter_player_lines} æ¡ï¼ˆä¸å»é‡ï¼‰\"\n",
    "        )\n",
    "\n",
    "        # ========== æ¨¡å‹ #2ï¼šè¯é¢˜ç°‡ ==========\n",
    "        user_prompt2 = build_user_prompt_clsuter(output_filter)\n",
    "        output_cluster = call_ark_chat_completions(\n",
    "            api_url=API_URL,\n",
    "            api_key=API_KEY,\n",
    "            model=V3_1_MODEL_ID,\n",
    "            system_prompt=system_prompt02,\n",
    "            user_prompt=user_prompt2,\n",
    "            temperature=TEMPERATURE,\n",
    "            max_tokens=MAX_TOKENS,\n",
    "            timeout=TIMEOUT_SEC,\n",
    "            retries=RETRIES,\n",
    "        )\n",
    "        if not output_cluster:\n",
    "            tqdm.write(f\"[æ‰¹æ¬¡ {b+1}] æ¨¡å‹#2 æ— æœ‰æ•ˆè¾“å‡ºï¼Œè·³è¿‡ã€‚\")\n",
    "            continue\n",
    "\n",
    "        # æ‰“å°æœ¬æ‰¹çš„è¯é¢˜ç°‡è¾“å‡ºï¼ˆåŸæ ·ï¼‰\n",
    "        print(f\"\\n===== æ‰¹æ¬¡ {b+1}/{total_batches} è¯é¢˜ç°‡è¾“å‡º =====\")\n",
    "        print(output_cluster)\n",
    "        print(\"===========================================\\n\")\n",
    "\n",
    "        # è®¡ç®—ï¼šæœ¬æ‰¹æœ‰å“ªäº› _idx è¢«è¯é¢˜ç°‡è¦†ç›–ï¼ˆä»â€œå‘è¨€è¡Œå·åˆ—è¡¨â€è§£æï¼‰\n",
    "        covered_idx = get_covered_indices_from_cluster_output(output_cluster)\n",
    "        total_covered_idx += len(covered_idx)\n",
    "\n",
    "        # å’Œâ€œæœ¬æ‰¹åŸå§‹å‘è¨€ _idx é›†åˆâ€åšå·®é›†ï¼Œçœ‹æœ‰å“ªäº›æ²¡è¢«è¦†ç›–\n",
    "        unclustered_idx = batch_original_idx - covered_idx\n",
    "\n",
    "        tqdm.write(\n",
    "            f\"[æ‰¹æ¬¡ {b+1}] è¯é¢˜ç°‡è¦†ç›–åŸå§‹å‘è¨€æ¡æ•°ï¼š{len(covered_idx)}ï¼Œ\"\n",
    "            f\"æœªè¢«è¦†ç›–æ¡æ•°ï¼š{len(unclustered_idx)}\"\n",
    "        )\n",
    "\n",
    "        # â­â­ æ–°å¢ï¼šæ‰“å°â€œæœªè¢«è¯é¢˜ç°‡è¦†ç›–â€çš„å‘è¨€ä¿¡æ¯ï¼ˆæœ€å¤šå‰ 20 æ¡ï¼‰\n",
    "        if PRINT_UNCLUSTERED and unclustered_idx:\n",
    "            # å…ˆæŠŠè¿™ä¸€æ‰¹ä¸­æœªè¦†ç›–çš„å‘è¨€å¯¹è±¡æå‡ºæ¥\n",
    "            unclustered_records = []\n",
    "            for line in batch_lines:\n",
    "                try:\n",
    "                    obj = json.loads(line)\n",
    "                except Exception:\n",
    "                    continue\n",
    "                idx_val = obj.get(\"_idx\")\n",
    "                try:\n",
    "                    idx_int = int(idx_val)\n",
    "                except Exception:\n",
    "                    continue\n",
    "                if idx_int in unclustered_idx:\n",
    "                    unclustered_records.append(obj)\n",
    "\n",
    "            # æŒ‰ _idx æ’åºï¼Œé¿å…ä¹±åº\n",
    "            unclustered_records.sort(key=lambda x: int(x.get(\"_idx\", 0)))\n",
    "\n",
    "            print(f\"\\n[æ‰¹æ¬¡ {b+1}] æœªè¢«è¯é¢˜ç°‡è¦†ç›–çš„åŸå§‹å‘è¨€ï¼ˆæœ€å¤šå‰20æ¡ï¼‰ï¼š\")\n",
    "            for rec in unclustered_records[:20]:\n",
    "                idx = rec.get(\"_idx\")\n",
    "                date = rec.get(\"å‘è¨€æ—¥æœŸ\") or rec.get(\"æ—¥æœŸ\") or \"\"\n",
    "                t = rec.get(\"å‘è¨€æ—¶é—´\") or rec.get(\"æ—¶é—´\") or \"\"\n",
    "                speaker = rec.get(\"å‘è¨€äººID\") or rec.get(\"ç©å®¶ID\") or rec.get(\"è§’è‰²ID\") or \"\"\n",
    "                msg = (\n",
    "                    rec.get(\"ç©å®¶æ¶ˆæ¯\")\n",
    "                    or rec.get(\"å‘è¨€å†…å®¹\")\n",
    "                    or rec.get(\"ç©å®¶å‘è¨€\")\n",
    "                    or rec.get(\"æ¶ˆæ¯\")\n",
    "                    or \"\"\n",
    "                )\n",
    "                print(f\"- _idx={idx} [{date} {t}] {speaker}: {msg}\")\n",
    "            print()  # æ¢è¡Œåˆ†éš”ä¸€ä¸‹\n",
    "\n",
    "    except Exception as e:\n",
    "        tqdm.write(f\"[æ‰¹æ¬¡ {b+1}] âŒ å‡ºé”™ï¼š{e}\")\n",
    "        continue\n",
    "\n",
    "    # é˜²æ­¢ QPS è¿‡é«˜\n",
    "    time.sleep(SLEEP_BETWEEN)\n",
    "\n",
    "print(\"\\nâœ… å…¨éƒ¨æ‰¹æ¬¡å¤„ç†å®Œæˆï¼\")\n",
    "print(f\"åŸå§‹è¾“å…¥æ€»æ•°ï¼š{total}\")\n",
    "print(f\"æ¨¡å‹#1 ç­›ç›¸å…³åæ€»è¡Œæ•°ï¼š{total_filtered_lines}ï¼Œå…¶ä¸­ç©å®¶å‘è¨€ï¼š{total_filtered_player_lines} æ¡\")\n",
    "print(f\"æ¨¡å‹#2 è¯é¢˜ç°‡ç´¯è®¡è¦†ç›–åŸå§‹å‘è¨€æ¡æ•°ï¼š{total_covered_idx}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5465d2eb-915e-4133-a3dd-485de2d48577",
   "metadata": {},
   "source": [
    "## åŠ è®¨è®ºè§‚ç‚¹åˆ†æçš„ç‰ˆæœ¬æµ‹è¯•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411f43b3-eb1e-4fff-9e58-f758a3848262",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å‡†å¤‡å¤„ç† 1201 æ¡ï¼Œå…± 5 æ‰¹ï¼ˆæ¯æ‰¹ 300 æ¡ï¼‰ã€‚\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ”¥ æ‰¹å¤„ç†è¿›åº¦:   0%|                                                                                                                                                                                         | 0/5 [00:00<?, ?æ‰¹/s]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# --- å‰ç½®ï¼šç³»ç»Ÿæç¤ºã€åˆå§‹åŒ–ç­‰ ---\n",
    "system_prompt01 = load_system_prompt(PROMPT_MD_PATH01)  # ç­›ç›¸å…³\n",
    "system_prompt02 = load_system_prompt(PROMPT_MD_PATH02)  # åšè¯æç°‡\n",
    "system_prompt03 = load_system_prompt(PROMPT_MD_PATH03)  # æ—¥è¯é¢˜ç°‡èšåˆ\n",
    "\n",
    "\n",
    "batch_cluster_outputs = []  # ç”¨äºå­˜æ”¾å½“å¤©æ‰€æœ‰æ‰¹æ¬¡çš„è¯é¢˜ç°‡ JSON è¡Œï¼ˆç»™æ¨¡å‹#3ç”¨ï¼‰\n",
    "\n",
    "total = len(jsonl_lines01)\n",
    "if total == 0:\n",
    "    print(\"æ²¡æœ‰å¯å¤„ç†çš„æ•°æ®ã€‚\")\n",
    "else:\n",
    "    total_batches = (total + BATCH_SIZE - 1) // BATCH_SIZE\n",
    "    print(f\"å‡†å¤‡å¤„ç† {total} æ¡ï¼Œå…± {total_batches} æ‰¹ï¼ˆæ¯æ‰¹ {BATCH_SIZE} æ¡ï¼‰ã€‚\")\n",
    "\n",
    "written_total = 0\n",
    "\n",
    "# ====================================================\n",
    "# æ¨¡å‹ #1 + æ¨¡å‹ #2ï¼šç­›ç›¸å…³ + è¯é¢˜ç°‡åˆ’åˆ†ï¼ˆæŒ‰æ‰¹å¤„ç†ï¼‰\n",
    "# ====================================================\n",
    "for b in tqdm(range(total_batches), desc=\"ğŸ”¥ æ‰¹å¤„ç†è¿›åº¦\", unit=\"æ‰¹\"):\n",
    "    start = b * BATCH_SIZE\n",
    "    end = min(start + BATCH_SIZE, total)\n",
    "    batch_lines = jsonl_lines01[start:end]\n",
    "\n",
    "    try:\n",
    "        # --- æ¨¡å‹ #1ï¼šç­›ç›¸å…³ ---\n",
    "        user_prompt1 = build_user_prompt_filter(batch_lines)\n",
    "        output_filter = call_ark_chat_completions(\n",
    "            api_url=API_URL,\n",
    "            api_key=API_KEY,\n",
    "            model=V3_MODEL_ID,\n",
    "            system_prompt=system_prompt01,\n",
    "            user_prompt=user_prompt1,\n",
    "            temperature=TEMPERATURE,\n",
    "            max_tokens=MAX_TOKENS,\n",
    "            timeout=TIMEOUT_SEC,\n",
    "            retries=RETRIES,\n",
    "        )\n",
    "        \n",
    "        if not output_filter:\n",
    "            tqdm.write(f\"[æ‰¹æ¬¡ {b+1}] æ¨¡å‹#1 æ— æœ‰æ•ˆè¾“å‡ºï¼Œè·³è¿‡ã€‚\")\n",
    "            continue\n",
    "\n",
    "        filter_count = sum(1 for line in output_filter.splitlines() if line.strip())\n",
    "        tqdm.write(f\"[æ‰¹æ¬¡ {b+1}] æ¨¡å‹#1 ç­›åä¿ç•™ {filter_count} æ¡\")\n",
    "        written_total += filter_count\n",
    "\n",
    "        # --- æ¨¡å‹ #2ï¼šè¯é¢˜ç°‡åˆ’åˆ† ---\n",
    "        user_prompt2 = build_user_prompt_clsuter(output_filter)\n",
    "        output_cluster = call_ark_chat_completions(\n",
    "            api_url=API_URL,\n",
    "            api_key=API_KEY,\n",
    "            model=V3_1_MODEL_ID,\n",
    "            system_prompt=system_prompt02,\n",
    "            user_prompt=user_prompt2,\n",
    "            temperature=TEMPERATURE,\n",
    "            max_tokens=MAX_TOKENS,\n",
    "            timeout=TIMEOUT_SEC,\n",
    "            retries=RETRIES,\n",
    "        )\n",
    "\n",
    "        if not output_cluster:\n",
    "            tqdm.write(f\"[æ‰¹æ¬¡ {b+1}] æ¨¡å‹#2 æ— æœ‰æ•ˆè¾“å‡ºï¼Œè·³è¿‡ã€‚\")\n",
    "            continue\n",
    "\n",
    "        # ---------- âœ… æ–°çš„ JSON è§£æ + _cluster_id éƒ¨åˆ† ----------\n",
    "        try:\n",
    "            # 1) å…ˆç”¨ä¿®å¤è§£æå™¨ï¼ŒæŠŠæ¨¡å‹#2è¾“å‡ºå˜æˆ list[dict]\n",
    "            cluster_json_list = parse_model2_output_to_json_list(\n",
    "                output_cluster,\n",
    "                batch_idx=b+1,\n",
    "            )\n",
    "\n",
    "            if not cluster_json_list:\n",
    "                tqdm.write(f\"[æ‰¹æ¬¡ {b+1}] âš  æœ¬æ‰¹æ¬¡æœªè§£æå‡ºä»»ä½•åˆæ³• JSON å¯¹è±¡ï¼Œè·³è¿‡ã€‚\")\n",
    "                continue\n",
    "\n",
    "            # 2) ä»è¯¥æ‰¹æ¬¡ä¸­æ¨æ–­æ—¥æœŸï¼ˆä½ è‡ªå·±çš„é€»è¾‘ï¼‰\n",
    "            date_str = infer_date_for_batch(cluster_json_list, batch_lines)\n",
    "            batch_id = f\"B{b+1}\"\n",
    "\n",
    "            # 3) åˆ†é…å…¨å±€ _cluster_idï¼šæ—¥æœŸ + æ‰¹æ¬¡å· + åºå· ...\n",
    "            cluster_json_list = assign_global_cluster_ids(\n",
    "                cluster_json_list,\n",
    "                date_str,\n",
    "                batch_id,\n",
    "            )\n",
    "\n",
    "            # 4) å†è½¬æˆ jsonl æ–‡æœ¬ï¼ˆä¾›åç»­ aggregate_cluster_outputs ä½¿ç”¨ï¼‰\n",
    "            output_cluster_with_ids = \"\\n\".join(\n",
    "                json.dumps(c, ensure_ascii=False) for c in cluster_json_list\n",
    "            )\n",
    "            batch_cluster_outputs.append(output_cluster_with_ids)\n",
    "\n",
    "        except Exception as e:\n",
    "            tqdm.write(f\"[æ‰¹æ¬¡ {b+1}] âš  æ·»åŠ  _cluster_id å¤±è´¥ï¼š{e}\")\n",
    "            continue\n",
    "        # ---------- JSON è§£æéƒ¨åˆ†ç»“æŸ ----------\n",
    "\n",
    "    except Exception as e:\n",
    "        tqdm.write(f\"[æ‰¹æ¬¡ {b+1}] âŒ å‡ºé”™ï¼š{e}\")\n",
    "        continue\n",
    "\n",
    "    time.sleep(SLEEP_BETWEEN)\n",
    "            \n",
    "\n",
    "# ====================================================\n",
    "# æ¨¡å‹ #3ï¼šæ—¥è¯é¢˜ç°‡èšåˆ\n",
    "# ====================================================\n",
    "\n",
    "# --- èšåˆå½“å¤©æ‰€æœ‰æ‰¹æ¬¡çš„è¯é¢˜ç°‡ jsonl ---\n",
    "all_cluster = aggregate_cluster_outputs(batch_cluster_outputs)\n",
    "\n",
    "# --- æ¨¡å‹ #3ï¼šæ—¥è¯é¢˜ç°‡èšåˆ ---\n",
    "user_prompt3 = build_user_prompt_cluster_agg(all_cluster)\n",
    "output_cluster_agg = call_ark_chat_completions(\n",
    "    api_url=API_URL,\n",
    "    api_key=API_KEY,\n",
    "    model=V3_1_MODEL_ID,           # æ™ºèƒ½ä½“3ç”¨çš„æ¨¡å‹\n",
    "    system_prompt=system_prompt03,  # æ—¥è¯é¢˜ç°‡èšåˆæç¤ºè¯\n",
    "    user_prompt=user_prompt3,\n",
    "    temperature=TEMPERATURE,\n",
    "    max_tokens=MAX_TOKENS,\n",
    "    timeout=TIMEOUT_SEC,\n",
    "    retries=RETRIES,\n",
    ")\n",
    "\n",
    "# å­è¯é¢˜ç°‡ï¼ˆæ¨¡å‹#2 è¾“å‡ºï¼Œç» aggregate åçš„ all_clusterï¼Œæœ¬èº«å°±æ˜¯ jsonlï¼‰\n",
    "parsed_subclusters = [\n",
    "    json.loads(line.strip())\n",
    "    for line in all_cluster.strip().splitlines()\n",
    "    if line.strip()\n",
    "]\n",
    "\n",
    "# èšåˆç°‡ï¼ˆæ¨¡å‹#3 è¾“å‡ºï¼Œå¦‚æœä¸å¤ªå¹²å‡€ï¼Œå¯ä»¥ç”¨ parse_jsonl_text åŒ…ä¸€ä¸‹ï¼‰\n",
    "parsed_clusters = normalize_model3_clusters(output_cluster_agg, parsed_subclusters)\n",
    "\n",
    "# ====================================================\n",
    "# è®¡ç®— Top5 & å†™å…¥ç‰ˆæœ¬ jsonl\n",
    "# ====================================================\n",
    "\n",
    "top5_results = extract_top5_heat_clusters(parsed_clusters, jsonl_lines01, top_k=5)\n",
    "final_result = attach_discussion_points(top5_results, parsed_subclusters)\n",
    "\n",
    "# è¾“å‡ºæ£€æŸ¥ï¼ˆå¯æš‚æ—¶æ‰“å¼€ï¼‰\n",
    "# for row in final_result:\n",
    "#     print(json.dumps(row, ensure_ascii=False, indent=2))\n",
    "\n",
    "append_daily_top5_to_version_jsonl(\n",
    "    final_result,\n",
    "    version_jsonl_path=VERSION_TOP5_JSONL,  # è¿™ä¸ªè·¯å¾„ä½ å¯ä»¥æŒ‰ç‰ˆæœ¬å·åŠ¨æ€æ”¹\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e56ff08-4c63-40a3-bddd-d852b3cd3d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'è¯é¢˜ç°‡': 'æµ‹è¯•ç‰ˆæœ¬ä¸‹è½½å®‰è£…å’¨è¯¢', 'è®¨è®ºç‚¹': ['åœ°çƒæµ‹è¯•ç‰ˆæœ¬ä¸‹è½½é“¾æ¥å‘æ”¾æ—¶é—´ä¸å®‰è£…æ–¹å¼çš„å…·ä½“è¯¢é—®', 'ç©å®¶è¯¢é—®å®‰è£…åŒ…å‘æ”¾æ—¶é—´ï¼ˆä¸‹åˆï¼‰ã€ä¸‹è½½å¹³å°ï¼ˆå®‰å“/iOS/æ¨¡æ‹Ÿå™¨ï¼‰åŠä¸‹è½½æ–¹å¼', 'æ¸¸æˆå®¢æˆ·ç«¯å®‰è£…åŒ…ä¸‹è½½ã€æ–‡ä»¶å¤§å°åŠå®‰è£…é—®é¢˜'], 'æ—¥æœŸidåˆ—è¡¨': [{'æ—¥æœŸ': '2025-12-03', 'id': '2025-12-03_T01'}]}, {'è¯é¢˜ç°‡': 'åœ°çƒæ¸¸æˆæ ¸å¿ƒç©æ³•å’¨è¯¢', 'è®¨è®ºç‚¹': ['åœ°çƒæ¸¸æˆæ ¸å¿ƒç©æ³•æœºåˆ¶å’¨è¯¢ï¼ŒåŒ…æ‹¬èµ°æ ¼å­å åœ°ã€æŒ–çŸ¿æŠ“çŸ¿å·¥ç­‰å…·ä½“ç©æ³•ç»†èŠ‚', 'ç©å®¶å¯¹æ¸¸æˆæ ¸å¿ƒç©æ³•ç±»å‹ï¼ˆåœ°å—èµ°æ ¼å­ç­–ç•¥ã€æŒ‚æœºæ”¾ç½®ã€ç”»é£é£æ ¼ï¼‰çš„è¯¢é—®ä¸è®¨è®º', 'æ¸¸æˆæ ¸å¿ƒç©æ³•ï¼ˆæ¢ç´¢å æ ¼å­ã€æ‰“æ€ªã€æ”¶é›†è£…å¤‡ï¼‰çš„ç†è§£ä¸å’¨è¯¢'], 'æ—¥æœŸidåˆ—è¡¨': [{'æ—¥æœŸ': '2025-12-02', 'id': '2025-12-02_T02'}]}, {'è¯é¢˜ç°‡': 'æ®–è£…ç³»ç»Ÿæœºåˆ¶ä¸ç­–ç•¥', 'è®¨è®ºç‚¹': ['æ®–è£…ç³»ç»Ÿè§£é”æ¡ä»¶ä¸ä½¿ç”¨é™åˆ¶', 'æ®–è£…ç³»ç»Ÿçš„è§’è‰²é…ç½®è§„åˆ™ï¼ŒåŒ…æ‹¬ä¸“å±é‡‘è‰²å¤©èµ‹ã€æ®–è£…é¢œè‰²é€‰æ‹©é™åˆ¶åŠ234ä½ç½®è‡ªé€‰æœºåˆ¶', 'æ®–è£…ç³»ç»Ÿå¼€å±€å›ºå®šæ®–è£…ä¸åç»­æ®–è£…é€‰æ‹©æ›´æ¢æœºåˆ¶', 'ä¸€å‘¨ç›®/äºŒå‘¨ç›®çŸ³æ¿é¢œè‰²é€‰æ‹©ä¸åˆå§‹æ®–è£…é¢œè‰²çš„åŒ¹é…ç­–ç•¥', 'æ®–è£…æ ¼å­æ•°é‡ä¸è¶³å¯¹å¥—è£…é€‚é…çš„å½±å“', 'æ®–è£…ç³»ç»Ÿçš„å‡çº§æ–¹æ³•ä¸é€”å¾„', 'æ®–è£…è·å–ã€å‡çº§ã€æ˜Ÿçº§æœºåˆ¶åŠå¤§è¢‹ç†Šç­‰å…·ä½“æ®–è£…ä½¿ç”¨ç­–ç•¥', 'äºŒæ˜Ÿæ®–è£…è§£é”æ¡ä»¶ä¸é˜µå®¹æ­é…ç­–ç•¥', 'æ®–è£…ç³»ç»Ÿçš„åŸºç¡€æœºåˆ¶ä¸æ“ä½œç†è§£'], 'æ—¥æœŸidåˆ—è¡¨': [{'æ—¥æœŸ': '2025-12-03', 'id': '2025-12-03_T05'}, {'æ—¥æœŸ': '2025-12-04', 'id': '2025-12-04_T01'}, {'æ—¥æœŸ': '2025-12-05', 'id': '2025-12-05_T01'}]}, {'è¯é¢˜ç°‡': 'ç²¾ç¥å€¼ç®¡ç†ç³»ç»Ÿ', 'è®¨è®ºç‚¹': ['è§’è‰²ç²¾ç¥çŠ¶æ€ç®¡ç†ç³»ç»Ÿï¼ŒåŒ…æ‹¬ç²¾ç¥å€¼å½’é›¶åæœã€å¼‚é£Ÿç™–æ•ˆæœã€ææƒ§ç—‡debuffä»¥åŠé©¾é©¶å‘˜ä½œä¸ºæ¶ˆè€—å“çš„æœºåˆ¶', 'ç²¾ç¥æ±¡æŸ“çŠ¶æ€çš„ç‰¹æ®Šæ•ˆæœï¼Œè®¨è®º30ç‚¹ç²¾ç¥ä»¥ä¸‹æ—¶ä¼¤å®³ç¿»å€çš„æœºåˆ¶ä¼˜åŠ¿', 'ç†æ™ºå€¼æ¢å¤æ–¹å¼ä¸é“å…·å›å¤æ•ˆæœæ¢è®¨', 'ç²¾ç¥åŠ›æ¢å¤æ–¹å¼ã€é©¾é©¶å‘˜æ­»äº¡ä¸å¤æ´»æœºåˆ¶ã€ç‰©å“ä¿ç•™è§„åˆ™', 'ä½ç²¾ç¥åŠ›çŠ¶æ€ä¸‹çš„æˆ˜åŠ›å¢å¼ºæ•ˆæœ', 'ç²¾ç¥å€¼å›å¤é“å…·ï¼ˆå¦‚çƒŸï¼‰çš„æ•ˆæœä¸é©¾é©¶å‘˜æ¶ˆè€—å“ç‰¹æ€§', 'ä½ç²¾ç¥å€¼çŠ¶æ€çš„ç‰¹æ®Šæ•ˆæœä¸æˆ˜æ–—ä¼˜åŠ¿', 'è„‘æ®‹å€¼ï¼ˆç†æ™ºå€¼ï¼‰æ§åˆ¶åœ¨10ç‚¹ä»¥ä¸‹çš„ç­–ç•¥ï¼Œä¸åŒæ®–è£…æŠ•ç¡¬å¸å’Œå‡€åŒ–æ“ä½œå¯¹ç†æ™ºå€¼çš„å½±å“', '15ç‚¹ä»¥ä¸‹ç²¾ç¥å€¼æˆ˜æ–—æ¸…é›¶é£é™©ä¸æ®–è£…è¡€é‡ç‹¬ç«‹äºé©¾é©¶å‘˜çš„æœºåˆ¶'], 'æ—¥æœŸidåˆ—è¡¨': [{'æ—¥æœŸ': '2025-12-03', 'id': '2025-12-03_T03'}, {'æ—¥æœŸ': '2025-12-04', 'id': '2025-12-04_T02'}, {'æ—¥æœŸ': '2025-12-05', 'id': '2025-12-05_T05'}]}, {'è¯é¢˜ç°‡': 'æ¸¸æˆæ€§èƒ½ä¸BUGå¤„ç†', 'è®¨è®ºç‚¹': ['æ¸¸æˆä½“éªŒé—®é¢˜ï¼ˆå‘çƒ­ã€å¡é¡¿ã€ç•Œé¢å¡æ­»ï¼‰åŠä¼˜åŒ–åé¦ˆ', 'æ¸¸æˆè¿è¡Œç¨³å®šæ€§é—®é¢˜ï¼Œè®¨è®ºå¡é¡¿ç°è±¡çš„å¤„ç†æ–¹æ³•åŠé‡å¯æ¸¸æˆçš„è§£å†³æ–¹æ¡ˆ', 'æ¸¸æˆBUGåé¦ˆä¸ä¼˜åŒ–å»ºè®®ï¼ŒåŒ…æ‹¬ç•Œé¢æ˜¾ç¤ºå¼‚å¸¸ã€åˆ†å±ä¼˜åŒ–åŠå‰©ä½™æ—¶é—´æ˜¾ç¤ºçš„åŠŸèƒ½éœ€æ±‚', 'æ¸¸æˆå¡é¡¿é—®é¢˜ä¸æˆ˜æ–—è¿›åº¦ä¿ç•™æœºåˆ¶', 'ä¼ é€é—¨ä¼ é€è¿‡ç¨‹ä¸­çš„å¡é¡¿ç°è±¡', 'ç©å®¶åé¦ˆæ¸¸æˆå¡é¡¿é—®é¢˜åŠé€šè¿‡é‡å¯è§£å†³çš„ä½“éªŒ', 'æ¸¸æˆç•Œé¢å¡ä½ã€æ˜¾ç¤ºå¼‚å¸¸ç­‰BUGç°è±¡çš„åé¦ˆåŠé‡å¯æ¸¸æˆçš„è§£å†³æ–¹æ³•', 'é¢åŒ…å¥—è£…å¤‡å›¾æ ‡æ˜¾ç¤ºå¼‚å¸¸ä¸é¢åŒ…ç‚‰æ‹ç‰©ç™–ç²¾ç¥ç—…ç—‡çš„å…³è”æ€§bugåé¦ˆ', 'ç²¾ç‚¼æç¤ºå¼‚å¸¸ã€è‡ªåŠ¨æ‘‡å¥–ä¸æ‹‰æ†æ— å“åº”çš„åŠŸèƒ½BUGåŠé‡å¯æ¢å¤æ•ˆæœ', 'æ¸¸æˆè¿è¡Œå¼‚å¸¸æ—¶çš„BUGå¤„ç†ä¸é‡å¯è§£å†³æœ‰æ•ˆæ€§éªŒè¯', 'æ¸¸æˆè¿è¡Œå¡é¡¿ç°è±¡çš„è¯†åˆ«ä¸é€šè¿‡é‡å¯è§£å†³çš„å¸¸è§„å¤„ç†æ–¹å¼', 'æ¸¸æˆå†…ç‰©å“æ˜¾ç¤ºå¼‚å¸¸é—®é¢˜çš„å®¢æœå¤„ç†ä¸é‡å¯è§£å†³å»ºè®®'], 'æ—¥æœŸidåˆ—è¡¨': [{'æ—¥æœŸ': '2025-12-03', 'id': '2025-12-03_T04'}, {'æ—¥æœŸ': '2025-12-04', 'id': '2025-12-04_T03'}, {'æ—¥æœŸ': '2025-12-05', 'id': '2025-12-05_T03'}, {'æ—¥æœŸ': '2025-12-02', 'id': '2025-12-02_T05'}]}, {'è¯é¢˜ç°‡': 'æ¸¸æˆé—®å·åé¦ˆæœºåˆ¶', 'è®¨è®ºç‚¹': ['æ¸¸æˆä½“éªŒé—®å·åé¦ˆå»ºè®®å¾é›†ä¸å¥–åŠ±å‘æ”¾é—®é¢˜'], 'æ—¥æœŸidåˆ—è¡¨': [{'æ—¥æœŸ': '2025-12-04', 'id': '2025-12-04_T04'}]}, {'è¯é¢˜ç°‡': 'è£…å¤‡ä¸²è”ç³»ç»Ÿæœºåˆ¶', 'è®¨è®ºç‚¹': ['è£…å¤‡ä¸²è”æœºåˆ¶çš„å…·ä½“æ“ä½œæ–¹å¼ä¸è¿æ¥ç‚¹åˆ¤å®šè§„åˆ™', 'æ‰‹å¶ä¸é¢å…·è£…å¤‡é“¾æ¥ä¸ç”Ÿæ•ˆçš„å…·ä½“åŸå› ä¸è§£å†³æ–¹æ³•', 'è£…å¤‡è¿æ¥ç‚¹çš„å…·ä½“æœºåˆ¶ï¼ˆç™½ç‚¹ã€ç´«è‰²åœˆï¼‰ä¸æ‘†æ”¾è¦æ±‚'], 'æ—¥æœŸidåˆ—è¡¨': [{'æ—¥æœŸ': '2025-12-04', 'id': '2025-12-04_T05'}]}, {'è¯é¢˜ç°‡': 'é­”æ–¹ç³»ç»Ÿç­‰çº§æœºåˆ¶', 'è®¨è®ºç‚¹': ['é­”æ–¹ç­‰çº§ä¸Šé™ä¸å¥‡è¿¹ç‚¹æœºåˆ¶', 'é­”æ–¹ä¹‹çœ¼çš„è·å–æ–¹å¼ã€æ•°é‡ä¸Šé™ï¼ˆ7-9ä¸ªï¼‰ã€ä¸åŒé€‰é¡¹æ•ˆæœï¼ˆå¥‡è¿¹ç‚¹ã€é­”æ–¹ç­‰çº§ã€å‡çº§æ—¶é—´ï¼‰ä»¥åŠå‘¨ç›®ç»§æ‰¿è§„åˆ™', '7ä¸ªé­”æ–¹ä¹‹çœ¼æ—¶ä¸‰ä¸ªé€‰é¡¹ï¼ˆå¥‡è¿¹ç‚¹ã€åè¿æŠ½ã€é£èˆ¹è¿›åŒ–ï¼‰çš„ä¼˜åŠ£æ¯”è¾ƒåŠå‘¨ç›®é€‰æ‹©å»ºè®®'], 'æ—¥æœŸidåˆ—è¡¨': [{'æ—¥æœŸ': '2025-12-05', 'id': '2025-12-05_T02'}]}, {'è¯é¢˜ç°‡': 'èµ„æºé‡‡é›†ç³»ç»Ÿæœºåˆ¶', 'è®¨è®ºç‚¹': ['é’“é±¼æŒ–çŸ¿èµ„æºçš„é‡‡é›†ä¸è€—å°½æœºåˆ¶', 'æŒ–çŸ¿è¿›åº¦æ¡æ˜¾ç¤ºã€æ”¶è·æœºåˆ¶ï¼ˆæ”¶è·ä¸ç»ˆæ­¢æŒ–çŸ¿ï¼‰ã€12å°æ—¶æ€ªç‰©å¤æ´»å‘¨æœŸä¸24å°æ—¶æŒ–çŸ¿ç­–ç•¥', 'æŒ–çŸ¿ç³»ç»Ÿ12å°æ—¶è‡ªåŠ¨ç”Ÿæˆ190çº§æ€ªç‰©çš„æœºåˆ¶é—®é¢˜'], 'æ—¥æœŸidåˆ—è¡¨': [{'æ—¥æœŸ': '2025-12-05', 'id': '2025-12-05_T04'}]}, {'è¯é¢˜ç°‡': 'PVPç©æ³•ç³»ç»Ÿ', 'è®¨è®ºç‚¹': ['æ–°å¢PVPç©æ³•åŠŸèƒ½çš„å¼€æ”¾é¢„å‘Šä¸ç©å®¶é—´å¯¹æŠ—ä½“éªŒé¢„æœŸ', 'PVPç©æ³•ä¸­é‡å¯ç©å®¶ä¸æœªé‡å¯ç©å®¶é—´çš„èµ„æºå·®è·ä¸å¹³è¡¡æ€§é—®é¢˜', 'PVPç¯å¢ƒä¸­è£…å¤‡å“è´¨ï¼ˆæ˜Ÿçº§ï¼‰ä¸é­”æ–¹ç­‰çº§å¯¹æˆ˜åŠ›å¹³è¡¡çš„å½±å“æœºåˆ¶'], 'æ—¥æœŸidåˆ—è¡¨': [{'æ—¥æœŸ': '2025-12-02', 'id': '2025-12-02_T01'}, {'æ—¥æœŸ': '2025-12-02', 'id': '2025-12-02_T03'}]}, {'è¯é¢˜ç°‡': 'æ¸¸æˆé‡å¯ä¸å‘¨ç›®è¿›åº¦ç­–ç•¥', 'è®¨è®ºç‚¹': ['æ¯æ—¥é‡å¯ç­–ç•¥ã€å‘¨ç›®è¿›åº¦ï¼ˆå…«å‘¨ç›®ï¼‰åŠå…­ä¸ƒå›¾é­”æ–¹ä¹‹çœ¼å‡»æ€é‡å¯çš„é«˜æ•ˆç©æ³•'], 'æ—¥æœŸidåˆ—è¡¨': [{'æ—¥æœŸ': '2025-12-02', 'id': '2025-12-02_T04'}]}]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "import json\n",
    "from pathlib import Path\n",
    "system_prompt04 = load_system_prompt(PROMPT_MD_PATH04)  # ç‰ˆæœ¬èšåˆï¼ˆæ¨¡å‹4ï¼‰# ====================================================\n",
    "# ï¼ˆå¯é€‰ï¼‰æ¨¡å‹ #4ï¼šç‰ˆæœ¬èšåˆ\n",
    "# ====================================================\n",
    "DAILY_TOP5_PATH = Path(VERSION_TOP5_JSONL)          # ä½ ç°æœ‰çš„å¤šæ—¥ top5 æ–‡ä»¶è·¯å¾„ï¼Œæ¯”å¦‚ \"daily_TOP5.jsonl\"\n",
    "VERSION_AGG_INPUT_PATH = Path(\"version_agg_input.jsonl\")  # æŠ½å–åçš„è¾“å…¥æ–‡ä»¶ï¼ˆç»™æ¨¡å‹#4ï¼‰\n",
    "\n",
    "# 1) è¯»å–å¤šæ—¥ daily_TOP5\n",
    "if not DAILY_TOP5_PATH.exists():\n",
    "    raise FileNotFoundError(f\"æ‰¾ä¸åˆ° daily_TOP5 æ–‡ä»¶ï¼š{DAILY_TOP5_PATH}\")\n",
    "\n",
    "daily_top5 = read_jsonl_file(DAILY_TOP5_PATH)\n",
    "if not daily_top5:\n",
    "    raise ValueError(\"daily_TOP5 æ–‡ä»¶ä¸ºç©ºæˆ–æ— å¯è§£æ JSON è¡Œï¼Œæ— æ³•åšç‰ˆæœ¬èšåˆã€‚\")\n",
    "\n",
    "# 2) æŠ½å–æœ€å°è¾“å…¥ -> å†™å…¥ version_agg_input.jsonl\n",
    "agg_top5_text = build_version_agg_input_jsonl_text(daily_top5, max_points_per_row=3)\n",
    "\n",
    "if not agg_top5_text.strip():\n",
    "    raise ValueError(\"æŠ½å–å agg_top5_text ä¸ºç©ºï¼šè¯·æ£€æŸ¥ daily_TOP5 æ¯è¡Œæ˜¯å¦éƒ½æœ‰ _daily_top_id/æ—¥æœŸ/èšåˆè¯é¢˜ç°‡/è®¨è®ºç‚¹ã€‚\")\n",
    "\n",
    "VERSION_AGG_INPUT_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "VERSION_AGG_INPUT_PATH.write_text(agg_top5_text + \"\\n\", encoding=\"utf-8\")\n",
    "version_agg_input_text = agg_top5_text\n",
    "# 3) å–‚ç»™æ¨¡å‹#4\n",
    "\n",
    "user_prompt4 = build_user_prompt_version_agg(version_agg_input_text)\n",
    "\n",
    "output_version_agg = call_ark_chat_completions(\n",
    "    api_url=API_URL,\n",
    "    api_key=API_KEY,\n",
    "    model=V3_1_MODEL_ID,\n",
    "    system_prompt=system_prompt04,\n",
    "    user_prompt=user_prompt4,\n",
    "    temperature=TEMPERATURE,\n",
    "    max_tokens=MAX_TOKENS,\n",
    "    timeout=TIMEOUT_SEC,\n",
    "    retries=RETRIES,\n",
    ")\n",
    "\n",
    "version_clusters: list[dict] = []   # âœ… ç”¨å†…ç½®ç±»å‹ï¼Œè¿è¡Œæ—¶ä¸ä¼š NameError\n",
    "for i, line in enumerate(output_version_agg.strip().splitlines(), start=1):\n",
    "    s = line.strip()\n",
    "    if not s:\n",
    "        continue\n",
    "    try:\n",
    "        obj = json.loads(s)\n",
    "    except Exception as e:\n",
    "        print(f\"[æ¨¡å‹#4ç‰ˆæœ¬èšåˆè¾“å‡º] ç¬¬{i}è¡Œ JSONè§£æå¤±è´¥ï¼š{e}\\nåŸæ–‡ï¼š{s[:200]}...\")\n",
    "        continue\n",
    "    version_clusters.append(obj)\n",
    "\n",
    "print(version_clusters)\n",
    "# âœ… ç›´æ¥ç”¨å‰é¢è¯»è¿‡çš„ daily_top5\n",
    "#version_top5 = compute_version_heat_topk(\n",
    "    #version_clusters,\n",
    "    #daily_top5,   # è¿™é‡Œç”¨çš„æ˜¯å†…å­˜é‡Œçš„ daily_top5\n",
    "    #top_k=5,\n",
    "#)\n",
    "#print(version_top5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f971efc-e8bf-4a3c-a2ef-478bb4e09f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… writing to: E:\\é¡¹ç›®\\ç©å®¶ç¤¾ç¾¤åˆ†ææ™ºèƒ½ä½“\\ç©å®¶å‘è¨€æ•´ç†ï¼ˆä¾›è¿è¥ä¾§ï¼‰\\ç©å®¶å‘è¨€æ€»ç»“_ç‰ˆæœ¬æ€»ç»“(å¤šå¤©)\\test_top5.jsonl\n",
      "âœ… cwd: E:\\é¡¹ç›®\\ç©å®¶ç¤¾ç¾¤åˆ†ææ™ºèƒ½ä½“\\ç©å®¶å‘è¨€æ•´ç†ï¼ˆä¾›è¿è¥ä¾§ï¼‰\\ç©å®¶å‘è¨€æ€»ç»“_ç‰ˆæœ¬æ€»ç»“(å¤šå¤©)\n"
     ]
    }
   ],
   "source": [
    "path = Path(VERSION_TOP5_JSONL)\n",
    "print(\"âœ… writing to:\", path.resolve())\n",
    "print(\"âœ… cwd:\", Path.cwd().resolve())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c21a3780-7f85-4d6d-9204-8c05638c0080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(raw) = 20 len(read) = 20\n",
      "head raw ids  = ['2025-12-03_T01', '2025-12-02_T02', '2025-12-03_T03', '2025-12-03_T04', '2025-12-03_T05', '2025-12-04_T01', '2025-12-04_T02', '2025-12-04_T03', '2025-12-04_T04', '2025-12-04_T05']\n",
      "head read ids = ['2025-12-03_T01', '2025-12-02_T02', '2025-12-03_T03', '2025-12-03_T04', '2025-12-03_T05', '2025-12-04_T01', '2025-12-04_T02', '2025-12-04_T03', '2025-12-04_T04', '2025-12-04_T05']\n",
      "missing ids count = 0 extra ids count = 0\n",
      "missing ids head = []\n"
     ]
    }
   ],
   "source": [
    "daily_top5 = read_jsonl_file(DAILY_TOP5_PATH)\n",
    "\n",
    "def pick_id(r):\n",
    "    return (r.get(\"_daily_top_id\") or r.get(\"id\") or \"\").strip()\n",
    "\n",
    "ids_raw  = [pick_id(r) for r in daily_top5_raw]\n",
    "ids_read = [pick_id(r) for r in daily_top5]\n",
    "\n",
    "print(\"len(raw) =\", len(daily_top5_raw), \"len(read) =\", len(daily_top5))\n",
    "print(\"head raw ids  =\", ids_raw[:10])\n",
    "print(\"head read ids =\", ids_read[:10])\n",
    "\n",
    "missing = sorted(set(ids_raw) - set(ids_read))\n",
    "extra   = sorted(set(ids_read) - set(ids_raw))\n",
    "print(\"missing ids count =\", len(missing), \"extra ids count =\", len(extra))\n",
    "print(\"missing ids head =\", missing[:20])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e99015f-028b-4df0-b3f0-228f671cacfa",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## å¼€å§‹è¿è¡Œ(ä¸å¯åŠ¨ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f8c0e8-7351-43b6-9745-d0f23cea3be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å‡†å¤‡å¤„ç† 2308 æ¡ï¼Œå…± 8 æ‰¹ï¼ˆæ¯æ‰¹ 300 æ¡ï¼‰ã€‚\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ”¥ æ‰¹å¤„ç†è¿›åº¦:   0%|                                                                                                                                                       | 0/8 [06:33<?, ?æ‰¹/s]      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[æ‰¹æ¬¡ 1] æ¨¡å‹#1 ç­›åä¿ç•™ 240 æ¡\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ”¥ æ‰¹å¤„ç†è¿›åº¦:  12%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                                                                                            | 1/8 [12:29<48:22, 414.62s/æ‰¹]      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[æ‰¹æ¬¡ 2] æ¨¡å‹#1 ç­›åä¿ç•™ 206 æ¡\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ”¥ æ‰¹å¤„ç†è¿›åº¦:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                                                                          | 2/8 [20:44<38:45, 387.59s/æ‰¹]      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[æ‰¹æ¬¡ 3] æ¨¡å‹#1 ç­›åä¿ç•™ 283 æ¡\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ”¥ æ‰¹å¤„ç†è¿›åº¦:  38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                                        | 3/8 [21:22<36:31, 438.36s/æ‰¹]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# ... å‰ç½®ï¼šç³»ç»Ÿæç¤ºã€create_intent_excel_styled(EXCEL_FILE)ã€jsonl_lines01 ç­‰\n",
    "\n",
    "system_prompt01 = load_system_prompt(PROMPT_MD_PATH01)  # ç­›ç›¸å…³\n",
    "system_prompt02 = load_system_prompt(PROMPT_MD_PATH02)  # åšè¯æç°‡\n",
    "system_prompt03 = load_system_prompt(PROMPT_MD_PATH03)  # è¯é¢˜ç°‡èšåˆ / æ ¡æ­£ï¼ˆæ™ºèƒ½ä½“4ï¼‰\n",
    "system_prompt04 = load_system_prompt(PROMPT_MD_PATH04)  # è¯æç°‡ç©å®¶è§‚ç‚¹æ„Ÿå—åˆ†æ\n",
    "\n",
    "\n",
    "sub_opinion_map = {}\n",
    "# ç”¨äºå­˜æ”¾å½“å¤©æ‰€æœ‰æ‰¹æ¬¡çš„è¯é¢˜ç°‡ JSON è¡Œï¼ˆç»™æ™ºèƒ½ä½“4ç”¨ï¼‰\n",
    "batch_cluster_outputs  = []\n",
    "total = len(jsonl_lines01)\n",
    "if total == 0:\n",
    "    print(\"æ²¡æœ‰å¯å¤„ç†çš„æ•°æ®ã€‚\")\n",
    "else:\n",
    "    total_batches = (total + BATCH_SIZE - 1) // BATCH_SIZE\n",
    "    print(f\"å‡†å¤‡å¤„ç† {total} æ¡ï¼Œå…± {total_batches} æ‰¹ï¼ˆæ¯æ‰¹ {BATCH_SIZE} æ¡ï¼‰ã€‚\")\n",
    "\n",
    "written_total = 0\n",
    "\n",
    "for b in tqdm(range(total_batches), desc=\"ğŸ”¥ æ‰¹å¤„ç†è¿›åº¦\", unit=\"æ‰¹\"):\n",
    "    start = b * BATCH_SIZE\n",
    "    end = min(start + BATCH_SIZE, total)\n",
    "    batch_lines = jsonl_lines01[start:end]\n",
    "\n",
    "    try:\n",
    "        # --- æ¨¡å‹ #1ï¼šç­›ç›¸å…³ ---\n",
    "        user_prompt1 = build_user_prompt_filter(batch_lines)\n",
    "        output_filter = call_ark_chat_completions(\n",
    "            api_url=API_URL,\n",
    "            api_key=API_KEY,\n",
    "            model=V3_MODEL_ID,\n",
    "            system_prompt=system_prompt01,\n",
    "            user_prompt=user_prompt1,\n",
    "            temperature=TEMPERATURE,\n",
    "            max_tokens=MAX_TOKENS,\n",
    "            timeout=TIMEOUT_SEC,\n",
    "            retries=RETRIES,\n",
    "        )\n",
    "        \n",
    "        if not output_filter:\n",
    "            tqdm.write(f\"[æ‰¹æ¬¡ {b+1}] æ¨¡å‹#1 æ— æœ‰æ•ˆè¾“å‡ºï¼Œè·³è¿‡ã€‚\")\n",
    "            continue\n",
    "        filter_count = sum(1 for line in output_filter.splitlines() if line.strip())\n",
    "        tqdm.write(f\"[æ‰¹æ¬¡ {b+1}] æ¨¡å‹#1 ç­›åä¿ç•™ {filter_count} æ¡\")\n",
    "        written_total += filter_count   # å¦‚æœä¸éœ€è¦æ€»æ•°ï¼Œå¯ä»¥åˆ æ‰è¿™ä¸€è¡Œ\n",
    "        \n",
    "        # --- æ¨¡å‹ #2ï¼šè¯é¢˜ç°‡åˆ’åˆ† ---\n",
    "        user_prompt2 = build_user_prompt_clsuter(output_filter)\n",
    "        output_cluster = call_ark_chat_completions(\n",
    "            api_url=API_URL,\n",
    "            api_key=API_KEY,\n",
    "            model=V3_1_MODEL_ID,\n",
    "            system_prompt=system_prompt02,\n",
    "            user_prompt=user_prompt2,\n",
    "            temperature=TEMPERATURE,\n",
    "            max_tokens=MAX_TOKENS,\n",
    "            timeout=TIMEOUT_SEC,\n",
    "            retries=RETRIES,\n",
    "        )\n",
    "        \n",
    "        \n",
    "\n",
    "        if not output_cluster:\n",
    "            tqdm.write(f\"[æ‰¹æ¬¡ {b+1}] æ¨¡å‹#2 æ— æœ‰æ•ˆè¾“å‡ºï¼Œè·³è¿‡ã€‚\")\n",
    "            continue\n",
    "        try:\n",
    "            cluster_json_list = []\n",
    "            for line in output_cluster.strip().splitlines():\n",
    "                line = line.strip()\n",
    "                if not line.startswith(\"{\"):\n",
    "                    continue\n",
    "                obj = json.loads(line)\n",
    "                # å°† \"è¯é¢˜ç°‡1\" â†’ \"è¯é¢˜ç°‡\"ï¼Œä¾¿äºåç»­ç»Ÿä¸€å¤„ç†\n",
    "                for key in list(obj.keys()):\n",
    "                    if key.startswith(\"è¯é¢˜ç°‡\") and key != \"è¯é¢˜ç°‡\":\n",
    "                        obj[\"è¯é¢˜ç°‡\"] = obj.pop(key)\n",
    "                cluster_json_list.append(obj)\n",
    "\n",
    "            # å‡è®¾ä»è¾“å‡ºä¸­æ‹¿æ—¥æœŸ\n",
    "            date_str = infer_date_for_batch(cluster_json_list, batch_lines)  # ä½ å¯ä»¥ä»ä¸Šä¸‹æ–‡è·å¾—æ›´å‡†ç¡®å€¼\n",
    "            batch_id = f\"B{b+1}\"\n",
    "            cluster_json_list = assign_global_cluster_ids(cluster_json_list, date_str, batch_id)\n",
    "        \n",
    "            output_cluster_with_ids = \"\\n\".join(json.dumps(c, ensure_ascii=False) for c in cluster_json_list)\n",
    "            batch_cluster_outputs.append(output_cluster_with_ids)\n",
    "        except Exception as e:\n",
    "            tqdm.write(f\"[æ‰¹æ¬¡ {b+1}] âš  æ·»åŠ  _cluster_id å¤±è´¥ï¼š{e}\")\n",
    "            continue\n",
    "\n",
    "       \n",
    "       \n",
    "    except Exception as e:\n",
    "        tqdm.write(f\"[æ‰¹æ¬¡ {b+1}] âŒ å‡ºé”™ï¼š{e}\")\n",
    "        continue\n",
    "\n",
    "    time.sleep(SLEEP_BETWEEN)\n",
    "\n",
    "\n",
    "\n",
    "# --- æ¯æ—¥è¯æç°‡èšåˆæˆjsonl ---\n",
    "all_cluster = aggregate_cluster_outputs(batch_cluster_outputs)\n",
    "\n",
    "# --- æ¨¡å‹ #3ï¼šæ—¥è¯æç°‡èšåˆ ---\n",
    "user_prompt3 = build_user_prompt_cluster_agg(all_cluster)\n",
    "output_cluster_agg = call_ark_chat_completions(\n",
    "    api_url=API_URL,\n",
    "    api_key=API_KEY,\n",
    "    model=V3_1_MODEL_ID,           # æˆ–ä½ ç»™æ™ºèƒ½ä½“4é€‰çš„æ¨¡å‹\n",
    "    system_prompt=system_prompt03,  # è¯é¢˜ç°‡èšåˆ/æ ¡æ­£æç¤ºè¯\n",
    "    user_prompt=user_prompt3,\n",
    "    temperature=TEMPERATURE,\n",
    "    max_tokens=MAX_TOKENS,\n",
    "    timeout=TIMEOUT_SEC,\n",
    "    retries=RETRIES,\n",
    ")\n",
    "\n",
    "#æ¯æ—¥æ€»å‘è¨€è½¬å•æ¡jonslæ ¼å¼\n",
    "parsed_subclusters = [\n",
    "    json.loads(line.strip()) for line in all_cluster.strip().splitlines() if line.strip()\n",
    "]\n",
    "\n",
    "# è§£æåŸå§‹å‘è¨€ jsonlï¼Œä¸ºæŒ‰æ—¶é—´è½´ç­›é€‰å¯¹è¯ç”¨\n",
    "parsed_msgs = [json.loads(line.strip()) for line in jsonl_lines01 if line.strip()]\n",
    "\n",
    "#æ¯æ—¥èšåˆåè¯æç°‡è½¬å•æ¡jsonlæ ¼å¼\n",
    "parsed_clusters = [json.loads(line) for line in output_cluster_agg.strip().splitlines() if line.strip()]\n",
    "\n",
    "#è®¡ç®—æ¯æ—¥è®¨è®ºçƒ­åº¦top5\n",
    "top5_results = extract_top5_heat_clusters(parsed_clusters, jsonl_lines01, top_k=5)\n",
    "\n",
    "#######æå–å­è¯æç°‡è®¨è®ºç‚¹###########################################################\n",
    "####### å»ºå­ç°‡ç´¢å¼•ï¼š_cluster_id -> å­ç°‡å¯¹è±¡ ########\n",
    "sub_map = {}\n",
    "for row in parsed_subclusters:\n",
    "    cid = row.get(\"_cluster_id\")\n",
    "    if isinstance(cid, str) and cid:\n",
    "        sub_map[cid] = row\n",
    "\n",
    "####### åœ¨ Top5 å¾ªç¯é‡Œï¼Œå¯¹æ¯ä¸ªã€å­è¯é¢˜ç°‡ã€‘å•ç‹¬è·‘æ¨¡å‹#4 ########\n",
    "for cluster in top5_results:\n",
    "    date = cluster[\"æ—¥æœŸ\"]\n",
    "    # èšåˆç°‡çš„æ•´ä½“æ—¶é—´è½´ï¼ˆåªç”¨æ¥å…œåº•ï¼‰\n",
    "    cluster_time_axis = cluster[\"æ—¶é—´è½´\"]\n",
    "    cid_list = cluster.get(\"å­è¯é¢˜ç°‡åˆ—è¡¨\", [])\n",
    "\n",
    "    for cid in cid_list:\n",
    "        sub = sub_map.get(cid)\n",
    "        if not sub:\n",
    "            print(f\"\\n[èšåˆè¯é¢˜ç°‡ï¼š{cluster.get('èšåˆè¯é¢˜ç°‡')}] å­è¯é¢˜ç°‡ IDï¼š{cid}\")\n",
    "            print(\"  âš  åœ¨ sub_map / parsed_subclusters ä¸­æœªæ‰¾åˆ°è¯¥ _cluster_idã€‚\")\n",
    "            continue\n",
    "\n",
    "        \n",
    "        # ---- 1ï¼‰ä»å­è¯é¢˜ç°‡ã€æ ‡é¢˜ã€‘é‡Œæå–æ—¶é—´è½´ ----\n",
    "        sub_title = sub.get(\"è¯é¢˜ç°‡\", \"\") or \"\"\n",
    "        sub_time_axis = extract_time_axis_from_title(sub_title)\n",
    "\n",
    "        # ---- 2ï¼‰æŒ‰ã€å­è¯æç°‡æ—¶é—´è½´ã€‘ä»åŸå§‹å‘è¨€é‡ŒåŒ¹é… dialogs ----\n",
    "        dialogs = match_dialogs_by_time(parsed_msgs, date, sub_time_axis)\n",
    "\n",
    "        # ---- 3ï¼‰æ„é€  discussion_pointï¼ˆä¸æ‰“å°ï¼Œåªç”¨æ¥å†™ promptï¼‰----\n",
    "        discussion_point = (\n",
    "    \n",
    "            sub.get(\"æ ¸å¿ƒå¯¹è±¡/æœºåˆ¶\")\n",
    "            or sub.get(\"è¯é¢˜ç°‡\")\n",
    "            or \"\"\n",
    "        )\n",
    "        topic_id = sub.get(\"_cluster_id\", cid)\n",
    "        \n",
    "        # ---- 4ï¼‰æ¨¡å‹4 ç©å®¶å‘è¨€æ„Ÿå—åˆ†ææ€»ç»“----\n",
    "        user_prompt4 = build_user_prompt_subcluster_opinion(\n",
    "            topic_id=topic_id,\n",
    "            discussion_point=discussion_point,\n",
    "            dialogs=dialogs,\n",
    "        )\n",
    "        if not isinstance(user_prompt4, str) or not user_prompt4.strip():\n",
    "            print(f\"  âš  user_prompt4 ä¸ºç©ºæˆ–éæ³•ï¼Œè·³è¿‡æœ¬å­è¯é¢˜ç°‡ï¼š{cid}\")\n",
    "            continue\n",
    "        opinion_output = call_ark_chat_completions(\n",
    "            api_url=API_URL,\n",
    "            api_key=API_KEY,\n",
    "            model=V3_1_MODEL_ID,             \n",
    "            system_prompt=system_prompt04,   \n",
    "            user_prompt=user_prompt4,\n",
    "            temperature=TEMPERATURE,\n",
    "            max_tokens=MAX_TOKENS,\n",
    "            timeout=TIMEOUT_SEC,\n",
    "            retries=RETRIES,\n",
    "        )\n",
    "\n",
    "\n",
    "       \n",
    "    opinion_obj = parse_and_normalize_opinion_output(\n",
    "        opinion_output=opinion_output,\n",
    "        topic_id=topic_id,\n",
    "        discussion_point=discussion_point,\n",
    "    )\n",
    "    sub_opinion_map[topic_id] = opinion_obj\n",
    "# ===================================\n",
    "# ç»„è£… Top5 + è§‚ç‚¹æ€»ç»“ï¼Œå¹¶å†™å…¥ jsonl\n",
    "# ===================================\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ada78d16-fe72-4a92-94d2-8b626ef64d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… å·²å°†å½“æ—¥ Top5ï¼ˆå« _idx å’Œ _daily_top_idï¼‰è¿½åŠ å†™å…¥: version_daily_top5_with_opinion.jsonl\n"
     ]
    }
   ],
   "source": [
    "final_top5_with_opinion = build_daily_top5_opinion_records(\n",
    "    top5_results=top5_results,\n",
    "    sub_opinion_map=sub_opinion_map,\n",
    ")\n",
    "\n",
    "append_daily_top5_to_version_jsonl(\n",
    "    final_result=final_top5_with_opinion,\n",
    "    version_jsonl_path=\"version_daily_top5_with_opinion.jsonl\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dfa2bb40-0ca1-4558-a350-06dbc11c2e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2025-12-02_B1_03', '2025-12-02_B1_14', '2025-12-02_B2_07']\n",
      "{'è¯é¢˜ç°‡': 'æ¸¸æˆç‰©å“å¼‚å¸¸é—®é¢˜åé¦ˆï¼ˆ2025-12-02 22:57:27-22:57:31ï¼‰', 'æ ¸å¿ƒå¯¹è±¡/æœºåˆ¶': 'æ¸¸æˆå†…ç‰©å“å¼‚å¸¸æ¶ˆå¤±é—®é¢˜çš„åé¦ˆä¸å¤„ç†', '_cluster_id': '2025-12-02_B2_07'}\n",
      "æ¸¸æˆç‰©å“å¼‚å¸¸é—®é¢˜åé¦ˆï¼ˆ2025-12-02 22:57:27-22:57:31ï¼‰\n",
      "22:57:27-22:57:31\n",
      "æ¸¸æˆå†…ç‰©å“å¼‚å¸¸æ¶ˆå¤±é—®é¢˜çš„åé¦ˆä¸å¤„ç†\n",
      "[{'å‘è¨€æ—¥æœŸ': '2025-12-02', 'å‘è¨€æ—¶é—´': '22:57:27', 'ç©å®¶ID': 'æ— ä¸ºæ— ç•(2514177080)', 'ç©å®¶æ¶ˆæ¯': '[å›¾ç‰‡]'}, {'å‘è¨€æ—¥æœŸ': '2025-12-02', 'å‘è¨€æ—¶é—´': '22:57:31', 'ç©å®¶ID': 'æ— ä¸ºæ— ç•(2514177080)', 'ç©å®¶æ¶ˆæ¯': 'ä¸œè¥¿æ²¡äº†'}]\n",
      "2025-12-02_B2_07\n"
     ]
    }
   ],
   "source": [
    "print(cid_list)\n",
    "print(sub)\n",
    "\n",
    "print(sub_title)\n",
    "print(sub_time_axis)\n",
    "print(discussion_point)\n",
    "print(dialogs)\n",
    "print(cid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21cb4444-2eeb-41e2-9797-1d5eeb074f05",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'opinion_output' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(opinion_output)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'opinion_output' is not defined"
     ]
    }
   ],
   "source": [
    "print(opinion_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "34e8df2c-b759-4281-9782-4a53a6602c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(sub_time_axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385e4733-358c-46e0-91ef-5d86f7da4e12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
