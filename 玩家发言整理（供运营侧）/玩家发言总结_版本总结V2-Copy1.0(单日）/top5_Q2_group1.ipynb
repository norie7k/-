{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a270f7e-1cbc-488e-b78b-d113cf2b2146",
   "metadata": {},
   "source": [
    "## æ•°æ®å¤„ç†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcb45d8-1ccc-4600-b1fb-9e30f9b83c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "from typing import List, Union, Optional\n",
    "from datetime import datetime\n",
    "\n",
    "import os, re, json, time\n",
    "import typing as T\n",
    "import requests\n",
    "\n",
    "from pathlib import Path\n",
    "from openpyxl import Workbook, load_workbook\n",
    "\n",
    "from openpyxl.utils import get_column_letter\n",
    "from openpyxl.utils import get_column_letter\n",
    "from openpyxl.styles import Font, Alignment, Border, Side, PatternFill\n",
    "from data_processing import load_and_process,build_jsonl_for_range, save_jsonl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f289cc4f-5fbb-4e00-bf55-1bd0fe391231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1784 lines\n",
      "{\"å‘è¨€æ—¥æœŸ\": \"2025-12-17\", \"å‘è¨€æ—¶é—´\": \"00:07:29\", \"ç©å®¶ID\": \"å°æ›¦(945058553)\", \"ç©å®¶æ¶ˆæ¯\": \"@é’ç“·å®¢æœ-è¥¿æŸ  è¥¿å¼Ÿ\"}\n"
     ]
    }
   ],
   "source": [
    "## ç ”å‘å­—å…¸\n",
    "speaker_map = {\n",
    "    \"16186514\":   \"peteræœ¬å°Š\",\n",
    "    \"1655611808\": \"è¿è¥ç»¾ç»¾\",\n",
    "    \"2073820674\": \"æ²™åˆ©æ–‡è€å¸ˆ\",\n",
    "    \"2726067525\": \"milissa\",\n",
    "}\n",
    "## å®¢æœå­—å…¸\n",
    "MAPPING_FILE = \"mappingåœ°çƒ1.xlsx\"\n",
    "\n",
    "##QQçš„txtæ–‡ä»¶\n",
    "pathtxt   = \"1219ã€Šæ¬¢è¿æ¥åˆ°åœ°çƒã€‹æµ‹è¯•1ç¾¤.txt\"\n",
    "\n",
    "# è®¾å®šæ—¶é—´èŒƒå›´\n",
    "start_time = \"2025-12-16 00:00:00\"\n",
    "end_time   = \"2025-12-17 00:00:00\"\n",
    "\n",
    "\n",
    "# 1) æ‹¿åˆ° JSONLï¼ˆåˆ—è¡¨ï¼‰\n",
    "jsonl_lines01 = build_jsonl_for_range(\n",
    "    pathtxt=pathtxt,\n",
    "    mapping_file=MAPPING_FILE,\n",
    "    speaker_map=speaker_map,\n",
    "    start_time=start_time,\n",
    "    end_time=end_time,\n",
    "    return_str=False,   # è¿”å› list[str]\n",
    ")\n",
    "\n",
    "print(len(jsonl_lines01), \"lines\")\n",
    "print(jsonl_lines01[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840c1e89-cc08-4532-bc6b-1842742fce13",
   "metadata": {},
   "source": [
    "## å¤§æ¨¡å‹åˆ†ç±»"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d8e640-2974-47ea-a008-6c08e71b46bd",
   "metadata": {},
   "source": [
    "## å®šä¹‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e952a6ae-48c3-49f3-9b91-d867f416c4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "æ‰¹å¤„ç† 10000 æ¡èŠå¤©æ•°æ®ï¼ˆæ¯æ‰¹ 100 æ¡ï¼‰ï¼š\n",
    "- æ¨¡å‹#1ï¼šè¿‡æ»¤éæ¸¸æˆç›¸å…³ï¼ˆåªä¿ç•™ç›¸å…³ JSON è¡Œï¼ŒåŸæ ·è¾“å‡ºï¼‰\n",
    "- æ¨¡å‹#2ï¼šæå–é«˜è®¨è®ºçš„å‘è¨€å¹¶åˆ†æ\n",
    "- ç»“æœæŒ‰wordæ ¼å¼æ–‡æ¡£è¾“å‡º\n",
    "\"\"\"\n",
    "from model_classifyV1_Copy1_Copy1 import (\n",
    "    load_system_prompt,\n",
    "    build_user_prompt_filter,build_user_prompt_clsuter,call_ark_chat_completions,\n",
    "    extract_valid_json_lines,add_index_to_jsonl_lines,count_output_filter_stats,get_covered_indices_from_cluster_output,\n",
    "    aggregate_cluster_outputs,build_user_prompt_cluster_agg,assign_global_cluster_ids,\n",
    "    extract_top5_heat_clusters,attach_discussion_points,extract_cluster_stats,append_daily_top5_to_version_jsonl,infer_date_for_batch,\n",
    "    build_user_prompt_subcluster_opinion,\n",
    "    print_mech_time_from_top5,get_dialogs_lines_by_fayan_time_debug,merge_top5_with_opinions_numbered,parse_opinion_output_to_list,\n",
    "    ensure_time_axis_key,ensure_subcluster_list_key,match_dialogs_by_time, parse_jsonl_text,parse_model2_output_to_json_list,parse_jsonl_text_safe\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b7b9c0-b495-4640-b7d1-2c31ef371d3d",
   "metadata": {},
   "source": [
    "## è®¾ç½®å‚æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70d36c9f-a439-4597-b52a-ca091439031b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============= ä½ çš„æ¨¡å‹ä¸æ–‡ä»¶é…ç½®ï¼ˆæ”¹è¿™é‡Œï¼‰ =============\n",
    "API_URL   = \"https://ark.cn-beijing.volces.com/api/v3/chat/completions\" \n",
    "API_KEY = \"de91deb0-aae6-46cb-bac0-17ac3b6107f5\" #API\n",
    "V3_MODEL_ID= \"ep-20251020160142-5d7hp\"#æ¥å…¥ç‚¹\n",
    "V3_1_MODEL_ID = \"ep-20251020160025-9p5tj\"#æ¥å…¥ç‚¹\n",
    "R1_MODEL_ID = \"ep-20251020160103-5n6g2\"#æ¥å…¥ç‚¹\n",
    "\n",
    "PROMPT_MD_PATH01 = Path(\"æç¤ºè¯1.md\") # æ¨¡å‹#1 system æç¤ºè¯ï¼ˆç­›ç›¸å…³ï¼‰\n",
    "PROMPT_MD_PATH02 = Path(\"2è¯é¢˜åˆ†ç±».md\") # æ¨¡å‹#2 system æç¤ºè¯ï¼ˆåˆ†è¯é¢˜ï¼‰\n",
    "PROMPT_MD_PATH03 = Path(\"3æ—¥èšåˆ.md\") # æ¨¡å‹#3 system æç¤ºè¯ï¼ˆæ—¥èšåˆï¼‰\n",
    "PROMPT_MD_PATH04 = Path(\"2è¯é¢˜åˆ†ç±»å’Œæ€»ç»“.md\") #æ¨¡å‹#4 system æç¤ºè¯ï¼ˆè§‚ç‚¹åˆ†æï¼‰\n",
    "VERSION_TOP5_JSONL = \"test_1207.jsonl\"\n",
    "BATCH_SIZE       = 300\n",
    "SLEEP_BETWEEN    = 1   # æ¯æ‰¹ä¹‹é—´çš„é—´éš”ï¼Œé˜²æ­¢QPSè§¦å‘é™æµï¼›æŒ‰éœ€è°ƒæ•´\n",
    "RETRIES          = 2\n",
    "TEMPERATURE      = 0.20\n",
    "MAX_TOKENS       = 16384\n",
    "TIMEOUT_SEC      = 600\n",
    "# ====================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3b2dc1-1a41-4ca6-9959-cccbb22adb86",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 1.æ£€éªŒæ¯æ—¥è¯æç°‡åˆ†ç±»è¾“å‡º"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5465d2eb-915e-4133-a3dd-485de2d48577",
   "metadata": {},
   "source": [
    "## åŠ è®¨è®ºè§‚ç‚¹åˆ†æçš„ç‰ˆæœ¬æµ‹è¯•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411f43b3-eb1e-4fff-9e58-f758a3848262",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å‡†å¤‡å¤„ç† 1784 æ¡ï¼Œå…± 6 æ‰¹ï¼ˆæ¯æ‰¹ 300 æ¡ï¼‰ã€‚\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ”¥ æ‰¹å¤„ç†è¿›åº¦:   0%|                                                                                 | 0/6 [02:52<?, ?æ‰¹/s]      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[æ‰¹æ¬¡ 1] æ¨¡å‹#1 ç­›åä¿ç•™ 107 æ¡\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ”¥ æ‰¹å¤„ç†è¿›åº¦:  17%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                            | 1/6 [03:12<16:04, 192.87s/æ‰¹]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# --- å‰ç½®ï¼šç³»ç»Ÿæç¤ºã€åˆå§‹åŒ–ç­‰ ---\n",
    "system_prompt01 = load_system_prompt(PROMPT_MD_PATH01)  # ç­›ç›¸å…³\n",
    "system_prompt02 = load_system_prompt(PROMPT_MD_PATH02)  # åšè¯æç°‡\n",
    "system_prompt03 = load_system_prompt(PROMPT_MD_PATH03)  # æ—¥è¯é¢˜ç°‡èšåˆ\n",
    "system_prompt04 = load_system_prompt(PROMPT_MD_PATH04)  # ç©å®¶è§‚ç‚¹åˆ†æï¼ˆæ¨¡å‹4ï¼‰\n",
    "\n",
    "batch_cluster_outputs = []   # æ¨¡å‹2æ‰€æœ‰æ‰¹æ¬¡ç°‡ï¼Œç”¨äºæ—¥èšåˆ\n",
    "all_opinions = []            # æ¨¡å‹4è§‚ç‚¹ç»“æœæ±‡æ€»\n",
    "\n",
    "total = len(jsonl_lines01)\n",
    "if total == 0:\n",
    "    print(\"æ²¡æœ‰å¯å¤„ç†çš„æ•°æ®ã€‚\")\n",
    "else:\n",
    "    total_batches = (total + BATCH_SIZE - 1) // BATCH_SIZE\n",
    "    print(f\"å‡†å¤‡å¤„ç† {total} æ¡ï¼Œå…± {total_batches} æ‰¹ï¼ˆæ¯æ‰¹ {BATCH_SIZE} æ¡ï¼‰ã€‚\")\n",
    "\n",
    "written_total = 0\n",
    "\n",
    "# ====================================================\n",
    "# æ¨¡å‹ #1 + æ¨¡å‹ #2ï¼šç­›ç›¸å…³ + è¯é¢˜ç°‡åˆ’åˆ†\n",
    "# ====================================================\n",
    "for b in tqdm(range(total_batches), desc=\"ğŸ”¥ æ‰¹å¤„ç†è¿›åº¦\", unit=\"æ‰¹\"):\n",
    "    start = b * BATCH_SIZE\n",
    "    end = min(start + BATCH_SIZE, total)\n",
    "    batch_lines = jsonl_lines01[start:end]\n",
    "\n",
    "    try:\n",
    "        # --- æ¨¡å‹ #1ï¼šç­›ç›¸å…³ ---\n",
    "        user_prompt1 = build_user_prompt_filter(batch_lines)\n",
    "        output_filter = call_ark_chat_completions(\n",
    "            api_url=API_URL,\n",
    "            api_key=API_KEY,\n",
    "            model=V3_MODEL_ID,\n",
    "            system_prompt=system_prompt01,\n",
    "            user_prompt=user_prompt1,\n",
    "            temperature=TEMPERATURE,\n",
    "            max_tokens=MAX_TOKENS,\n",
    "            timeout=TIMEOUT_SEC,\n",
    "            retries=RETRIES,\n",
    "        )\n",
    "        \n",
    "        if not output_filter:\n",
    "            tqdm.write(f\"[æ‰¹æ¬¡ {b+1}] æ¨¡å‹#1 æ— æœ‰æ•ˆè¾“å‡ºï¼Œè·³è¿‡ã€‚\")\n",
    "            continue\n",
    "\n",
    "        filter_count = sum(1 for line in output_filter.splitlines() if line.strip())\n",
    "        tqdm.write(f\"[æ‰¹æ¬¡ {b+1}] æ¨¡å‹#1 ç­›åä¿ç•™ {filter_count} æ¡\")\n",
    "        written_total += filter_count\n",
    "\n",
    "        # --- æ¨¡å‹ #2ï¼šè¯é¢˜ç°‡åˆ’åˆ† ---\n",
    "        user_prompt2 = build_user_prompt_clsuter(output_filter)\n",
    "        output_cluster = call_ark_chat_completions(\n",
    "            api_url=API_URL,\n",
    "            api_key=API_KEY,\n",
    "            model=V3_1_MODEL_ID,\n",
    "            system_prompt=system_prompt02,\n",
    "            user_prompt=user_prompt2,\n",
    "            temperature=TEMPERATURE,\n",
    "            max_tokens=MAX_TOKENS,\n",
    "            timeout=TIMEOUT_SEC,\n",
    "            retries=RETRIES,\n",
    "        )\n",
    "\n",
    "        if not output_cluster:\n",
    "            tqdm.write(f\"[æ‰¹æ¬¡ {b+1}] æ¨¡å‹#2 æ— æœ‰æ•ˆè¾“å‡ºï¼Œè·³è¿‡ã€‚\")\n",
    "            continue\n",
    "\n",
    "       # ---------- âœ… æ–°çš„ JSON è§£æ + _cluster_id éƒ¨åˆ† ----------\n",
    "        try:\n",
    "            # 1) å…ˆç”¨ä¿®å¤è§£æå™¨ï¼ŒæŠŠæ¨¡å‹#2è¾“å‡ºå˜æˆ list[dict]\n",
    "            cluster_json_list = parse_model2_output_to_json_list(\n",
    "                output_cluster,\n",
    "                batch_idx=b+1,\n",
    "            )\n",
    "\n",
    "            if not cluster_json_list:\n",
    "                tqdm.write(f\"[æ‰¹æ¬¡ {b+1}] âš  æœ¬æ‰¹æ¬¡æœªè§£æå‡ºä»»ä½•åˆæ³• JSON å¯¹è±¡ï¼Œè·³è¿‡ã€‚\")\n",
    "                continue\n",
    "\n",
    "            # 2) ä»è¯¥æ‰¹æ¬¡ä¸­æ¨æ–­æ—¥æœŸï¼ˆä½ è‡ªå·±çš„é€»è¾‘ï¼‰\n",
    "            date_str = infer_date_for_batch(cluster_json_list, batch_lines)\n",
    "            batch_id = f\"B{b+1}\"\n",
    "\n",
    "            # 3) åˆ†é…å…¨å±€ _cluster_idï¼šæ—¥æœŸ + æ‰¹æ¬¡å· + åºå· ...\n",
    "            cluster_json_list = assign_global_cluster_ids(\n",
    "                cluster_json_list,\n",
    "                date_str,\n",
    "                batch_id,\n",
    "            )\n",
    "\n",
    "            # 4) å†è½¬æˆ jsonl æ–‡æœ¬ï¼ˆä¾›åç»­ aggregate_cluster_outputs ä½¿ç”¨ï¼‰\n",
    "            output_cluster_with_ids = \"\\n\".join(\n",
    "                json.dumps(c, ensure_ascii=False) for c in cluster_json_list\n",
    "            )\n",
    "            batch_cluster_outputs.append(output_cluster_with_ids)\n",
    "\n",
    "        except Exception as e:\n",
    "            tqdm.write(f\"[æ‰¹æ¬¡ {b+1}] âš  æ·»åŠ  _cluster_id å¤±è´¥ï¼š{e}\")\n",
    "            continue\n",
    "        # ---------- JSON è§£æéƒ¨åˆ†ç»“æŸ ----------\n",
    "\n",
    "    except Exception as e:\n",
    "        tqdm.write(f\"[æ‰¹æ¬¡ {b+1}] âŒ å‡ºé”™ï¼š{e}\")\n",
    "        continue\n",
    "\n",
    "    time.sleep(SLEEP_BETWEEN)\n",
    "            \n",
    "\n",
    "\n",
    "# ====================================================\n",
    "# æ¨¡å‹ #3ï¼šæ—¥è¯é¢˜ç°‡èšåˆ & Top5\n",
    "# ====================================================\n",
    "\n",
    "# --- èšåˆå½“å¤©æ‰€æœ‰æ‰¹æ¬¡çš„è¯é¢˜ç°‡ jsonl ---\n",
    "all_cluster = aggregate_cluster_outputs(batch_cluster_outputs)\n",
    "\n",
    "# --- æ¨¡å‹ #3ï¼šæ—¥è¯é¢˜ç°‡èšåˆ ---\n",
    "user_prompt3 = build_user_prompt_cluster_agg(all_cluster)\n",
    "output_cluster_agg = call_ark_chat_completions(\n",
    "    api_url=API_URL,\n",
    "    api_key=API_KEY,\n",
    "    model=V3_1_MODEL_ID,\n",
    "    system_prompt=system_prompt03,\n",
    "    user_prompt=user_prompt3,\n",
    "    temperature=TEMPERATURE,\n",
    "    max_tokens=MAX_TOKENS,\n",
    "    timeout=TIMEOUT_SEC,\n",
    "    retries=RETRIES,\n",
    ")\n",
    "\n",
    "# èšåˆç°‡ï¼ˆæ¨¡å‹#3 è¾“å‡ºï¼‰\n",
    "parsed_clusters = parse_jsonl_text_safe(output_cluster_agg, label=\"æ¨¡å‹#3èšåˆè¾“å‡º\")\n",
    "# å­è¯é¢˜ç°‡ï¼ˆæ¨¡å‹#2 è¾“å‡ºåˆå¹¶åçš„ all_clusterï¼‰\n",
    "parsed_subclusters = parse_jsonl_text(all_cluster)\n",
    "\n",
    "# å…œåº•ä¿® keyï¼ˆæ—¶é—´è½´ / å­è¯é¢˜ç°‡åˆ—è¡¨ï¼‰\n",
    "fixed_cnt = 0\n",
    "fixed_sub_cnt = 0\n",
    "for c in parsed_clusters:\n",
    "    if ensure_time_axis_key(c, verbose=False):\n",
    "        fixed_cnt += 1\n",
    "    if ensure_subcluster_list_key(c):\n",
    "        fixed_sub_cnt += 1\n",
    "print(f\"âœ… å·²è‡ªåŠ¨è¡¥é½/ä¿®å¤ æ—¶é—´è½´ çš„èšåˆç°‡æ•°é‡ï¼š{fixed_cnt}\")\n",
    "print(f\"âœ… å·²è‡ªåŠ¨è¡¥é½/ä¿®å¤ å­è¯é¢˜ç°‡åˆ—è¡¨ çš„èšåˆç°‡æ•°é‡ï¼š{fixed_sub_cnt}\")\n",
    "\n",
    "# è®¡ç®—æ¯æ—¥è®¨è®ºçƒ­åº¦ Top5\n",
    "top5_results = extract_top5_heat_clusters(parsed_clusters, jsonl_lines01, top_k=5)\n",
    "final_result = attach_discussion_points(top5_results, parsed_subclusters)\n",
    "\n",
    "# ====================================================\n",
    "# æ¨¡å‹ #4ï¼šæ ¹æ® Top5 å›æº¯åŸæ–‡ï¼Œåšè§‚ç‚¹å…±è¯†åˆ†æ\n",
    "# ====================================================\n",
    "\n",
    "rows = print_mech_time_from_top5(final_result, all_cluster)  # è¾“å‡ºå« æ ¸å¿ƒå¯¹è±¡/æœºåˆ¶ + å‘è¨€æ—¶é—´\n",
    "\n",
    "all_opinions = []\n",
    "\n",
    "for idx, r in enumerate(rows, start=1):\n",
    "    mech = r.get(\"æ ¸å¿ƒå¯¹è±¡/æœºåˆ¶\") or \"\"\n",
    "    full_time = (r.get(\"å‘è¨€æ—¶é—´\") or \"\").strip()\n",
    "\n",
    "    if not mech or not full_time:\n",
    "        print(f\"âš  ç¬¬ {idx} æ¡ç¼ºå°‘ æ ¸å¿ƒå¯¹è±¡/æœºåˆ¶ æˆ– å‘è¨€æ—¶é—´ï¼ŒåŸå§‹è¡Œï¼š{r}\")\n",
    "        continue\n",
    "\n",
    "    # full_time å½¢å¦‚ï¼š\"2025-12-02 14:01:57-14:42:21\"\n",
    "    if \" \" not in full_time:\n",
    "        print(f\"âš  ç¬¬ {idx} æ¡å‘è¨€æ—¶é—´æ ¼å¼å¼‚å¸¸ï¼Œæ— æ³•æ‹†åˆ†æ—¥æœŸå’Œæ—¶é—´è½´ï¼š{full_time}\")\n",
    "        continue\n",
    "\n",
    "    fayan_date, fayan_time = full_time.split(\" \", 1)\n",
    "\n",
    "    dialogs_lines = get_dialogs_lines_by_fayan_time_debug(\n",
    "        jsonl_lines01,\n",
    "        fayan_date,\n",
    "        fayan_time,\n",
    "        debug=True,\n",
    "    )\n",
    "\n",
    "    if not dialogs_lines:\n",
    "        print(f\"âš  è¯¥æ—¶é—´æ®µå†…æ²¡æœ‰åŸæ–‡ï¼Œè·³è¿‡ï¼š{mech} | {fayan_date} {fayan_time}\")\n",
    "        continue\n",
    "\n",
    "    # --- æ¨¡å‹ #4ï¼šåˆ†æç©å®¶å…±è¯† ---\n",
    "    user_prompt4 = build_user_prompt_subcluster_opinion(\n",
    "        discussion_point=mech,\n",
    "        json_lines=dialogs_lines,\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        opinion_output = call_ark_chat_completions(\n",
    "            api_url=API_URL,\n",
    "            api_key=API_KEY,\n",
    "            model=V3_1_MODEL_ID,\n",
    "            system_prompt=system_prompt04,\n",
    "            user_prompt=user_prompt4,\n",
    "            temperature=TEMPERATURE,\n",
    "            max_tokens=MAX_TOKENS,\n",
    "            timeout=TIMEOUT_SEC,\n",
    "            retries=RETRIES,\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(\"âŒ è°ƒç”¨æ¨¡å‹4å‡ºé”™:\", e)\n",
    "        continue\n",
    "\n",
    "    opinions_this_mech = parse_opinion_output_to_list(opinion_output)\n",
    "    all_opinions.extend(opinions_this_mech)\n",
    "\n",
    "# åˆå¹¶æ¨¡å‹4è§‚ç‚¹ç»“æœå› Top5\n",
    "merged_top5 = merge_top5_with_opinions_numbered(final_result, all_opinions)\n",
    "\n",
    "for row in merged_top5:\n",
    "    print(json.dumps(row, ensure_ascii=False, indent=2))\n",
    "\n",
    "# å¦‚è¦æŠŠå¸¦è§‚ç‚¹ç‰ˆå†™å…¥ç‰ˆæœ¬ jsonlï¼Œå¯ä»¥ç”¨ merged_top5ï¼›å¦‚æœåªè¦çƒ­åº¦+è®¨è®ºç‚¹ï¼Œå°±ç”¨ final_result\n",
    "# append_daily_top5_to_version_jsonl(\n",
    "#     merged_top5,\n",
    "#     version_jsonl_path=VERSION_TOP5_JSONL\n",
    "# )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
