{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a270f7e-1cbc-488e-b78b-d113cf2b2146",
   "metadata": {},
   "source": [
    "## æ•°æ®å¤„ç†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bcb45d8-1ccc-4600-b1fb-9e30f9b83c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "from typing import List, Union, Optional\n",
    "from datetime import datetime\n",
    "\n",
    "import os, re, json, time\n",
    "import typing as T\n",
    "import requests\n",
    "\n",
    "from pathlib import Path\n",
    "from openpyxl import Workbook, load_workbook\n",
    "\n",
    "from openpyxl.utils import get_column_letter\n",
    "from openpyxl.utils import get_column_letter\n",
    "from openpyxl.styles import Font, Alignment, Border, Side, PatternFill\n",
    "from data_processing import load_and_process,build_jsonl_for_range, save_jsonl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f289cc4f-5fbb-4e00-bf55-1bd0fe391231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1784 lines\n",
      "{\"å‘è¨€æ—¥æœŸ\": \"2025-12-17\", \"å‘è¨€æ—¶é—´\": \"00:07:29\", \"ç©å®¶ID\": \"å°æ›¦(945058553)\", \"ç©å®¶æ¶ˆæ¯\": \"@é’ç“·å®¢æœ-è¥¿æŸ  è¥¿å¼Ÿ\"}\n"
     ]
    }
   ],
   "source": [
    "## ç ”å‘å­—å…¸\n",
    "speaker_map = {\n",
    "    \"16186514\":   \"peteræœ¬å°Š\",\n",
    "    \"1655611808\": \"è¿è¥ç»¾ç»¾\",\n",
    "    \"2073820674\": \"æ²™åˆ©æ–‡è€å¸ˆ\",\n",
    "    \"2726067525\": \"milissa\",\n",
    "}\n",
    "## å®¢æœå­—å…¸\n",
    "MAPPING_FILE = \"mappingåœ°çƒ1.xlsx\"\n",
    "\n",
    "##QQçš„txtæ–‡ä»¶\n",
    "pathtxt   = \"1218ã€Šæ¬¢è¿æ¥åˆ°åœ°çƒã€‹æµ‹è¯•1ç¾¤.txt\"\n",
    "\n",
    "# è®¾å®šæ—¶é—´èŒƒå›´\n",
    "start_time = \"2025-12-17 00:00:00\"\n",
    "end_time   = \"2025-12-18 00:00:00\"\n",
    "\n",
    "\n",
    "# 1) æ‹¿åˆ° JSONLï¼ˆåˆ—è¡¨ï¼‰\n",
    "jsonl_lines01 = build_jsonl_for_range(\n",
    "    pathtxt=pathtxt,\n",
    "    mapping_file=MAPPING_FILE,\n",
    "    speaker_map=speaker_map,\n",
    "    start_time=start_time,\n",
    "    end_time=end_time,\n",
    "    return_str=False,   # è¿”å› list[str]\n",
    ")\n",
    "\n",
    "print(len(jsonl_lines01), \"lines\")\n",
    "print(jsonl_lines01[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840c1e89-cc08-4532-bc6b-1842742fce13",
   "metadata": {},
   "source": [
    "## å¤§æ¨¡å‹åˆ†ç±»"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d8e640-2974-47ea-a008-6c08e71b46bd",
   "metadata": {},
   "source": [
    "## å®šä¹‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e952a6ae-48c3-49f3-9b91-d867f416c4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "æ‰¹å¤„ç† 10000 æ¡èŠå¤©æ•°æ®ï¼ˆæ¯æ‰¹ 100 æ¡ï¼‰ï¼š\n",
    "- æ¨¡å‹#1ï¼šè¿‡æ»¤éæ¸¸æˆç›¸å…³ï¼ˆåªä¿ç•™ç›¸å…³ JSON è¡Œï¼ŒåŸæ ·è¾“å‡ºï¼‰\n",
    "- æ¨¡å‹#2ï¼šæå–é«˜è®¨è®ºçš„å‘è¨€å¹¶åˆ†æ\n",
    "- ç»“æœæŒ‰wordæ ¼å¼æ–‡æ¡£è¾“å‡º\n",
    "\"\"\"\n",
    "from model_classifyV1_Copy1_Copy1 import (\n",
    "    load_system_prompt,\n",
    "    build_user_prompt_filter,build_user_prompt_clsuter,call_ark_chat_completions,\n",
    "    extract_valid_json_lines,add_index_to_jsonl_lines,count_output_filter_stats,get_covered_indices_from_cluster_output,\n",
    "    aggregate_cluster_outputs,build_user_prompt_cluster_agg,assign_global_cluster_ids,\n",
    "    extract_top5_heat_clusters,attach_discussion_points,extract_cluster_stats,append_daily_top5_to_version_jsonl,infer_date_for_batch,\n",
    "    build_user_prompt_subcluster_opinion,\n",
    "    print_mech_time_from_top5,get_dialogs_lines_by_fayan_time_debug,merge_top5_with_opinions_numbered,parse_opinion_output_to_list,\n",
    "    ensure_time_axis_key,ensure_subcluster_list_key,match_dialogs_by_time, parse_jsonl_text\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b7b9c0-b495-4640-b7d1-2c31ef371d3d",
   "metadata": {},
   "source": [
    "## è®¾ç½®å‚æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70d36c9f-a439-4597-b52a-ca091439031b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============= ä½ çš„æ¨¡å‹ä¸æ–‡ä»¶é…ç½®ï¼ˆæ”¹è¿™é‡Œï¼‰ =============\n",
    "API_URL   = \"https://ark.cn-beijing.volces.com/api/v3/chat/completions\" \n",
    "API_KEY = \"de91deb0-aae6-46cb-bac0-17ac3b6107f5\" #API\n",
    "V3_MODEL_ID= \"ep-20251020160142-5d7hp\"#æ¥å…¥ç‚¹\n",
    "V3_1_MODEL_ID = \"ep-20251020160025-9p5tj\"#æ¥å…¥ç‚¹\n",
    "R1_MODEL_ID = \"ep-20251020160103-5n6g2\"#æ¥å…¥ç‚¹\n",
    "\n",
    "PROMPT_MD_PATH01 = Path(\"æç¤ºè¯1.md\") # æ¨¡å‹#1 system æç¤ºè¯ï¼ˆç­›ç›¸å…³ï¼‰\n",
    "PROMPT_MD_PATH02 = Path(\"2è¯é¢˜åˆ†ç±».md\") # æ¨¡å‹#2 system æç¤ºè¯ï¼ˆåˆ†è¯é¢˜ï¼‰\n",
    "PROMPT_MD_PATH03 = Path(\"3æ—¥èšåˆ.md\") # æ¨¡å‹#3 system æç¤ºè¯ï¼ˆæ—¥èšåˆï¼‰\n",
    "PROMPT_MD_PATH04 = Path(\"2è¯é¢˜åˆ†ç±»å’Œæ€»ç»“.md\") #æ¨¡å‹#4 system æç¤ºè¯ï¼ˆè§‚ç‚¹åˆ†æï¼‰\n",
    "VERSION_TOP5_JSONL = \"version_daily_top5_with_opinion.jsonl\"\n",
    "BATCH_SIZE       = 300\n",
    "SLEEP_BETWEEN    = 1   # æ¯æ‰¹ä¹‹é—´çš„é—´éš”ï¼Œé˜²æ­¢QPSè§¦å‘é™æµï¼›æŒ‰éœ€è°ƒæ•´\n",
    "RETRIES          = 2\n",
    "TEMPERATURE      = 0.20\n",
    "MAX_TOKENS       = 16384\n",
    "TIMEOUT_SEC      = 600\n",
    "# ====================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3b2dc1-1a41-4ca6-9959-cccbb22adb86",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 1.æ£€éªŒæ¯æ—¥è¯æç°‡åˆ†ç±»è¾“å‡º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "80ca2f9f-62ca-4df1-aeae-2ead09fb39de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å‡†å¤‡å¤„ç† 141 æ¡ï¼Œå…± 1 æ‰¹ï¼ˆæ¯æ‰¹ 300 æ¡ï¼‰ã€‚\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ”¥ æ‰¹å¤„ç†è¿›åº¦:   0%|                                                                                                                                     | 0/1 [02:39<?, ?æ‰¹/s]      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[æ‰¹æ¬¡ 1] æ¨¡å‹#1 è¾“å‡ºæ€»è¡Œæ•°ï¼š89ï¼Œå…¶ä¸­ç©å®¶å‘è¨€ï¼š89 æ¡ï¼ˆä¸å»é‡ï¼‰\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ”¥ æ‰¹å¤„ç†è¿›åº¦:   0%|                                                                                                                                     | 0/1 [02:46<?, ?æ‰¹/s]      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== æ‰¹æ¬¡ 1/1 è¯é¢˜ç°‡è¾“å‡º =====\n",
      "{\"è¯é¢˜ç°‡\":\"åœæœç»´æŠ¤è¡¥å¿è®¨è®ºï¼ˆ2025-11-19 15:02:03-15:11:27ï¼‰\",\"æ ¸å¿ƒå¯¹è±¡/æœºåˆ¶\":\"åœæœç»´æŠ¤è¡¥å¿æœºåˆ¶ï¼Œç©å®¶è®¨è®ºç»´æŠ¤æ—¶é•¿ä¸è¡¥å¿æœŸæœ›ï¼ˆ100æŠ½ã€50æŠ½ã€çŸ³å¸ã€ä»£å¸ç­‰ï¼‰\"}\n",
      "{\"è¯é¢˜ç°‡\":\"æ¸¸æˆä¸‹è½½ä¸å®‰è£…é—®é¢˜ï¼ˆ2025-11-19 15:02:22-15:13:20ï¼‰\",\"æ ¸å¿ƒå¯¹è±¡/æœºåˆ¶\":\"æ¸¸æˆå®‰è£…åŒ…ä¸‹è½½ä¸æ›´æ–°æœºåˆ¶ï¼Œç©å®¶è¯¢é—®ä¸‹è½½é“¾æ¥ã€æ˜¯å¦éœ€è¦é‡æ–°ä¸‹è½½ç­‰é—®é¢˜\"}\n",
      "{\"è¯é¢˜ç°‡\":\"è§’è‰²æŠ€èƒ½æ›´æ–°è®¨è®ºï¼ˆ2025-11-19 15:02:58-15:04:02ï¼‰\",\"æ ¸å¿ƒå¯¹è±¡/æœºåˆ¶\":\"çŒ›çŠ¸è±¡å’Œä»™äººæŒè§’è‰²çš„PTSDä¸å¼ºè¿«ç—‡è¢«åŠ¨æŠ€èƒ½æ›´æ–°å®è£…æƒ…å†µ\"}\n",
      "{\"è¯é¢˜ç°‡\":\"å®¢æœäº’åŠ¨ä¸è°ƒä¾ƒï¼ˆ2025-11-19 15:07:27-15:14:50ï¼‰\",\"æ ¸å¿ƒå¯¹è±¡/æœºåˆ¶\":\"å®¢æœæœåŠ¡ä½“éªŒï¼Œç©å®¶ä¸å®¢æœè–ç±³ã€è“æ¡‰çš„äº’åŠ¨è°ƒä¾ƒåŠæ— å…³æ¸¸æˆå†…å®¹çš„é—²èŠ\"}\n",
      "===========================================\n",
      "\n",
      "[æ‰¹æ¬¡ 1] è¯é¢˜ç°‡è¦†ç›–åŸå§‹å‘è¨€æ¡æ•°ï¼š0ï¼Œæœªè¢«è¦†ç›–æ¡æ•°ï¼š141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ”¥ æ‰¹å¤„ç†è¿›åº¦: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:47<00:00, 167.86s/æ‰¹]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… å…¨éƒ¨æ‰¹æ¬¡å¤„ç†å®Œæˆï¼\n",
      "åŸå§‹è¾“å…¥æ€»æ•°ï¼š141\n",
      "æ¨¡å‹#1 ç­›ç›¸å…³åæ€»è¡Œæ•°ï¼š89ï¼Œå…¶ä¸­ç©å®¶å‘è¨€ï¼š89 æ¡\n",
      "æ¨¡å‹#2 è¯é¢˜ç°‡ç´¯è®¡è¦†ç›–åŸå§‹å‘è¨€æ¡æ•°ï¼š0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "# ===========================================================\n",
    "# =============== ä¸»å¾ªç¯ï¼šæ¨¡å‹#1 + æ¨¡å‹#2 ====================\n",
    "# ===========================================================\n",
    "\n",
    "# è¯»å–ç³»ç»Ÿæç¤º\n",
    "system_prompt01 = load_system_prompt(PROMPT_MD_PATH01)  # ç­›ç›¸å…³\n",
    "system_prompt02 = load_system_prompt(PROMPT_MD_PATH02)  # åšè¯é¢˜ç°‡\n",
    "# 1âƒ£ ç»™åŸå§‹ jsonl æ¯æ¡åŠ  _idx\n",
    "jsonl_lines01_indexed = add_index_to_jsonl_lines(jsonl_lines01)\n",
    "\n",
    "total = len(jsonl_lines01_indexed)\n",
    "\n",
    "PRINT_UNCLUSTERED = False\n",
    "if total == 0:\n",
    "    print(\"æ²¡æœ‰å¯å¤„ç†çš„æ•°æ®ã€‚\")\n",
    "else:\n",
    "    total_batches = (total + BATCH_SIZE - 1) // BATCH_SIZE\n",
    "    print(f\"å‡†å¤‡å¤„ç† {total} æ¡ï¼Œå…± {total_batches} æ‰¹ï¼ˆæ¯æ‰¹ {BATCH_SIZE} æ¡ï¼‰ã€‚\")\n",
    "\n",
    "# ç»Ÿè®¡æ€»é‡ç”¨çš„ï¼ˆå¯é€‰ï¼‰\n",
    "total_filtered_lines = 0         # æ¨¡å‹#1 è¾“å‡ºæ€»è¡Œæ•°ä¹‹å’Œï¼ˆå«å®¢æœï¼‰\n",
    "total_filtered_player_lines = 0  # æ¨¡å‹#1 è¾“å‡ºç©å®¶è¡Œæ•°ä¹‹å’Œ\n",
    "total_covered_idx = 0            # è¢«è¯é¢˜ç°‡è¦†ç›–çš„åŸå§‹å‘è¨€æ€»æ•°ï¼ˆæŒ‰ _idx å»é‡ï¼‰\n",
    "\n",
    "\n",
    "for b in tqdm(range(total_batches), desc=\"ğŸ”¥ æ‰¹å¤„ç†è¿›åº¦\", unit=\"æ‰¹\"):\n",
    "    start = b * BATCH_SIZE\n",
    "    end = min(start + BATCH_SIZE, total)\n",
    "    # æœ¬æ‰¹åŸå§‹å‘è¨€ï¼ˆå·²å¸¦ _idxï¼‰\n",
    "    batch_lines = jsonl_lines01_indexed[start:end]\n",
    "\n",
    "    # æœ¬æ‰¹åŸå§‹ _idx é›†åˆï¼Œç”¨æ¥å’Œè¯é¢˜ç°‡è¦†ç›–åšå·®é›†\n",
    "    batch_original_idx = set()\n",
    "    for line in batch_lines:\n",
    "        try:\n",
    "            obj = json.loads(line)\n",
    "            batch_original_idx.add(int(obj[\"_idx\"]))\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    try:\n",
    "        # ========== æ¨¡å‹ #1ï¼šç­›ç›¸å…³ ==========\n",
    "        user_prompt1 = build_user_prompt_filter(batch_lines)\n",
    "        output_filter = call_ark_chat_completions(\n",
    "            api_url=API_URL,\n",
    "            api_key=API_KEY,\n",
    "            model=V3_MODEL_ID,\n",
    "            system_prompt=system_prompt01,\n",
    "            user_prompt=user_prompt1,\n",
    "            temperature=TEMPERATURE,\n",
    "            max_tokens=MAX_TOKENS,\n",
    "            timeout=TIMEOUT_SEC,\n",
    "            retries=RETRIES,\n",
    "        )\n",
    "        if not output_filter:\n",
    "            tqdm.write(f\"[æ‰¹æ¬¡ {b+1}] æ¨¡å‹#1 æ— æœ‰æ•ˆè¾“å‡ºï¼Œè·³è¿‡ã€‚\")\n",
    "            continue\n",
    "\n",
    "        # ç»Ÿè®¡ç­›ç›¸å…³ä¹‹åçš„è¡Œæ•°ï¼šæ€»è¡Œæ•° & ç©å®¶è¡Œæ•°\n",
    "        filter_total_lines, filter_player_lines = count_output_filter_stats(output_filter)\n",
    "        total_filtered_lines += filter_total_lines\n",
    "        total_filtered_player_lines += filter_player_lines\n",
    "\n",
    "        tqdm.write(\n",
    "            f\"[æ‰¹æ¬¡ {b+1}] æ¨¡å‹#1 è¾“å‡ºæ€»è¡Œæ•°ï¼š{filter_total_lines}ï¼Œ\"\n",
    "            f\"å…¶ä¸­ç©å®¶å‘è¨€ï¼š{filter_player_lines} æ¡ï¼ˆä¸å»é‡ï¼‰\"\n",
    "        )\n",
    "\n",
    "        # ========== æ¨¡å‹ #2ï¼šè¯é¢˜ç°‡ ==========\n",
    "        user_prompt2 = build_user_prompt_clsuter(output_filter)\n",
    "        output_cluster = call_ark_chat_completions(\n",
    "            api_url=API_URL,\n",
    "            api_key=API_KEY,\n",
    "            model=V3_1_MODEL_ID,\n",
    "            system_prompt=system_prompt02,\n",
    "            user_prompt=user_prompt2,\n",
    "            temperature=TEMPERATURE,\n",
    "            max_tokens=MAX_TOKENS,\n",
    "            timeout=TIMEOUT_SEC,\n",
    "            retries=RETRIES,\n",
    "        )\n",
    "        if not output_cluster:\n",
    "            tqdm.write(f\"[æ‰¹æ¬¡ {b+1}] æ¨¡å‹#2 æ— æœ‰æ•ˆè¾“å‡ºï¼Œè·³è¿‡ã€‚\")\n",
    "            continue\n",
    "\n",
    "        # æ‰“å°æœ¬æ‰¹çš„è¯é¢˜ç°‡è¾“å‡ºï¼ˆåŸæ ·ï¼‰\n",
    "        print(f\"\\n===== æ‰¹æ¬¡ {b+1}/{total_batches} è¯é¢˜ç°‡è¾“å‡º =====\")\n",
    "        print(output_cluster)\n",
    "        print(\"===========================================\\n\")\n",
    "\n",
    "        # è®¡ç®—ï¼šæœ¬æ‰¹æœ‰å“ªäº› _idx è¢«è¯é¢˜ç°‡è¦†ç›–ï¼ˆä»â€œå‘è¨€è¡Œå·åˆ—è¡¨â€è§£æï¼‰\n",
    "        covered_idx = get_covered_indices_from_cluster_output(output_cluster)\n",
    "        total_covered_idx += len(covered_idx)\n",
    "\n",
    "        # å’Œâ€œæœ¬æ‰¹åŸå§‹å‘è¨€ _idx é›†åˆâ€åšå·®é›†ï¼Œçœ‹æœ‰å“ªäº›æ²¡è¢«è¦†ç›–\n",
    "        unclustered_idx = batch_original_idx - covered_idx\n",
    "\n",
    "        tqdm.write(\n",
    "            f\"[æ‰¹æ¬¡ {b+1}] è¯é¢˜ç°‡è¦†ç›–åŸå§‹å‘è¨€æ¡æ•°ï¼š{len(covered_idx)}ï¼Œ\"\n",
    "            f\"æœªè¢«è¦†ç›–æ¡æ•°ï¼š{len(unclustered_idx)}\"\n",
    "        )\n",
    "\n",
    "        # â­â­ æ–°å¢ï¼šæ‰“å°â€œæœªè¢«è¯é¢˜ç°‡è¦†ç›–â€çš„å‘è¨€ä¿¡æ¯ï¼ˆæœ€å¤šå‰ 20 æ¡ï¼‰\n",
    "        if PRINT_UNCLUSTERED and unclustered_idx:\n",
    "            # å…ˆæŠŠè¿™ä¸€æ‰¹ä¸­æœªè¦†ç›–çš„å‘è¨€å¯¹è±¡æå‡ºæ¥\n",
    "            unclustered_records = []\n",
    "            for line in batch_lines:\n",
    "                try:\n",
    "                    obj = json.loads(line)\n",
    "                except Exception:\n",
    "                    continue\n",
    "                idx_val = obj.get(\"_idx\")\n",
    "                try:\n",
    "                    idx_int = int(idx_val)\n",
    "                except Exception:\n",
    "                    continue\n",
    "                if idx_int in unclustered_idx:\n",
    "                    unclustered_records.append(obj)\n",
    "\n",
    "            # æŒ‰ _idx æ’åºï¼Œé¿å…ä¹±åº\n",
    "            unclustered_records.sort(key=lambda x: int(x.get(\"_idx\", 0)))\n",
    "\n",
    "            print(f\"\\n[æ‰¹æ¬¡ {b+1}] æœªè¢«è¯é¢˜ç°‡è¦†ç›–çš„åŸå§‹å‘è¨€ï¼ˆæœ€å¤šå‰20æ¡ï¼‰ï¼š\")\n",
    "            for rec in unclustered_records[:20]:\n",
    "                idx = rec.get(\"_idx\")\n",
    "                date = rec.get(\"å‘è¨€æ—¥æœŸ\") or rec.get(\"æ—¥æœŸ\") or \"\"\n",
    "                t = rec.get(\"å‘è¨€æ—¶é—´\") or rec.get(\"æ—¶é—´\") or \"\"\n",
    "                speaker = rec.get(\"å‘è¨€äººID\") or rec.get(\"ç©å®¶ID\") or rec.get(\"è§’è‰²ID\") or \"\"\n",
    "                msg = (\n",
    "                    rec.get(\"ç©å®¶æ¶ˆæ¯\")\n",
    "                    or rec.get(\"å‘è¨€å†…å®¹\")\n",
    "                    or rec.get(\"ç©å®¶å‘è¨€\")\n",
    "                    or rec.get(\"æ¶ˆæ¯\")\n",
    "                    or \"\"\n",
    "                )\n",
    "                print(f\"- _idx={idx} [{date} {t}] {speaker}: {msg}\")\n",
    "            print()  # æ¢è¡Œåˆ†éš”ä¸€ä¸‹\n",
    "\n",
    "    except Exception as e:\n",
    "        tqdm.write(f\"[æ‰¹æ¬¡ {b+1}] âŒ å‡ºé”™ï¼š{e}\")\n",
    "        continue\n",
    "\n",
    "    # é˜²æ­¢ QPS è¿‡é«˜\n",
    "    time.sleep(SLEEP_BETWEEN)\n",
    "\n",
    "print(\"\\nâœ… å…¨éƒ¨æ‰¹æ¬¡å¤„ç†å®Œæˆï¼\")\n",
    "print(f\"åŸå§‹è¾“å…¥æ€»æ•°ï¼š{total}\")\n",
    "print(f\"æ¨¡å‹#1 ç­›ç›¸å…³åæ€»è¡Œæ•°ï¼š{total_filtered_lines}ï¼Œå…¶ä¸­ç©å®¶å‘è¨€ï¼š{total_filtered_player_lines} æ¡\")\n",
    "print(f\"æ¨¡å‹#2 è¯é¢˜ç°‡ç´¯è®¡è¦†ç›–åŸå§‹å‘è¨€æ¡æ•°ï¼š{total_covered_idx}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5465d2eb-915e-4133-a3dd-485de2d48577",
   "metadata": {},
   "source": [
    "## åŠ è®¨è®ºè§‚ç‚¹åˆ†æçš„ç‰ˆæœ¬æµ‹è¯•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411f43b3-eb1e-4fff-9e58-f758a3848262",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å‡†å¤‡å¤„ç† 1784 æ¡ï¼Œå…± 6 æ‰¹ï¼ˆæ¯æ‰¹ 300 æ¡ï¼‰ã€‚\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ”¥ æ‰¹å¤„ç†è¿›åº¦:   0%|                                                                                                                                                       | 0/6 [00:00<?, ?æ‰¹/s]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# ... å‰ç½®ï¼šç³»ç»Ÿæç¤ºã€create_intent_excel_styled(EXCEL_FILE)ã€jsonl_lines01 ç­‰\n",
    "\n",
    "system_prompt01 = load_system_prompt(PROMPT_MD_PATH01)  # ç­›ç›¸å…³\n",
    "system_prompt02 = load_system_prompt(PROMPT_MD_PATH02)  # åšè¯æç°‡\n",
    "system_prompt03 = load_system_prompt(PROMPT_MD_PATH03)  # è¯é¢˜ç°‡èšåˆ / æ ¡æ­£ï¼ˆæ™ºèƒ½ä½“4ï¼‰\n",
    "system_prompt04 = load_system_prompt(PROMPT_MD_PATH04)  # è¯é¢˜ç°‡èšåˆ / æ ¡æ­£ï¼ˆæ™ºèƒ½ä½“4ï¼‰\n",
    "# ç”¨äºå­˜æ”¾å½“å¤©æ‰€æœ‰æ‰¹æ¬¡çš„è¯é¢˜ç°‡ JSON è¡Œï¼ˆç»™æ™ºèƒ½ä½“4ç”¨ï¼‰\n",
    "batch_cluster_outputs  = []\n",
    "all_opinions = []\n",
    "total = len(jsonl_lines01)\n",
    "if total == 0:\n",
    "    print(\"æ²¡æœ‰å¯å¤„ç†çš„æ•°æ®ã€‚\")\n",
    "else:\n",
    "    total_batches = (total + BATCH_SIZE - 1) // BATCH_SIZE\n",
    "    print(f\"å‡†å¤‡å¤„ç† {total} æ¡ï¼Œå…± {total_batches} æ‰¹ï¼ˆæ¯æ‰¹ {BATCH_SIZE} æ¡ï¼‰ã€‚\")\n",
    "\n",
    "written_total = 0\n",
    "\n",
    "for b in tqdm(range(total_batches), desc=\"ğŸ”¥ æ‰¹å¤„ç†è¿›åº¦\", unit=\"æ‰¹\"):\n",
    "    start = b * BATCH_SIZE\n",
    "    end = min(start + BATCH_SIZE, total)\n",
    "    batch_lines = jsonl_lines01[start:end]\n",
    "\n",
    "    try:\n",
    "        # --- æ¨¡å‹ #1ï¼šç­›ç›¸å…³ ---\n",
    "        user_prompt1 = build_user_prompt_filter(batch_lines)\n",
    "        output_filter = call_ark_chat_completions(\n",
    "            api_url=API_URL,\n",
    "            api_key=API_KEY,\n",
    "            model=V3_MODEL_ID,\n",
    "            system_prompt=system_prompt01,\n",
    "            user_prompt=user_prompt1,\n",
    "            temperature=TEMPERATURE,\n",
    "            max_tokens=MAX_TOKENS,\n",
    "            timeout=TIMEOUT_SEC,\n",
    "            retries=RETRIES,\n",
    "        )\n",
    "        \n",
    "        if not output_filter:\n",
    "            tqdm.write(f\"[æ‰¹æ¬¡ {b+1}] æ¨¡å‹#1 æ— æœ‰æ•ˆè¾“å‡ºï¼Œè·³è¿‡ã€‚\")\n",
    "            continue\n",
    "        filter_count = sum(1 for line in output_filter.splitlines() if line.strip())\n",
    "        tqdm.write(f\"[æ‰¹æ¬¡ {b+1}] æ¨¡å‹#1 ç­›åä¿ç•™ {filter_count} æ¡\")\n",
    "        written_total += filter_count   # å¦‚æœä¸éœ€è¦æ€»æ•°ï¼Œå¯ä»¥åˆ æ‰è¿™ä¸€è¡Œ\n",
    "        \n",
    "        # --- æ¨¡å‹ #2ï¼šè¯é¢˜ç°‡åˆ’åˆ† ---\n",
    "        user_prompt2 = build_user_prompt_clsuter(output_filter)\n",
    "        output_cluster = call_ark_chat_completions(\n",
    "            api_url=API_URL,\n",
    "            api_key=API_KEY,\n",
    "            model=V3_1_MODEL_ID,\n",
    "            system_prompt=system_prompt02,\n",
    "            user_prompt=user_prompt2,\n",
    "            temperature=TEMPERATURE,\n",
    "            max_tokens=MAX_TOKENS,\n",
    "            timeout=TIMEOUT_SEC,\n",
    "            retries=RETRIES,\n",
    "        )\n",
    "        if not output_cluster:\n",
    "            tqdm.write(f\"[æ‰¹æ¬¡ {b+1}] æ¨¡å‹#2 æ— æœ‰æ•ˆè¾“å‡ºï¼Œè·³è¿‡ã€‚\")\n",
    "            continue\n",
    "        try:\n",
    "            cluster_json_list = []\n",
    "            for line in output_cluster.strip().splitlines():\n",
    "                line = line.strip()\n",
    "                if not line.startswith(\"{\"):\n",
    "                    continue\n",
    "                obj = json.loads(line)\n",
    "                # å°† \"è¯é¢˜ç°‡1\" â†’ \"è¯é¢˜ç°‡\"ï¼Œä¾¿äºåç»­ç»Ÿä¸€å¤„ç†\n",
    "                for key in list(obj.keys()):\n",
    "                    if key.startswith(\"è¯é¢˜ç°‡\") and key != \"è¯é¢˜ç°‡\":\n",
    "                        obj[\"è¯é¢˜ç°‡\"] = obj.pop(key)\n",
    "                cluster_json_list.append(obj)\n",
    "\n",
    "            # å‡è®¾ä»è¾“å‡ºä¸­æ‹¿æ—¥æœŸ\n",
    "            date_str = infer_date_for_batch(cluster_json_list, batch_lines)  # ä½ å¯ä»¥ä»ä¸Šä¸‹æ–‡è·å¾—æ›´å‡†ç¡®å€¼\n",
    "            batch_id = f\"B{b+1}\"\n",
    "            cluster_json_list = assign_global_cluster_ids(cluster_json_list, date_str, batch_id)\n",
    "        \n",
    "            output_cluster_with_ids = \"\\n\".join(json.dumps(c, ensure_ascii=False) for c in cluster_json_list)\n",
    "            batch_cluster_outputs.append(output_cluster_with_ids)\n",
    "        except Exception as e:\n",
    "            tqdm.write(f\"[æ‰¹æ¬¡ {b+1}] âš  æ·»åŠ  _cluster_id å¤±è´¥ï¼š{e}\")\n",
    "            continue\n",
    "\n",
    "       \n",
    "       \n",
    "    except Exception as e:\n",
    "        tqdm.write(f\"[æ‰¹æ¬¡ {b+1}] âŒ å‡ºé”™ï¼š{e}\")\n",
    "        continue\n",
    "\n",
    "    time.sleep(SLEEP_BETWEEN)\n",
    "\n",
    "\n",
    "\n",
    "# --- æ¯æ—¥è¯æç°‡èšåˆæˆjsonl ---\n",
    "all_cluster = aggregate_cluster_outputs(batch_cluster_outputs)\n",
    "\n",
    "# --- æ¨¡å‹ #3ï¼šæ—¥è¯æç°‡èšåˆ ---\n",
    "user_prompt3 = build_user_prompt_cluster_agg(all_cluster)\n",
    "output_cluster_agg = call_ark_chat_completions(\n",
    "    api_url=API_URL,\n",
    "    api_key=API_KEY,\n",
    "    model=V3_1_MODEL_ID,           # æˆ–ä½ ç»™æ™ºèƒ½ä½“4é€‰çš„æ¨¡å‹\n",
    "    system_prompt=system_prompt03,  # è¯é¢˜ç°‡èšåˆ/æ ¡æ­£æç¤ºè¯\n",
    "    user_prompt=user_prompt3,\n",
    "    temperature=TEMPERATURE,\n",
    "    max_tokens=MAX_TOKENS,\n",
    "    timeout=TIMEOUT_SEC,\n",
    "    retries=RETRIES,\n",
    ")\n",
    "\n",
    "# --- æ¯æ—¥è¯æç°‡èšåˆæˆjsonl ---\n",
    "all_cluster = aggregate_cluster_outputs(batch_cluster_outputs)\n",
    "\n",
    "# --- æ¨¡å‹ #3ï¼šæ—¥è¯æç°‡èšåˆ ---\n",
    "user_prompt3 = build_user_prompt_cluster_agg(all_cluster)\n",
    "output_cluster_agg = call_ark_chat_completions(\n",
    "    api_url=API_URL,\n",
    "    api_key=API_KEY,\n",
    "    model=V3_1_MODEL_ID,\n",
    "    system_prompt=system_prompt03,\n",
    "    user_prompt=user_prompt3,\n",
    "    temperature=TEMPERATURE,\n",
    "    max_tokens=MAX_TOKENS,\n",
    "    timeout=TIMEOUT_SEC,\n",
    "    retries=RETRIES,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# --- ç­›é€‰æ¯æ—¥å‘è¨€çƒ­åº¦top5 ---\n",
    "# å­è¯é¢˜ç°‡ï¼ˆæ¥è‡ª all_clusterï¼‰\n",
    "# âœ… 2) å†è§£æèšåˆç°‡ï¼ˆæ¥è‡ª output_cluster_aggï¼‰\n",
    "# èšåˆç°‡ï¼ˆæ¨¡å‹#3 è¾“å‡ºï¼‰\n",
    "parsed_clusters = parse_jsonl_text(output_cluster_agg)\n",
    "\n",
    "# å­è¯é¢˜ç°‡ï¼ˆall_cluster å·²ç»æ˜¯ jsonlï¼Œä½†ä¹Ÿç”¨ç»Ÿä¸€è§£ææ›´å®‰å…¨ï¼‰\n",
    "parsed_subclusters = parse_jsonl_text(all_cluster)\n",
    "# âœ… 3) æœ€åå…œåº•è¡¥é½â€œæ—¶é—´è½´â€ï¼ˆé¿å… None.splitï¼‰\n",
    "fixed_cnt = 0\n",
    "fixed_sub_cnt = 0\n",
    "for c in parsed_clusters:\n",
    "    if ensure_time_axis_key(c, verbose=False):\n",
    "        fixed_cnt += 1\n",
    "    if ensure_subcluster_list_key(c):\n",
    "        fixed_sub_cnt += 1\n",
    "print(f\"âœ… å·²è‡ªåŠ¨è¡¥é½/ä¿®å¤ æ—¶é—´è½´ çš„èšåˆç°‡æ•°é‡ï¼š{fixed_cnt}\")\n",
    "print(f\"âœ… å·²è‡ªåŠ¨è¡¥é½/ä¿®å¤ å­è¯é¢˜ç°‡åˆ—è¡¨ çš„èšåˆç°‡æ•°é‡ï¼š{fixed_sub_cnt}\")\n",
    "\n",
    "# è®¡ç®— top5\n",
    "top5_results = extract_top5_heat_clusters(parsed_clusters, jsonl_lines01, top_k=5)\n",
    "final_result = attach_discussion_points(top5_results, parsed_subclusters)\n",
    "\n",
    "# --- æ ¹æ®æ¯æ—¥è®¨è®ºçƒ­åº¦5å›æº¯è‡³åŸæ–‡åˆ†æè§‚ç‚¹å…±è¯† ---\n",
    "rows = print_mech_time_from_top5(final_result, all_cluster)\n",
    "\n",
    "# âœ… è®°å¾—åˆå§‹åŒ–\n",
    "all_opinions = []\n",
    "\n",
    "for idx, r in enumerate(rows, start=1):\n",
    "    mech = r.get(\"æ ¸å¿ƒå¯¹è±¡/æœºåˆ¶\") or \"\"\n",
    "    full_time = (r.get(\"å‘è¨€æ—¶é—´\") or \"\").strip()\n",
    "\n",
    "    if not mech or not full_time:\n",
    "        print(f\"âš  ç¬¬ {idx} æ¡ç¼ºå°‘ æ ¸å¿ƒå¯¹è±¡/æœºåˆ¶ æˆ– å‘è¨€æ—¶é—´ï¼ŒåŸå§‹è¡Œï¼š{r}\")\n",
    "        continue\n",
    "\n",
    "    # full_time æ ¼å¼ç±»ä¼¼ï¼š\"2025-12-02 14:01:57-14:42:21\"\n",
    "    if \" \" not in full_time:\n",
    "        print(f\"âš  ç¬¬ {idx} æ¡å‘è¨€æ—¶é—´æ ¼å¼å¼‚å¸¸ï¼Œæ— æ³•æ‹†åˆ†æ—¥æœŸå’Œæ—¶é—´è½´ï¼š{full_time}\")\n",
    "        continue\n",
    "\n",
    "    fayan_date, fayan_time = full_time.split(\" \", 1)  # \"2025-12-02\", \"14:01:57-14:42:21\"\n",
    "\n",
    "    # ç”¨ debug ç‰ˆå›æº¯åŸæ–‡\n",
    "    dialogs_lines = get_dialogs_lines_by_fayan_time_debug(\n",
    "        jsonl_lines01,\n",
    "        fayan_date,\n",
    "        fayan_time,\n",
    "        debug=True,\n",
    "    )\n",
    "\n",
    "    if not dialogs_lines:\n",
    "        print(f\"âš  è¯¥æ—¶é—´æ®µå†…æ²¡æœ‰åŸæ–‡ï¼Œè·³è¿‡ï¼š{mech} | {fayan_date} {fayan_time}\")\n",
    "        continue\n",
    "\n",
    "    # --- æ¨¡å‹ #4ï¼šåˆ†æç©å®¶å…±è¯† ---\n",
    "    user_prompt4 = build_user_prompt_subcluster_opinion(\n",
    "        discussion_point=mech,\n",
    "        json_lines=dialogs_lines,\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        opinion_output = call_ark_chat_completions(\n",
    "            api_url=API_URL,\n",
    "            api_key=API_KEY,\n",
    "            model=V3_1_MODEL_ID,\n",
    "            system_prompt=system_prompt04,\n",
    "            user_prompt=user_prompt4,\n",
    "            temperature=TEMPERATURE,\n",
    "            max_tokens=MAX_TOKENS,\n",
    "            timeout=TIMEOUT_SEC,\n",
    "            retries=RETRIES,\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(\"âŒ è°ƒç”¨æ¨¡å‹4å‡ºé”™:\", e)\n",
    "        continue\n",
    "\n",
    "    opinions_this_mech = parse_opinion_output_to_list(opinion_output)\n",
    "    all_opinions.extend(opinions_this_mech)\n",
    "\n",
    "merged_top5 = merge_top5_with_opinions_numbered(final_result, all_opinions)\n",
    "\n",
    "for row in merged_top5:\n",
    "    print(json.dumps(row, ensure_ascii=False, indent=2))\n",
    "\n",
    "\n",
    "# è¾“å‡ºæŸ¥çœ‹ï¼š\n",
    "#for row in final_result:\n",
    "    #print(json.dumps(row, ensure_ascii=False, indent=2))\n",
    "\n",
    "#append_daily_top5_to_version_jsonl(\n",
    "    #final_result,\n",
    "    #version_jsonl_path=VERSION_TOP5_JSONL # è¿™ä¸ªè·¯å¾„ä½ å¯ä»¥æŒ‰ç‰ˆæœ¬å·åŠ¨æ€æ”¹\n",
    "#)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f86a3e57-3b7e-470c-aed3-9a1dc9b0cf1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"è®¨è®ºç‚¹\": \"æ¸¸æˆè‚‰é¸½å…ƒç´ å¸¦æ¥çš„éšæœºæ€§ä½“éªŒ\",\n",
      "  \"ç©å®¶å…±è¯†\": \"ç©å®¶æ™®éè®¤ä¸ºæ¸¸æˆå…·æœ‰æ˜æ˜¾çš„è‚‰é¸½å…ƒç´ ï¼Œæ¯å±€åœ°å›¾å’Œå¯ç”¨æµæ´¾éƒ½ä¸åŒï¼Œå¯¼è‡´ç©æ³•éšæœºæ€§å¼ºï¼Œéœ€è¦æ ¹æ®è·å¾—çš„èµ„æºè°ƒæ•´ç­–ç•¥\",\n",
      "  \"ç©å®¶ä¸»è¦åˆ†æ­§ç‚¹\": \"æ— æ˜æ˜¾åˆ†æ­§\",\n",
      "  \"ç©å®¶è§‚ç‚¹\": [\n",
      "    \"1ï¼šå¤šåç©å®¶æåˆ°æ¯å±€åœ°å›¾å’Œå¯ç”¨æµæ´¾éƒ½ä¸åŒï¼Œä½“ç°äº†è‚‰é¸½ç©æ³•çš„éšæœºæ€§ï¼ˆæ¸…æ¸…ï¼šåœ°å›¾éƒ½ä¸ä¸€æ ·ï¼Œæ¯ä¸ªäººï¼Œæ¯ä¸€å±€ï¼›å¥½åƒå¾ˆçªç„¶ï¼šå› ä¸ºæ˜¯æœ‰åœ°å›¾åŒºåˆ†çš„ï¼‰\",\n",
      "    \"2ï¼šè‹¥å¹²ç©å®¶è¡¨ç¤ºå› éšæœºæ€§è¢«è¿«æ”¹å˜ç©æ³•æµæ´¾ï¼ˆåŒæ­¥ï¼šè¿‘æˆ˜å¤©èµ‹çš„è¢«é€¼ç€å»ç©å¬å”¤äº†ï¼›æ¸…æ¸…ï¼šæˆ‘å¼€å±€åˆ°ç°åœ¨åªèƒ½ç©ç¨»è‰äººå¥—ï¼›æ¸…æ¸…ï¼šå¬å”¤æµç©åˆ°ç°åœ¨ï¼‰\",\n",
      "    \"3ï¼šä¸ªåˆ«ç©å®¶æåˆ°æ ¹æ®éšæœºè·å¾—çš„èµ„æºé€‰æ‹©ç­–ç•¥ï¼ˆgood iceï¼šå“ªä¸ªæ˜Ÿé«˜ç”¨é‚£ä¸ªï¼›good iceï¼šç„¶åçå‡‘çš„ç³–æœï¼‰\",\n",
      "    \"4ï¼šä¸ªåˆ«ç©å®¶è¡¨è¾¾äº†å¯¹è‚‰é¸½ç©æ³•çš„å–œçˆ±ï¼ˆæ¸…æ¸…ï¼šå› ä¸ºè¿™æ¸¸æˆç©æ³•å¾ˆè‚‰é¸½ï¼Œå…¶å®æŒºå–œæ¬¢çš„ï¼‰\"\n",
      "  ],\n",
      "  \"ä»£è¡¨æ€§ç©å®¶å‘è¨€ç¤ºä¾‹\": [\n",
      "    \"æ¸…æ¸…ï¼šåœ°å›¾éƒ½ä¸ä¸€æ ·ï¼Œæ¯ä¸ªäººï¼Œæ¯ä¸€å±€\",\n",
      "    \"åŒæ­¥ï¼šè¿‘æˆ˜å¤©èµ‹çš„è¢«é€¼ç€å»ç©å¬å”¤äº†\",\n",
      "    \"æ¸…æ¸…ï¼šå› ä¸ºè¿™æ¸¸æˆç©æ³•å¾ˆè‚‰é¸½ï¼Œå…¶å®æŒºå–œæ¬¢çš„\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "        print(opinion_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e99015f-028b-4df0-b3f0-228f671cacfa",
   "metadata": {},
   "source": [
    "## å¼€å§‹è¿è¡Œ(ä¸å¯åŠ¨ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3f8c0e8-7351-43b6-9745-d0f23cea3be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å‡†å¤‡å¤„ç† 2308 æ¡ï¼Œå…± 8 æ‰¹ï¼ˆæ¯æ‰¹ 300 æ¡ï¼‰ã€‚\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ”¥ æ‰¹å¤„ç†è¿›åº¦:   0%|                                                                                                                                                                                         | 0/8 [01:49<?, ?æ‰¹/s]      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[æ‰¹æ¬¡ 1] æ¨¡å‹#1 ç­›åä¿ç•™ 68 æ¡\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ”¥ æ‰¹å¤„ç†è¿›åº¦:  12%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                                                                                                                          | 1/8 [10:14<13:56, 119.49s/æ‰¹]      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[æ‰¹æ¬¡ 2] æ¨¡å‹#1 ç­›åä¿ç•™ 264 æ¡\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ”¥ æ‰¹å¤„ç†è¿›åº¦:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                                                                                                    | 2/8 [18:28<35:40, 356.71s/æ‰¹]      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[æ‰¹æ¬¡ 3] æ¨¡å‹#1 ç­›åä¿ç•™ 279 æ¡\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ”¥ æ‰¹å¤„ç†è¿›åº¦:  38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                                                                              | 3/8 [25:36<35:32, 426.55s/æ‰¹]      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[æ‰¹æ¬¡ 4] æ¨¡å‹#1 ç­›åä¿ç•™ 225 æ¡\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ”¥ æ‰¹å¤„ç†è¿›åº¦:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                                                        | 4/8 [35:11<29:07, 436.90s/æ‰¹]      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[æ‰¹æ¬¡ 5] æ¨¡å‹#1 ç­›åä¿ç•™ 299 æ¡\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ”¥ æ‰¹å¤„ç†è¿›åº¦:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                                  | 5/8 [42:11<24:03, 481.03s/æ‰¹]      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[æ‰¹æ¬¡ 6] æ¨¡å‹#1 ç­›åä¿ç•™ 230 æ¡\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ”¥ æ‰¹å¤„ç†è¿›åº¦:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                            | 6/8 [43:03<15:20, 460.17s/æ‰¹]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[æ‰¹æ¬¡ 6] âš  è§£ææ¨¡å‹#2 è¾“å‡º JSON å¤±è´¥ï¼šExpecting value: line 1 column 1 (char 0)ï¼Œè¡Œå†…å®¹ï¼š}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ”¥ æ‰¹å¤„ç†è¿›åº¦:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                            | 6/8 [48:56<15:20, 460.17s/æ‰¹]      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[æ‰¹æ¬¡ 7] æ¨¡å‹#1 ç­›åä¿ç•™ 235 æ¡\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ”¥ æ‰¹å¤„ç†è¿›åº¦:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                      | 7/8 [54:33<07:19, 439.94s/æ‰¹]      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[æ‰¹æ¬¡ 8] æ¨¡å‹#1 ç­›åä¿ç•™ 205 æ¡\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ”¥ æ‰¹å¤„ç†è¿›åº¦: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [55:16<00:00, 414.54s/æ‰¹]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# ... å‰ç½®ï¼šç³»ç»Ÿæç¤ºã€create_intent_excel_styled(EXCEL_FILE)ã€jsonl_lines01 ç­‰\n",
    "\n",
    "system_prompt01 = load_system_prompt(PROMPT_MD_PATH01)  # ç­›ç›¸å…³\n",
    "system_prompt02 = load_system_prompt(PROMPT_MD_PATH02)  # åšè¯æç°‡\n",
    "system_prompt03 = load_system_prompt(PROMPT_MD_PATH03)  # è¯é¢˜ç°‡èšåˆ / æ ¡æ­£ï¼ˆæ™ºèƒ½ä½“4ï¼‰\n",
    "system_prompt04 = load_system_prompt(PROMPT_MD_PATH04)  # è¯æç°‡ç©å®¶è§‚ç‚¹æ„Ÿå—åˆ†æ\n",
    "\n",
    "\n",
    "sub_opinion_map = {}\n",
    "# ç”¨äºå­˜æ”¾å½“å¤©æ‰€æœ‰æ‰¹æ¬¡çš„è¯é¢˜ç°‡ JSON è¡Œï¼ˆç»™æ™ºèƒ½ä½“4ç”¨ï¼‰\n",
    "batch_cluster_outputs  = []\n",
    "total = len(jsonl_lines01)\n",
    "if total == 0:\n",
    "    print(\"æ²¡æœ‰å¯å¤„ç†çš„æ•°æ®ã€‚\")\n",
    "else:\n",
    "    total_batches = (total + BATCH_SIZE - 1) // BATCH_SIZE\n",
    "    print(f\"å‡†å¤‡å¤„ç† {total} æ¡ï¼Œå…± {total_batches} æ‰¹ï¼ˆæ¯æ‰¹ {BATCH_SIZE} æ¡ï¼‰ã€‚\")\n",
    "\n",
    "written_total = 0\n",
    "\n",
    "for b in tqdm(range(total_batches), desc=\"ğŸ”¥ æ‰¹å¤„ç†è¿›åº¦\", unit=\"æ‰¹\"):\n",
    "    start = b * BATCH_SIZE\n",
    "    end = min(start + BATCH_SIZE, total)\n",
    "    batch_lines = jsonl_lines01[start:end]\n",
    "\n",
    "    try:\n",
    "        # --- æ¨¡å‹ #1ï¼šç­›ç›¸å…³ ---\n",
    "        user_prompt1 = build_user_prompt_filter(batch_lines)\n",
    "        output_filter = call_ark_chat_completions(\n",
    "            api_url=API_URL,\n",
    "            api_key=API_KEY,\n",
    "            model=V3_MODEL_ID,\n",
    "            system_prompt=system_prompt01,\n",
    "            user_prompt=user_prompt1,\n",
    "            temperature=TEMPERATURE,\n",
    "            max_tokens=MAX_TOKENS,\n",
    "            timeout=TIMEOUT_SEC,\n",
    "            retries=RETRIES,\n",
    "        )\n",
    "        \n",
    "        if not output_filter:\n",
    "            tqdm.write(f\"[æ‰¹æ¬¡ {b+1}] æ¨¡å‹#1 æ— æœ‰æ•ˆè¾“å‡ºï¼Œè·³è¿‡ã€‚\")\n",
    "            continue\n",
    "        filter_count = sum(1 for line in output_filter.splitlines() if line.strip())\n",
    "        tqdm.write(f\"[æ‰¹æ¬¡ {b+1}] æ¨¡å‹#1 ç­›åä¿ç•™ {filter_count} æ¡\")\n",
    "        written_total += filter_count   # å¦‚æœä¸éœ€è¦æ€»æ•°ï¼Œå¯ä»¥åˆ æ‰è¿™ä¸€è¡Œ\n",
    "        \n",
    "        # --- æ¨¡å‹ #2ï¼šè¯é¢˜ç°‡åˆ’åˆ† ---\n",
    "        user_prompt2 = build_user_prompt_clsuter(output_filter)\n",
    "        output_cluster = call_ark_chat_completions(\n",
    "            api_url=API_URL,\n",
    "            api_key=API_KEY,\n",
    "            model=V3_1_MODEL_ID,\n",
    "            system_prompt=system_prompt02,\n",
    "            user_prompt=user_prompt2,\n",
    "            temperature=TEMPERATURE,\n",
    "            max_tokens=MAX_TOKENS,\n",
    "            timeout=TIMEOUT_SEC,\n",
    "            retries=RETRIES,\n",
    "        )\n",
    "        \n",
    "        \n",
    "\n",
    "        if not output_cluster:\n",
    "            tqdm.write(f\"[æ‰¹æ¬¡ {b+1}] æ¨¡å‹#2 æ— æœ‰æ•ˆè¾“å‡ºï¼Œè·³è¿‡ã€‚\")\n",
    "            continue\n",
    "        try:\n",
    "            cluster_json_list = []\n",
    "            for raw in output_cluster.strip().splitlines():\n",
    "                line = raw.strip()\n",
    "                if not line:\n",
    "                    continue\n",
    "                if line in (\"{\", \"}\", \"},\"):\n",
    "                    continue\n",
    "                if not line.startswith(\"{\"):\n",
    "                    continue\n",
    "            try:\n",
    "                obj = json.loads(line)\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"[æ‰¹æ¬¡ {b+1}] âš  è§£ææ¨¡å‹#2 è¾“å‡º JSON å¤±è´¥ï¼š{e}ï¼Œè¡Œå†…å®¹ï¼š{line[:120]}\")\n",
    "                continue\n",
    "            \n",
    "            # å°† \"è¯é¢˜ç°‡1\" â†’ \"è¯é¢˜ç°‡\"ï¼Œä¾¿äºåç»­ç»Ÿä¸€å¤„ç†\n",
    "            for key in list(obj.keys()):\n",
    "                if key.startswith(\"è¯é¢˜ç°‡\") and key != \"è¯é¢˜ç°‡\":\n",
    "                    obj[\"è¯é¢˜ç°‡\"] = obj.pop(key)\n",
    "            cluster_json_list.append(obj)\n",
    "\n",
    "\n",
    "            # å‡è®¾ä»è¾“å‡ºä¸­æ‹¿æ—¥æœŸ\n",
    "            date_str = infer_date_for_batch(cluster_json_list, batch_lines)  # ä½ å¯ä»¥ä»ä¸Šä¸‹æ–‡è·å¾—æ›´å‡†ç¡®å€¼\n",
    "            batch_id = f\"B{b+1}\"\n",
    "            cluster_json_list = assign_global_cluster_ids(cluster_json_list, date_str, batch_id)\n",
    "        \n",
    "            output_cluster_with_ids = \"\\n\".join(json.dumps(c, ensure_ascii=False) for c in cluster_json_list)\n",
    "            batch_cluster_outputs.append(output_cluster_with_ids)\n",
    "        except Exception as e:\n",
    "            tqdm.write(f\"[æ‰¹æ¬¡ {b+1}] âš  æ·»åŠ  _cluster_id å¤±è´¥ï¼š{e}\")\n",
    "            continue\n",
    "\n",
    "       \n",
    "       \n",
    "    except Exception as e:\n",
    "        tqdm.write(f\"[æ‰¹æ¬¡ {b+1}] âŒ å‡ºé”™ï¼š{e}\")\n",
    "        continue\n",
    "\n",
    "    time.sleep(SLEEP_BETWEEN)\n",
    "\n",
    "\n",
    "\n",
    "# --- æ¯æ—¥è¯æç°‡èšåˆæˆjsonl ---\n",
    "all_cluster = aggregate_cluster_outputs(batch_cluster_outputs)\n",
    "\n",
    "# --- æ¨¡å‹ #3ï¼šæ—¥è¯æç°‡èšåˆ ---\n",
    "user_prompt3 = build_user_prompt_cluster_agg(all_cluster)\n",
    "output_cluster_agg = call_ark_chat_completions(\n",
    "    api_url=API_URL,\n",
    "    api_key=API_KEY,\n",
    "    model=V3_1_MODEL_ID,           # æˆ–ä½ ç»™æ™ºèƒ½ä½“4é€‰çš„æ¨¡å‹\n",
    "    system_prompt=system_prompt03,  # è¯é¢˜ç°‡èšåˆ/æ ¡æ­£æç¤ºè¯\n",
    "    user_prompt=user_prompt3,\n",
    "    temperature=TEMPERATURE,\n",
    "    max_tokens=MAX_TOKENS,\n",
    "    timeout=TIMEOUT_SEC,\n",
    "    retries=RETRIES,\n",
    ")\n",
    "\n",
    "\n",
    "# 1) å…ˆä¿® raw æ–‡æœ¬è¾“å‡ºï¼ˆç»Ÿä¸€ key åï¼‰\n",
    "output_cluster_agg = fix_output_cluster_agg_keys(output_cluster_agg)\n",
    "\n",
    "\n",
    "#æ¯æ—¥æ€»å‘è¨€è½¬å•æ¡jonslæ ¼å¼\n",
    "parsed_subclusters = [\n",
    "    json.loads(line.strip()) for line in all_cluster.strip().splitlines() if line.strip()\n",
    "]\n",
    "\n",
    "# 3) æœ€ååšå…œåº•ï¼šç¡®ä¿æ¯æ¡éƒ½æœ‰ æ—¶é—´è½´\n",
    "fixed_cnt = 0\n",
    "for c in parsed_clusters:\n",
    "    if ensure_time_axis_key(c, verbose=False):\n",
    "        fixed_cnt += 1\n",
    "print(f\"âœ… å·²è‡ªåŠ¨è¡¥é½/ä¿®å¤ æ—¶é—´è½´ çš„èšåˆç°‡æ•°é‡ï¼š{fixed_cnt}\")\n",
    "\n",
    "\n",
    "# è§£æåŸå§‹å‘è¨€ jsonlï¼Œä¸ºæŒ‰æ—¶é—´è½´ç­›é€‰å¯¹è¯ç”¨\n",
    "parsed_msgs = [json.loads(line.strip()) for line in jsonl_lines01 if line.strip()]\n",
    "\n",
    "#æ¯æ—¥èšåˆåè¯æç°‡è½¬å•æ¡jsonlæ ¼å¼\n",
    "parsed_clusters = [json.loads(line) for line in output_cluster_agg.strip().splitlines() if line.strip()]\n",
    "\n",
    "#è®¡ç®—æ¯æ—¥è®¨è®ºçƒ­åº¦top5\n",
    "top5_results = extract_top5_heat_clusters(parsed_clusters, jsonl_lines01, top_k=5)\n",
    "\n",
    "#######æå–å­è¯æç°‡è®¨è®ºç‚¹###########################################################\n",
    "####### å»ºå­ç°‡ç´¢å¼•ï¼š_cluster_id -> å­ç°‡å¯¹è±¡ ########\n",
    "sub_map = {}\n",
    "for row in parsed_subclusters:\n",
    "    cid = row.get(\"_cluster_id\")\n",
    "    if isinstance(cid, str) and cid:\n",
    "        sub_map[cid] = row\n",
    "\n",
    "####### åœ¨ Top5 å¾ªç¯é‡Œï¼Œå¯¹æ¯ä¸ªã€å­è¯é¢˜ç°‡ã€‘å•ç‹¬è·‘æ¨¡å‹#4 ########\n",
    "for cluster in top5_results:\n",
    "    date = cluster[\"æ—¥æœŸ\"]\n",
    "    # èšåˆç°‡çš„æ•´ä½“æ—¶é—´è½´ï¼ˆåªç”¨æ¥å…œåº•ï¼‰\n",
    "    cluster_time_axis = cluster[\"æ—¶é—´è½´\"]\n",
    "    cid_list = cluster.get(\"å­è¯é¢˜ç°‡åˆ—è¡¨\", [])\n",
    "\n",
    "    for cid in cid_list:\n",
    "        sub = sub_map.get(cid)\n",
    "        if not sub:\n",
    "            print(f\"\\n[èšåˆè¯é¢˜ç°‡ï¼š{cluster.get('èšåˆè¯é¢˜ç°‡')}] å­è¯é¢˜ç°‡ IDï¼š{cid}\")\n",
    "            print(\"  âš  åœ¨ sub_map / parsed_subclusters ä¸­æœªæ‰¾åˆ°è¯¥ _cluster_idã€‚\")\n",
    "            continue\n",
    "\n",
    "        \n",
    "        # ---- 1ï¼‰ä»å­è¯é¢˜ç°‡ã€æ ‡é¢˜ã€‘é‡Œæå–æ—¶é—´è½´ ----\n",
    "        sub_title = sub.get(\"è¯é¢˜ç°‡\", \"\") or \"\"\n",
    "        sub_time_axis = extract_time_axis_from_title(sub_title)\n",
    "\n",
    "        # ---- 2ï¼‰æŒ‰ã€å­è¯æç°‡æ—¶é—´è½´ã€‘ä»åŸå§‹å‘è¨€é‡ŒåŒ¹é… dialogs ----\n",
    "        dialogs = match_dialogs_by_time(parsed_msgs, date, sub_time_axis)\n",
    "\n",
    "        # ---- 3ï¼‰æ„é€  discussion_pointï¼ˆä¸æ‰“å°ï¼Œåªç”¨æ¥å†™ promptï¼‰----\n",
    "        discussion_point = (\n",
    "    \n",
    "            sub.get(\"æ ¸å¿ƒå¯¹è±¡/æœºåˆ¶\")\n",
    "            or sub.get(\"è¯é¢˜ç°‡\")\n",
    "            or \"\"\n",
    "        )\n",
    "        topic_id = sub.get(\"_cluster_id\", cid)\n",
    "        \n",
    "        # ---- 4ï¼‰æ¨¡å‹4 ç©å®¶å‘è¨€æ„Ÿå—åˆ†ææ€»ç»“----\n",
    "        user_prompt4 = build_user_prompt_subcluster_opinion(\n",
    "            topic_id=topic_id,\n",
    "            discussion_point=discussion_point,\n",
    "            dialogs=dialogs,\n",
    "        )\n",
    "        if not isinstance(user_prompt4, str) or not user_prompt4.strip():\n",
    "            print(f\"  âš  user_prompt4 ä¸ºç©ºæˆ–éæ³•ï¼Œè·³è¿‡æœ¬å­è¯é¢˜ç°‡ï¼š{cid}\")\n",
    "            continue\n",
    "        opinion_output = call_ark_chat_completions(\n",
    "            api_url=API_URL,\n",
    "            api_key=API_KEY,\n",
    "            model=V3_1_MODEL_ID,             \n",
    "            system_prompt=system_prompt04,   \n",
    "            user_prompt=user_prompt4,\n",
    "            temperature=TEMPERATURE,\n",
    "            max_tokens=MAX_TOKENS,\n",
    "            timeout=TIMEOUT_SEC,\n",
    "            retries=RETRIES,\n",
    "        )\n",
    "\n",
    "\n",
    "       \n",
    "    opinion_obj = parse_and_normalize_opinion_output(\n",
    "        opinion_output=opinion_output,\n",
    "        topic_id=topic_id,\n",
    "        discussion_point=discussion_point,\n",
    "    )\n",
    "    sub_opinion_map[topic_id] = opinion_obj\n",
    "# ===================================\n",
    "# ç»„è£… Top5 + è§‚ç‚¹æ€»ç»“ï¼Œå¹¶å†™å…¥ jsonl\n",
    "# ===================================\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0b52dd6-8cd5-46f1-88de-2691129b86b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#æ¯æ—¥æ€»å‘è¨€è½¬å•æ¡jonslæ ¼å¼\n",
    "parsed_subclusters = [\n",
    "    json.loads(line.strip()) for line in all_cluster.strip().splitlines() if line.strip()\n",
    "]\n",
    "\n",
    "# è§£æåŸå§‹å‘è¨€ jsonlï¼Œä¸ºæŒ‰æ—¶é—´è½´ç­›é€‰å¯¹è¯ç”¨\n",
    "parsed_msgs = [json.loads(line.strip()) for line in jsonl_lines01 if line.strip()]\n",
    "\n",
    "#æ¯æ—¥èšåˆåè¯æç°‡è½¬å•æ¡jsonlæ ¼å¼\n",
    "parsed_clusters = [json.loads(line) for line in output_cluster_agg.strip().splitlines() if line.strip()]\n",
    "\n",
    "#è®¡ç®—æ¯æ—¥è®¨è®ºçƒ­åº¦top5\n",
    "top5_results = extract_top5_heat_clusters(parsed_clusters, jsonl_lines01, top_k=5)\n",
    "\n",
    "#######æå–å­è¯æç°‡è®¨è®ºç‚¹###########################################################\n",
    "####### å»ºå­ç°‡ç´¢å¼•ï¼š_cluster_id -> å­ç°‡å¯¹è±¡ ########\n",
    "sub_map = {}\n",
    "for row in parsed_subclusters:\n",
    "    cid = row.get(\"_cluster_id\")\n",
    "    if isinstance(cid, str) and cid:\n",
    "        sub_map[cid] = row\n",
    "\n",
    "####### åœ¨ Top5 å¾ªç¯é‡Œï¼Œå¯¹æ¯ä¸ªã€å­è¯é¢˜ç°‡ã€‘å•ç‹¬è·‘æ¨¡å‹#4 ########\n",
    "for cluster in top5_results:\n",
    "    date = cluster[\"æ—¥æœŸ\"]\n",
    "    # èšåˆç°‡çš„æ•´ä½“æ—¶é—´è½´ï¼ˆåªç”¨æ¥å…œåº•ï¼‰\n",
    "    cluster_time_axis = cluster[\"æ—¶é—´è½´\"]\n",
    "    cid_list = cluster.get(\"å­è¯é¢˜ç°‡åˆ—è¡¨\", [])\n",
    "\n",
    "    for cid in cid_list:\n",
    "        sub = sub_map.get(cid)\n",
    "        if not sub:\n",
    "            print(f\"\\n[èšåˆè¯é¢˜ç°‡ï¼š{cluster.get('èšåˆè¯é¢˜ç°‡')}] å­è¯é¢˜ç°‡ IDï¼š{cid}\")\n",
    "            print(\"  âš  åœ¨ sub_map / parsed_subclusters ä¸­æœªæ‰¾åˆ°è¯¥ _cluster_idã€‚\")\n",
    "            continue\n",
    "\n",
    "        \n",
    "        # ---- 1ï¼‰ä»å­è¯é¢˜ç°‡ã€æ ‡é¢˜ã€‘é‡Œæå–æ—¶é—´è½´ ----\n",
    "        sub_title = sub.get(\"è¯é¢˜ç°‡\", \"\") or \"\"\n",
    "        sub_time_axis = extract_time_axis_from_title(sub_title)\n",
    "\n",
    "        # ---- 2ï¼‰æŒ‰ã€å­è¯æç°‡æ—¶é—´è½´ã€‘ä»åŸå§‹å‘è¨€é‡ŒåŒ¹é… dialogs ----\n",
    "        dialogs = match_dialogs_by_time(parsed_msgs, date, sub_time_axis)\n",
    "\n",
    "        # ---- 3ï¼‰æ„é€  discussion_pointï¼ˆä¸æ‰“å°ï¼Œåªç”¨æ¥å†™ promptï¼‰----\n",
    "        discussion_point = (\n",
    "    \n",
    "            sub.get(\"æ ¸å¿ƒå¯¹è±¡/æœºåˆ¶\")\n",
    "            or sub.get(\"è¯é¢˜ç°‡\")\n",
    "            or \"\"\n",
    "        )\n",
    "        topic_id = sub.get(\"_cluster_id\", cid)\n",
    "        \n",
    "        # ---- 4ï¼‰æ¨¡å‹4 ç©å®¶å‘è¨€æ„Ÿå—åˆ†ææ€»ç»“----\n",
    "        user_prompt4 = build_user_prompt_subcluster_opinion(\n",
    "            topic_id=topic_id,\n",
    "            discussion_point=discussion_point,\n",
    "            dialogs=dialogs,\n",
    "        )\n",
    "        if not isinstance(user_prompt4, str) or not user_prompt4.strip():\n",
    "            print(f\"  âš  user_prompt4 ä¸ºç©ºæˆ–éæ³•ï¼Œè·³è¿‡æœ¬å­è¯é¢˜ç°‡ï¼š{cid}\")\n",
    "            continue\n",
    "        opinion_output = call_ark_chat_completions(\n",
    "            api_url=API_URL,\n",
    "            api_key=API_KEY,\n",
    "            model=V3_1_MODEL_ID,             \n",
    "            system_prompt=system_prompt04,   \n",
    "            user_prompt=user_prompt4,\n",
    "            temperature=TEMPERATURE,\n",
    "            max_tokens=MAX_TOKENS,\n",
    "            timeout=TIMEOUT_SEC,\n",
    "            retries=RETRIES,\n",
    "        )\n",
    "\n",
    "\n",
    "       \n",
    "    opinion_obj = parse_and_normalize_opinion_output(\n",
    "        opinion_output=opinion_output,\n",
    "        topic_id=topic_id,\n",
    "        discussion_point=discussion_point,\n",
    "    )\n",
    "    sub_opinion_map[topic_id] = opinion_obj\n",
    "# ===================================\n",
    "# ç»„è£… Top5 + è§‚ç‚¹æ€»ç»“ï¼Œå¹¶å†™å…¥ jsonl\n",
    "# ===================================\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ada78d16-fe72-4a92-94d2-8b626ef64d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš  å­è¯é¢˜ç°‡ 2025-12-04_B1_01 æœªåœ¨ sub_opinion_map ä¸­æ‰¾åˆ°æ¨¡å‹#4ç»“æœï¼Œè·³è¿‡ã€‚\n",
      "âš  å­è¯é¢˜ç°‡ 2025-12-04_B3_01 æœªåœ¨ sub_opinion_map ä¸­æ‰¾åˆ°æ¨¡å‹#4ç»“æœï¼Œè·³è¿‡ã€‚\n",
      "âš  å­è¯é¢˜ç°‡ 2025-12-04_B5_01 æœªåœ¨ sub_opinion_map ä¸­æ‰¾åˆ°æ¨¡å‹#4ç»“æœï¼Œè·³è¿‡ã€‚\n",
      "âœ… å·²å°†å½“æ—¥ Top5ï¼ˆå« _idx å’Œ _daily_top_idï¼‰è¿½åŠ å†™å…¥: version_daily_top5_with_opinion.jsonl\n"
     ]
    }
   ],
   "source": [
    "final_top5_with_opinion = build_daily_top5_opinion_records(\n",
    "    top5_results=top5_results,\n",
    "    sub_opinion_map=sub_opinion_map,\n",
    ")\n",
    "\n",
    "append_daily_top5_to_version_jsonl(\n",
    "    final_result=final_top5_with_opinion,\n",
    "    version_jsonl_path=\"version_daily_top5_with_opinion.jsonl\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dfa2bb40-0ca1-4558-a350-06dbc11c2e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2025-12-02_B1_03', '2025-12-02_B1_14', '2025-12-02_B2_07']\n",
      "{'è¯é¢˜ç°‡': 'æ¸¸æˆç‰©å“å¼‚å¸¸é—®é¢˜åé¦ˆï¼ˆ2025-12-02 22:57:27-22:57:31ï¼‰', 'æ ¸å¿ƒå¯¹è±¡/æœºåˆ¶': 'æ¸¸æˆå†…ç‰©å“å¼‚å¸¸æ¶ˆå¤±é—®é¢˜çš„åé¦ˆä¸å¤„ç†', '_cluster_id': '2025-12-02_B2_07'}\n",
      "æ¸¸æˆç‰©å“å¼‚å¸¸é—®é¢˜åé¦ˆï¼ˆ2025-12-02 22:57:27-22:57:31ï¼‰\n",
      "22:57:27-22:57:31\n",
      "æ¸¸æˆå†…ç‰©å“å¼‚å¸¸æ¶ˆå¤±é—®é¢˜çš„åé¦ˆä¸å¤„ç†\n",
      "[{'å‘è¨€æ—¥æœŸ': '2025-12-02', 'å‘è¨€æ—¶é—´': '22:57:27', 'ç©å®¶ID': 'æ— ä¸ºæ— ç•(2514177080)', 'ç©å®¶æ¶ˆæ¯': '[å›¾ç‰‡]'}, {'å‘è¨€æ—¥æœŸ': '2025-12-02', 'å‘è¨€æ—¶é—´': '22:57:31', 'ç©å®¶ID': 'æ— ä¸ºæ— ç•(2514177080)', 'ç©å®¶æ¶ˆæ¯': 'ä¸œè¥¿æ²¡äº†'}]\n",
      "2025-12-02_B2_07\n"
     ]
    }
   ],
   "source": [
    "print(cid_list)\n",
    "print(sub)\n",
    "\n",
    "print(sub_title)\n",
    "print(sub_time_axis)\n",
    "print(discussion_point)\n",
    "print(dialogs)\n",
    "print(cid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21cb4444-2eeb-41e2-9797-1d5eeb074f05",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'continue' not properly in loop (1099491447.py, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[13], line 10\u001b[1;36m\u001b[0m\n\u001b[1;33m    continue\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m 'continue' not properly in loop\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    obj = json.loads(line)\n",
    "except json.JSONDecodeError as e:\n",
    "    print(\n",
    "        f\"[æ‰¹æ¬¡ {b+1}] âš  è§£ææ¨¡å‹#2 è¾“å‡º JSON å¤±è´¥ï¼š{e}ï¼Œè¡Œå†…å®¹ï¼š{line!r}\"\n",
    "    )\n",
    "    print(\"=== è¯¥æ‰¹æ¬¡æ¨¡å‹#2 åŸå§‹å®Œæ•´è¾“å‡ºï¼ˆè°ƒè¯•ç”¨ï¼‰ ===\")\n",
    "    print(output_cluster)\n",
    "    print(\"=== â†‘â†‘â†‘ è¯·æŸ¥çœ‹è¿™ä¸€æ‰¹è¾“å‡ºä¸­å“ªé‡Œæœ‰å¤šä½™çš„å¤§æ‹¬å·/å¥‡æ€ªå­—ç¬¦ â†‘â†‘â†‘ ===\")\n",
    "    continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "34e8df2c-b759-4281-9782-4a53a6602c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'èšåˆè¯é¢˜ç°‡': 'ç²¾ç¥åŠ›æ¢å¤ä¸é©¾é©¶å‘˜æ­»äº¡æœºåˆ¶', 'å­è¯é¢˜ç°‡åˆ—è¡¨': ['2025-12-04_B1_01', '2025-12-04_B3_01', '2025-12-04_B5_01', '2025-12-04_B7_01'], 'æ—¥æœŸ': '2025-12-04', 'æ—¶é—´è½´': '00:16:08-00:16:44ã€11:35:58-11:38:28ã€15:03:41-15:03:41ã€19:31:23-19:31:42', 'å‘è¨€ç©å®¶æ€»æ•°': 10, 'å‘è¨€æ€»æ•°': 36, 'çƒ­åº¦è¯„åˆ†': 60.0}, {'èšåˆè¯é¢˜ç°‡': 'å‘æ—¥è‘µèŠ±å›­ä»“åº“å¡å…³é—®é¢˜', 'å­è¯é¢˜ç°‡åˆ—è¡¨': ['2025-12-04_B4_01'], 'æ—¥æœŸ': '2025-12-04', 'æ—¶é—´è½´': '12:24:48-12:28:54', 'å‘è¨€ç©å®¶æ€»æ•°': 6, 'å‘è¨€æ€»æ•°': 32, 'çƒ­åº¦è¯„åˆ†': 33.94}, {'èšåˆè¯é¢˜ç°‡': 'æ¸¸æˆç•Œé¢BUGä¸æ˜¾ç¤ºå¼‚å¸¸', 'å­è¯é¢˜ç°‡åˆ—è¡¨': ['2025-12-04_B8_01'], 'æ—¥æœŸ': '2025-12-04', 'æ—¶é—´è½´': '23:57:14-23:59:10', 'å‘è¨€ç©å®¶æ€»æ•°': 1, 'å‘è¨€æ€»æ•°': 6, 'çƒ­åº¦è¯„åˆ†': 2.45}, {'èšåˆè¯é¢˜ç°‡': 'åœ°å›¾ç¼©æ”¾åŠŸèƒ½ä½“éªŒä¼˜åŒ–', 'å­è¯é¢˜ç°‡åˆ—è¡¨': ['2025-12-04_B2_01'], 'æ—¥æœŸ': '2025-12-04', 'æ—¶é—´è½´': '10:08:53-10:09:16', 'å‘è¨€ç©å®¶æ€»æ•°': 1, 'å‘è¨€æ€»æ•°': 5, 'çƒ­åº¦è¯„åˆ†': 2.24}]\n"
     ]
    }
   ],
   "source": [
    "print(top5_results )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "385e4733-358c-46e0-91ef-5d86f7da4e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== DEBUG æ¨¡å‹#4é˜¶æ®µ =====\n",
      "cid: 2025-12-04_B1_01\n",
      "sub_title: ç²¾ç¥åŠ›æ¢å¤ä¸é©¾é©¶å‘˜æ­»äº¡æœºåˆ¶ï¼ˆ2025-12-04 00:16:08-00:16:44ï¼‰\n",
      "sub_time_axis: 00:16:08-00:16:44\n",
      "dialogs æ¡æ•°: 15\n",
      "user_prompt4 å‰ 200 å­—:\n",
      "ç¦æ­¢ä½¿ç”¨ ```json æˆ– ``` ç­‰ Markdown ä»£ç å—ï¼Œç¦æ­¢è¾“å‡ºè§£é‡Šæ–‡å­—ã€‚\n",
      "\n",
      "ã€è¾“å…¥ã€‘æœ¬æ¬¡æ‰€æœ‰æ•°æ®ï¼ˆJSONLï¼Œç¬¬ä¸€è¡Œä¸ºè¯é¢˜ç°‡ä¿¡æ¯ï¼Œå…¶ä½™ä¸ºå‘è¨€ï¼‰ï¼š\n",
      "{\"è¯é¢˜ç°‡ID\": \"2025-12-04_B1_01\", \"è®¨è®ºç‚¹\": \"ç²¾ç¥åŠ›è¡¥å……æ–¹å¼ä¸é©¾é©¶å‘˜æ­»äº¡å¤æ´»æœºåˆ¶\"}\n",
      "{\"å‘è¨€æ—¥æœŸ\": \"2025-12-04\", \"å‘è¨€æ—¶é—´\": \"00:16:08\", \"ç©å®¶ID\": \"1(34771858\n",
      "opinion_output åŸå§‹å†…å®¹:\n",
      "{\"è¯é¢˜ç°‡ID\": \"2025-12-04_B2_01\", \"è®¨è®ºç‚¹\": \"åœ°å›¾ç¼©æ”¾åŠŸèƒ½çš„ä½¿ç”¨ä½“éªŒä¸ä¼˜åŒ–å»ºè®®\", \"ç©å®¶å…±è¯†\": \"ç©å®¶æ™®éè®¤ä¸ºå½“å‰åœ°å›¾ç¼©æ”¾åŠŸèƒ½ä½“éªŒä¸ä½³ï¼Œç¼©æ”¾èŒƒå›´å—é™ä¸”åœ°å›¾è¿‡å¤§å¯¼è‡´æ“ä½œä¸ä¾¿\", \"ç©å®¶ä¸»è¦åˆ†æ­§ç‚¹\": \"æ— æ˜æ˜¾åˆ†æ­§\", \"ä»£è¡¨æ€§ç©å®¶å‘è¨€ç¤ºä¾‹\": [\"ç¼©æ”¾å¥½éš¾å—\", \"ä¸èƒ½å†å°ä¸€ç‚¹ä¹ˆ\", \"@æœ‰ç¼˜åˆ†. åœ°å›¾å¤§äº†\"]}\n",
      "===== END DEBUG =====\n",
      "\n",
      "\n",
      "===== DEBUG æ¨¡å‹#4é˜¶æ®µ =====\n",
      "cid: 2025-12-04_B3_01\n",
      "sub_title: ç²¾ç¥å€¼å›å¤æœºåˆ¶ï¼ˆ2025-12-04 11:35:58-11:38:28ï¼‰\n",
      "sub_time_axis: 11:35:58-11:38:28\n",
      "dialogs æ¡æ•°: 17\n",
      "user_prompt4 å‰ 200 å­—:\n",
      "ç¦æ­¢ä½¿ç”¨ ```json æˆ– ``` ç­‰ Markdown ä»£ç å—ï¼Œç¦æ­¢è¾“å‡ºè§£é‡Šæ–‡å­—ã€‚\n",
      "\n",
      "ã€è¾“å…¥ã€‘æœ¬æ¬¡æ‰€æœ‰æ•°æ®ï¼ˆJSONLï¼Œç¬¬ä¸€è¡Œä¸ºè¯é¢˜ç°‡ä¿¡æ¯ï¼Œå…¶ä½™ä¸ºå‘è¨€ï¼‰ï¼š\n",
      "{\"è¯é¢˜ç°‡ID\": \"2025-12-04_B1_01\", \"è®¨è®ºç‚¹\": \"ç²¾ç¥åŠ›è¡¥å……æ–¹å¼ä¸é©¾é©¶å‘˜æ­»äº¡å¤æ´»æœºåˆ¶\"}\n",
      "{\"å‘è¨€æ—¥æœŸ\": \"2025-12-04\", \"å‘è¨€æ—¶é—´\": \"00:16:08\", \"ç©å®¶ID\": \"1(34771858\n",
      "opinion_output åŸå§‹å†…å®¹:\n",
      "{\"è¯é¢˜ç°‡ID\": \"2025-12-04_B2_01\", \"è®¨è®ºç‚¹\": \"åœ°å›¾ç¼©æ”¾åŠŸèƒ½çš„ä½¿ç”¨ä½“éªŒä¸ä¼˜åŒ–å»ºè®®\", \"ç©å®¶å…±è¯†\": \"ç©å®¶æ™®éè®¤ä¸ºå½“å‰åœ°å›¾ç¼©æ”¾åŠŸèƒ½ä½“éªŒä¸ä½³ï¼Œç¼©æ”¾èŒƒå›´å—é™ä¸”åœ°å›¾è¿‡å¤§å¯¼è‡´æ“ä½œä¸ä¾¿\", \"ç©å®¶ä¸»è¦åˆ†æ­§ç‚¹\": \"æ— æ˜æ˜¾åˆ†æ­§\", \"ä»£è¡¨æ€§ç©å®¶å‘è¨€ç¤ºä¾‹\": [\"ç¼©æ”¾å¥½éš¾å—\", \"ä¸èƒ½å†å°ä¸€ç‚¹ä¹ˆ\", \"@æœ‰ç¼˜åˆ†. åœ°å›¾å¤§äº†\"]}\n",
      "===== END DEBUG =====\n",
      "\n",
      "\n",
      "===== DEBUG æ¨¡å‹#4é˜¶æ®µ =====\n",
      "cid: 2025-12-04_B5_01\n",
      "sub_title: ä½ç²¾ç¥å€¼é€æ€ªç­–ç•¥ï¼ˆ2025-12-04 15:03:41-15:03:41ï¼‰\n",
      "sub_time_axis: 15:03:41-15:03:41\n",
      "dialogs æ¡æ•°: 1\n",
      "user_prompt4 å‰ 200 å­—:\n",
      "ç¦æ­¢ä½¿ç”¨ ```json æˆ– ``` ç­‰ Markdown ä»£ç å—ï¼Œç¦æ­¢è¾“å‡ºè§£é‡Šæ–‡å­—ã€‚\n",
      "\n",
      "ã€è¾“å…¥ã€‘æœ¬æ¬¡æ‰€æœ‰æ•°æ®ï¼ˆJSONLï¼Œç¬¬ä¸€è¡Œä¸ºè¯é¢˜ç°‡ä¿¡æ¯ï¼Œå…¶ä½™ä¸ºå‘è¨€ï¼‰ï¼š\n",
      "{\"è¯é¢˜ç°‡ID\": \"2025-12-04_B1_01\", \"è®¨è®ºç‚¹\": \"ç²¾ç¥åŠ›è¡¥å……æ–¹å¼ä¸é©¾é©¶å‘˜æ­»äº¡å¤æ´»æœºåˆ¶\"}\n",
      "{\"å‘è¨€æ—¥æœŸ\": \"2025-12-04\", \"å‘è¨€æ—¶é—´\": \"00:16:08\", \"ç©å®¶ID\": \"1(34771858\n",
      "opinion_output åŸå§‹å†…å®¹:\n",
      "{\"è¯é¢˜ç°‡ID\": \"2025-12-04_B2_01\", \"è®¨è®ºç‚¹\": \"åœ°å›¾ç¼©æ”¾åŠŸèƒ½çš„ä½¿ç”¨ä½“éªŒä¸ä¼˜åŒ–å»ºè®®\", \"ç©å®¶å…±è¯†\": \"ç©å®¶æ™®éè®¤ä¸ºå½“å‰åœ°å›¾ç¼©æ”¾åŠŸèƒ½ä½“éªŒä¸ä½³ï¼Œç¼©æ”¾èŒƒå›´å—é™ä¸”åœ°å›¾è¿‡å¤§å¯¼è‡´æ“ä½œä¸ä¾¿\", \"ç©å®¶ä¸»è¦åˆ†æ­§ç‚¹\": \"æ— æ˜æ˜¾åˆ†æ­§\", \"ä»£è¡¨æ€§ç©å®¶å‘è¨€ç¤ºä¾‹\": [\"ç¼©æ”¾å¥½éš¾å—\", \"ä¸èƒ½å†å°ä¸€ç‚¹ä¹ˆ\", \"@æœ‰ç¼˜åˆ†. åœ°å›¾å¤§äº†\"]}\n",
      "===== END DEBUG =====\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DEBUG_CIDS = {\"2025-12-04_B1_01\", \"2025-12-04_B3_01\", \"2025-12-04_B5_01\"}\n",
    "\n",
    "for cluster in top5_results:\n",
    "    date = cluster[\"æ—¥æœŸ\"]\n",
    "    cid_list = cluster.get(\"å­è¯é¢˜ç°‡åˆ—è¡¨\", [])\n",
    "\n",
    "    for cid in cid_list:\n",
    "        sub = sub_map.get(cid)\n",
    "        if not sub:\n",
    "            print(f\"[DEBUG] å­ç°‡ {cid} åœ¨ sub_map ä¸­ä¸å­˜åœ¨\")\n",
    "            continue\n",
    "\n",
    "        sub_title = sub.get(\"è¯é¢˜ç°‡\", \"\") or \"\"\n",
    "        sub_time_axis = extract_time_axis_from_title(sub_title)\n",
    "        dialogs = match_dialogs_by_time(parsed_msgs, date, sub_time_axis)\n",
    "\n",
    "        discussion_point = (\n",
    "            sub.get(\"æ ¸å¿ƒå¯¹è±¡/æœºåˆ¶\") or sub.get(\"è¯é¢˜ç°‡\") or \"\"\n",
    "        )\n",
    "        topic_id = sub.get(\"_cluster_id\", cid)\n",
    "\n",
    "      \n",
    "\n",
    "        if cid in DEBUG_CIDS:\n",
    "            print(\"\\n===== DEBUG æ¨¡å‹#4é˜¶æ®µ =====\")\n",
    "            print(\"cid:\", cid)\n",
    "            print(\"sub_title:\", sub_title)\n",
    "            print(\"sub_time_axis:\", sub_time_axis)\n",
    "            print(\"dialogs æ¡æ•°:\", len(dialogs))\n",
    "            print(\"user_prompt4 å‰ 200 å­—:\")\n",
    "            print(user_prompt4[:200])\n",
    "            print(\"opinion_output åŸå§‹å†…å®¹:\")\n",
    "            print(opinion_output)\n",
    "            print(\"===== END DEBUG =====\\n\")\n",
    "\n",
    "        opinion_obj = parse_and_normalize_opinion_output(\n",
    "            opinion_output=opinion_output,\n",
    "            topic_id=topic_id,\n",
    "            discussion_point=discussion_point,\n",
    "        )\n",
    "\n",
    "        if not opinion_obj:\n",
    "            print(f\"  âš  æ¨¡å‹#4è¾“å‡ºä¸­æœªæ‰¾åˆ°åˆæ³• JSONï¼š{cid}\")\n",
    "            continue\n",
    "\n",
    "        sub_opinion_map[topic_id] = opinion_obj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa7dbd9-de74-414b-a4c7-12bf40a5c9df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
