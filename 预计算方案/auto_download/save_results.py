"""
å°†åˆ†æç»“æœæŒ‰ç¾¤åˆ†åˆ«ä¿å­˜åˆ° results ç›®å½•å¹¶æ¨é€åˆ° GitHub

ç»“æ„:
    results/
    â”œâ”€â”€ group1/          # ç¾¤1 æ¯æ—¥ç»“æœ
    â”‚   â”œâ”€â”€ index.json
    â”‚   â””â”€â”€ 2025-12-17.json
    â”œâ”€â”€ group2/          # ç¾¤2 æ¯æ—¥ç»“æœ
    â”‚   â”œâ”€â”€ index.json
    â”‚   â””â”€â”€ 2025-12-17.json
    â””â”€â”€ index.json       # æ€»ç´¢å¼•

ä½¿ç”¨æ–¹å¼:
    # ä¿å­˜ç¾¤1ä»Šå¤©çš„ç»“æœï¼ˆç²˜è´´æ¨¡å¼ï¼‰
    python save_results.py --group 1 --paste
    
    # ä¿å­˜ç¾¤2ä»Šå¤©çš„ç»“æœï¼ˆç²˜è´´æ¨¡å¼ï¼‰
    python save_results.py --group 2 --paste
    
    # ä¿å­˜åæ¨é€åˆ° GitHub
    python save_results.py --group 1 --paste --push
    
    # ä»æ–‡ä»¶è¯»å–ä¿å­˜
    python save_results.py --group 1 --file output.json --push
"""
import json
import os
import subprocess
import sys
from pathlib import Path
from datetime import datetime
from collections import defaultdict

# è·¯å¾„é…ç½®
PROJECT_ROOT = Path(__file__).parent.parent.parent
SOURCE_DIR = PROJECT_ROOT / "ç©å®¶å‘è¨€æ•´ç†ï¼ˆä¾›è¿è¥ä¾§ï¼‰" / "ç©å®¶å‘è¨€æ€»ç»“_ç‰ˆæœ¬æ€»ç»“V2-Copy1.0(å•æ—¥ï¼‰"
RESULTS_DIR = PROJECT_ROOT / "é¢„è®¡ç®—æ–¹æ¡ˆ" / "results"

# ç¾¤é…ç½®
GROUPS = {
    "1": {"name": "åœ°çƒç¾¤1", "dir": "group1"},
    "2": {"name": "åœ°çƒç¾¤2", "dir": "group2"},
}


def get_group_dir(group_id: str) -> Path:
    """è·å–ç¾¤çš„ç»“æœç›®å½•"""
    group = GROUPS.get(group_id)
    if not group:
        raise ValueError(f"æœªçŸ¥çš„ç¾¤ID: {group_id}")
    return RESULTS_DIR / group["dir"]


def save_from_paste(group_id: str) -> bool:
    """
    ä»ç²˜è´´çš„ JSON å†…å®¹ä¿å­˜ç»“æœ
    """
    group = GROUPS.get(group_id)
    if not group:
        print(f"âŒ æœªçŸ¥çš„ç¾¤ID: {group_id}")
        return False
    
    print("=" * 60)
    print(f"ğŸ“‹ ç²˜è´´æ¨¡å¼ - ä¿å­˜ {group['name']} çš„ç»“æœ")
    print("=" * 60)
    print()
    print("è¯·ç²˜è´´ Notebook è¾“å‡ºçš„ JSON å†…å®¹")
    print("(æ”¯æŒå¤šä¸ª JSON å¯¹è±¡ï¼Œè¾“å…¥ç©ºè¡Œä¸¤æ¬¡ç»“æŸ)")
    print("-" * 40)
    
    lines = []
    empty_count = 0
    
    while True:
        try:
            line = input()
            if line.strip() == "":
                empty_count += 1
                if empty_count >= 2:
                    break
            else:
                empty_count = 0
                lines.append(line)
        except EOFError:
            break
    
    content = "\n".join(lines)
    
    if not content.strip():
        print("âŒ æ²¡æœ‰è¾“å…¥å†…å®¹")
        return False
    
    # è§£æ JSON
    results = parse_json_content(content)
    
    if not results:
        print("âŒ æœªèƒ½è§£æå‡ºæœ‰æ•ˆçš„ JSON æ•°æ®")
        return False
    
    # ä¿å­˜ç»“æœ
    return save_results_to_group(group_id, results)


def save_from_file(group_id: str, file_path: Path) -> bool:
    """ä»æ–‡ä»¶è¯»å–å¹¶ä¿å­˜ç»“æœ"""
    if not file_path.exists():
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        return False
    
    print(f"ğŸ“„ ä»æ–‡ä»¶è¯»å–: {file_path}")
    
    with open(file_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    results = parse_json_content(content)
    
    if not results:
        print("âŒ æœªèƒ½è§£æå‡ºæœ‰æ•ˆçš„ JSON æ•°æ®")
        return False
    
    return save_results_to_group(group_id, results)


def parse_json_content(content: str) -> list:
    """è§£æ JSON å†…å®¹ï¼ˆæ”¯æŒå¤šç§æ ¼å¼ï¼‰"""
    results = []
    
    # å°è¯•ä½œä¸ºå•ä¸ª JSON æ•°ç»„è§£æ
    try:
        data = json.loads(content)
        if isinstance(data, list):
            return data
        else:
            return [data]
    except json.JSONDecodeError:
        pass
    
    # å°è¯•æŒ‰ }{ åˆ†å‰²ï¼ˆå¤šä¸ªè¿ç»­ JSON å¯¹è±¡ï¼‰
    content_fixed = content.replace("}\n{", "}|||{").replace("}{", "}|||{")
    parts = content_fixed.split("|||")
    
    for part in parts:
        part = part.strip()
        if part:
            try:
                results.append(json.loads(part))
            except json.JSONDecodeError:
                # å°è¯• JSONL æ ¼å¼ï¼ˆæ¯è¡Œä¸€ä¸ª JSONï¼‰
                for line in part.split("\n"):
                    line = line.strip()
                    if line:
                        try:
                            results.append(json.loads(line))
                        except:
                            continue
    
    return results


def save_results_to_group(group_id: str, results: list) -> bool:
    """ä¿å­˜ç»“æœåˆ°æŒ‡å®šç¾¤çš„ç›®å½•"""
    group = GROUPS.get(group_id)
    group_dir = get_group_dir(group_id)
    group_dir.mkdir(parents=True, exist_ok=True)
    
    print(f"\nâœ… è§£æåˆ° {len(results)} æ¡è®°å½•")
    
    # æŒ‰æ—¥æœŸåˆ†ç»„
    by_date = defaultdict(list)
    for record in results:
        date = record.get("æ—¥æœŸ", "unknown")
        by_date[date].append(record)
    
    print(f"ğŸ“… åŒ…å« {len(by_date)} ä¸ªæ—¥æœŸçš„æ•°æ®:")
    for date in sorted(by_date.keys()):
        print(f"   {date}: {len(by_date[date])} æ¡è¯é¢˜ç°‡")
    
    # ä¿å­˜æ¯æ—¥ç»“æœ
    saved_files = []
    for date in sorted(by_date.keys()):
        if date == "unknown":
            continue
        
        clusters = by_date[date]
        
        # æ„å»ºç»“æœ
        result = {
            "group": group["name"],
            "group_id": group_id,
            "date": date,
            "generated_at": datetime.now().isoformat(),
            "clusters": clusters,
            "summary": {
                "total_clusters": len(clusters),
                "total_players": sum(c.get("å‘è¨€ç©å®¶æ€»æ•°", 0) for c in clusters),
                "total_messages": sum(c.get("å‘è¨€æ€»æ•°", 0) for c in clusters),
                "top_cluster": max(clusters, key=lambda x: x.get("çƒ­åº¦è¯„åˆ†", 0)).get("èšåˆè¯é¢˜ç°‡", "") if clusters else "",
            }
        }
        
        # ä¿å­˜
        output_file = group_dir / f"{date}.json"
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(result, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… å·²ä¿å­˜: {group['dir']}/{date}.json")
        saved_files.append(output_file)
    
    # æ›´æ–°ç¾¤ç´¢å¼•
    update_group_index(group_id)
    
    # æ›´æ–°æ€»ç´¢å¼•
    update_main_index()
    
    print(f"\nğŸ“Š {group['name']} å…±ä¿å­˜ {len(saved_files)} ä¸ªæ—¥æœŸçš„ç»“æœ")
    return True


def update_group_index(group_id: str):
    """æ›´æ–°ç¾¤çš„ç´¢å¼•æ–‡ä»¶"""
    group = GROUPS.get(group_id)
    group_dir = get_group_dir(group_id)
    
    # æ‰«ææ‰€æœ‰æ—¥æœŸæ–‡ä»¶
    dates = []
    for f in group_dir.glob("*.json"):
        if f.name != "index.json":
            dates.append(f.stem)
    
    index = {
        "group": group["name"],
        "group_id": group_id,
        "updated_at": datetime.now().isoformat(),
        "available_dates": sorted(dates, reverse=True),  # æœ€æ–°æ—¥æœŸåœ¨å‰
        "total_days": len(dates),
    }
    
    index_file = group_dir / "index.json"
    with open(index_file, 'w', encoding='utf-8') as f:
        json.dump(index, f, ensure_ascii=False, indent=2)


def update_main_index():
    """æ›´æ–°æ€»ç´¢å¼•æ–‡ä»¶"""
    RESULTS_DIR.mkdir(parents=True, exist_ok=True)
    
    groups_info = []
    all_dates = set()
    
    for group_id, group in GROUPS.items():
        group_dir = RESULTS_DIR / group["dir"]
        if group_dir.exists():
            index_file = group_dir / "index.json"
            if index_file.exists():
                with open(index_file, 'r', encoding='utf-8') as f:
                    group_index = json.load(f)
                    groups_info.append({
                        "group_id": group_id,
                        "name": group["name"],
                        "total_days": group_index.get("total_days", 0),
                        "latest_date": group_index.get("available_dates", [""])[0] if group_index.get("available_dates") else "",
                    })
                    all_dates.update(group_index.get("available_dates", []))
    
    index = {
        "updated_at": datetime.now().isoformat(),
        "groups": groups_info,
        "all_dates": sorted(all_dates, reverse=True),
        "total_days": len(all_dates),
    }
    
    index_file = RESULTS_DIR / "index.json"
    with open(index_file, 'w', encoding='utf-8') as f:
        json.dump(index, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… å·²æ›´æ–°æ€»ç´¢å¼•")


def git_push():
    """æ¨é€åˆ° GitHub"""
    print()
    print("=" * 60)
    print("ğŸš€ æ¨é€åˆ° GitHub")
    print("=" * 60)
    print()
    
    try:
        os.chdir(PROJECT_ROOT)
        
        # git add
        subprocess.run(["git", "add", "é¢„è®¡ç®—æ–¹æ¡ˆ/results/"], check=True)
        print("âœ… git add å®Œæˆ")
        
        # git commit
        commit_msg = f"[è‡ªåŠ¨] æ›´æ–°åˆ†æç»“æœ {datetime.now().strftime('%Y-%m-%d %H:%M')}"
        result = subprocess.run(
            ["git", "commit", "-m", commit_msg],
            capture_output=True,
            text=True
        )
        if result.returncode == 0:
            print(f"âœ… git commit å®Œæˆ: {commit_msg}")
        else:
            if "nothing to commit" in result.stdout or "nothing to commit" in result.stderr:
                print("â„¹ï¸ æ²¡æœ‰æ–°çš„æ›´æ”¹éœ€è¦æäº¤")
                return True
            else:
                print(f"âš ï¸ commit è¾“å‡º: {result.stderr or result.stdout}")
        
        # git push
        result = subprocess.run(
            ["git", "push"],
            capture_output=True,
            text=True,
            timeout=60
        )
        if result.returncode == 0:
            print("âœ… git push å®Œæˆ!")
            return True
        else:
            print(f"âŒ push å¤±è´¥: {result.stderr}")
            return False
            
    except subprocess.CalledProcessError as e:
        print(f"âŒ Git æ“ä½œå¤±è´¥: {e}")
        return False
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        return False


def main():
    import argparse
    parser = argparse.ArgumentParser(description="ä¿å­˜ç¾¤åˆ†æç»“æœåˆ° results ç›®å½•")
    parser.add_argument("--group", "-g", type=str, required=True, choices=["1", "2"],
                       help="ç¾¤ID: 1=åœ°çƒç¾¤1, 2=åœ°çƒç¾¤2")
    parser.add_argument("--paste", "-p", action="store_true", 
                       help="ç²˜è´´æ¨¡å¼ï¼šç›´æ¥ç²˜è´´ JSON å†…å®¹ä¿å­˜")
    parser.add_argument("--file", "-f", type=str, 
                       help="ä»æŒ‡å®šæ–‡ä»¶è¯»å–ç»“æœ")
    parser.add_argument("--push", action="store_true", 
                       help="ä¿å­˜åæ¨é€åˆ° GitHub")
    args = parser.parse_args()
    
    success = False
    
    if args.paste:
        success = save_from_paste(args.group)
    elif args.file:
        success = save_from_file(args.group, Path(args.file))
    else:
        print("âŒ è¯·æŒ‡å®š --paste æˆ– --file å‚æ•°")
        parser.print_help()
        sys.exit(1)
    
    if success and args.push:
        git_push()
    
    print()
    print("=" * 60)
    if success:
        print("ğŸ‰ å®Œæˆ!")
    else:
        print("âŒ æ“ä½œå¤±è´¥")
    print("=" * 60)


if __name__ == "__main__":
    main()
