"""
å°†æ¯æ—¥è¾“å‡ºæ ¼å¼è½¬æ¢ä¸ºç¬¦åˆæ•°æ®åº“æ ¼å¼çš„ JSON æ–‡ä»¶
æ”¯æŒä»å¤šä¸ª JSON å¯¹è±¡è½¬æ¢ä¸ºå®Œæ•´çš„åˆ†æç»“æœæ–‡ä»¶
"""
import json
import sys
import re
from pathlib import Path
from datetime import datetime
from typing import List, Dict

PROJECT_ROOT = Path(__file__).parent.parent

def parse_multiple_json_objects(text: str) -> List[Dict]:
    """
    ä»æ–‡æœ¬ä¸­è§£æå¤šä¸ªç‹¬ç«‹çš„ JSON å¯¹è±¡
    æ”¯æŒå¤šä¸ª JSON å¯¹è±¡ç”¨æ¢è¡Œåˆ†éš”
    """
    objects = []
    
    # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æ‰¾åˆ°æ‰€æœ‰ç‹¬ç«‹çš„ JSON å¯¹è±¡
    # åŒ¹é…ä» { å¼€å§‹åˆ° } ç»“æŸçš„å®Œæ•´ JSON å¯¹è±¡
    pattern = r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}'
    
    # æ›´ç®€å•çš„æ–¹æ³•ï¼šæŒ‰è¡Œåˆ†å‰²ï¼Œç„¶åå°è¯•è§£ææ¯ä¸ª JSON å¯¹è±¡
    # ä½†æ›´å¥½çš„æ–¹æ³•æ˜¯æ‰¾åˆ°å®Œæ•´çš„ JSON å¯¹è±¡
    current_obj = ""
    brace_count = 0
    in_string = False
    escape_next = False
    
    for char in text:
        if escape_next:
            escape_next = False
            current_obj += char
            continue
            
        if char == '\\':
            escape_next = True
            current_obj += char
            continue
            
        if char == '"' and not escape_next:
            in_string = not in_string
            
        if not in_string:
            if char == '{':
                if brace_count == 0:
                    current_obj = ""
                brace_count += 1
            elif char == '}':
                brace_count -= 1
                
        current_obj += char
        
        # å½“ brace_count ä¸º 0 ä¸”ä¸åœ¨å­—ç¬¦ä¸²ä¸­æ—¶ï¼Œè¯´æ˜ä¸€ä¸ªå®Œæ•´çš„ JSON å¯¹è±¡ç»“æŸäº†
        if brace_count == 0 and current_obj.strip() and not in_string:
            try:
                obj = json.loads(current_obj.strip())
                objects.append(obj)
            except json.JSONDecodeError as e:
                print(f"âš ï¸ è§£æ JSON å¯¹è±¡æ—¶å‡ºé”™: {e}")
                print(f"   å†…å®¹ç‰‡æ®µ: {current_obj[:200]}...")
            current_obj = ""
    
    return objects

def calculate_summary(clusters: List[Dict]) -> Dict:
    """è®¡ç®— summary ç»Ÿè®¡ä¿¡æ¯"""
    total_clusters = len(clusters)
    
    # è®¡ç®—æ€»ç©å®¶æ•°å’Œæ€»å‘è¨€æ•°ï¼ˆå¯èƒ½æœ‰é‡å¤ï¼Œä½†æŒ‰æ ¼å¼åº”è¯¥æ˜¯æ€»å’Œï¼‰
    total_players = sum(c.get("å‘è¨€ç©å®¶æ€»æ•°", 0) for c in clusters)
    total_messages = sum(c.get("å‘è¨€æ€»æ•°", 0) for c in clusters)
    
    # æ‰¾åˆ°çƒ­åº¦æœ€é«˜çš„è¯é¢˜ç°‡
    top_cluster = ""
    if clusters:
        top_cluster_obj = max(clusters, key=lambda x: x.get("çƒ­åº¦è¯„åˆ†", 0))
        top_cluster = top_cluster_obj.get("èšåˆè¯é¢˜ç°‡", "")
    
    return {
        "total_clusters": total_clusters,
        "total_players": total_players,
        "total_messages": total_messages,
        "top_cluster": top_cluster
    }

def update_group_index(group_id: str, date: str, group_name: str = None):
    """
    æ›´æ–°å¯¹åº”ç¾¤ç»„çš„ index.json æ–‡ä»¶
    
    Args:
        group_id: ç¾¤ç»„ID ("1" æˆ– "2")
        date: æ—¥æœŸå­—ç¬¦ä¸² (æ ¼å¼: "YYYY-MM-DD")
        group_name: ç¾¤ç»„åç§°ï¼ˆå¯é€‰ï¼‰
    """
    if group_name is None:
        group_name = f"åœ°çƒç¾¤{group_id}"
    
    index_path = PROJECT_ROOT / "é¢„è®¡ç®—æ–¹æ¡ˆ" / "results" / f"group{group_id}" / "index.json"
    
    # å¦‚æœ index.json ä¸å­˜åœ¨ï¼Œåˆ›å»ºæ–°çš„
    if not index_path.exists():
        index_path.parent.mkdir(parents=True, exist_ok=True)
        index_data = {
            "group": group_name,
            "group_id": group_id,
            "updated_at": datetime.now().isoformat(),
            "available_dates": [date],
            "total_days": 1
        }
    else:
        # è¯»å–ç°æœ‰çš„ index.json
        with open(index_path, 'r', encoding='utf-8') as f:
            index_data = json.load(f)
        
        # æ›´æ–°æ—¥æœŸåˆ—è¡¨ï¼ˆå¦‚æœæ—¥æœŸä¸å­˜åœ¨ï¼Œæ·»åŠ åˆ°åˆ—è¡¨å¼€å¤´ï¼‰
        available_dates = index_data.get("available_dates", [])
        if date not in available_dates:
            available_dates.insert(0, date)  # æ–°æ—¥æœŸæ·»åŠ åˆ°å¼€å¤´ï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
            index_data["available_dates"] = available_dates
            index_data["total_days"] = len(available_dates)
        
        # æ›´æ–°æ›´æ–°æ—¶é—´
        index_data["updated_at"] = datetime.now().isoformat()
    
    # ä¿å­˜æ›´æ–°åçš„ index.json
    with open(index_path, 'w', encoding='utf-8') as f:
        json.dump(index_data, f, ensure_ascii=False, indent=2)
    
    return index_path

def convert_to_result_format(clusters: List[Dict], group_id: str, date: str, group_name: str = None) -> Dict:
    """
    å°†è¯é¢˜ç°‡åˆ—è¡¨è½¬æ¢ä¸ºå®Œæ•´çš„ç»“æœæ ¼å¼
    
    Args:
        clusters: è¯é¢˜ç°‡åˆ—è¡¨
        group_id: ç¾¤ç»„ID ("1" æˆ– "2")
        date: æ—¥æœŸå­—ç¬¦ä¸² (æ ¼å¼: "YYYY-MM-DD")
        group_name: ç¾¤ç»„åç§°ï¼ˆå¯é€‰ï¼Œé»˜è®¤æ ¹æ® group_id ç”Ÿæˆï¼‰
    """
    if group_name is None:
        group_name = f"åœ°çƒç¾¤{group_id}"
    
    return {
        "group": group_name,
        "group_id": group_id,
        "date": date,
        "generated_at": datetime.now().isoformat(),
        "clusters": clusters,
        "summary": calculate_summary(clusters)
    }

def process_input_file(input_path: str, output_path: str, group_id: str, date: str = None, group_name: str = None):
    """
    å¤„ç†è¾“å…¥æ–‡ä»¶ï¼Œè½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼å¹¶ä¿å­˜
    
    Args:
        input_path: è¾“å…¥æ–‡ä»¶è·¯å¾„ï¼ˆå¯ä»¥æ˜¯æ–‡æœ¬æ–‡ä»¶æˆ– JSON æ–‡ä»¶ï¼‰
        output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        group_id: ç¾¤ç»„ID ("1" æˆ– "2")
        date: æ—¥æœŸå­—ç¬¦ä¸²ï¼ˆå¦‚æœä¸º Noneï¼Œä¼šä» clusters ä¸­æå–ï¼‰
        group_name: ç¾¤ç»„åç§°ï¼ˆå¯é€‰ï¼‰
    """
    # å¤„ç†ç›¸å¯¹è·¯å¾„ï¼šå¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°è¯•åœ¨é¢„è®¡ç®—æ–¹æ¡ˆç›®å½•ä¸‹æŸ¥æ‰¾
    input_file = Path(input_path)
    if not input_file.is_absolute():
        # ç›¸å¯¹è·¯å¾„ï¼šå…ˆå°è¯•å½“å‰ç›®å½•ï¼Œå†å°è¯•é¢„è®¡ç®—æ–¹æ¡ˆç›®å½•
        if not input_file.exists():
            alt_path = PROJECT_ROOT / "é¢„è®¡ç®—æ–¹æ¡ˆ" / input_path
            if alt_path.exists():
                input_file = alt_path
            else:
                # å°è¯•ç›´æ¥åœ¨å½“å‰å·¥ä½œç›®å½•æŸ¥æ‰¾
                cwd_path = Path.cwd() / input_path
                if cwd_path.exists():
                    input_file = cwd_path
    
    if not input_file.exists():
        print(f"âŒ è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {input_path}")
        print(f"   å°è¯•æŸ¥æ‰¾è·¯å¾„:")
        print(f"   - {Path(input_path).absolute()}")
        print(f"   - {PROJECT_ROOT / 'é¢„è®¡ç®—æ–¹æ¡ˆ' / input_path}")
        print(f"   - {Path.cwd() / input_path}")
        return False
    
    # è¯»å–è¾“å…¥æ–‡ä»¶
    print(f"ğŸ“– è¯»å–æ–‡ä»¶: {input_path}")
    with open(input_file, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # è§£æ JSON å¯¹è±¡
    print("ğŸ” è§£æ JSON å¯¹è±¡...")
    clusters = parse_multiple_json_objects(content)
    
    if not clusters:
        print("âŒ æœªæ‰¾åˆ°æœ‰æ•ˆçš„ JSON å¯¹è±¡")
        return False
    
    print(f"âœ… è§£æåˆ° {len(clusters)} ä¸ªè¯é¢˜ç°‡")
    
    # å¦‚æœæ²¡æœ‰æŒ‡å®šæ—¥æœŸï¼Œä»ç¬¬ä¸€ä¸ª cluster ä¸­æå–
    if date is None:
        first_cluster = clusters[0]
        date = first_cluster.get("æ—¥æœŸ", "")
        if not date:
            print("âŒ æ— æ³•ä»æ•°æ®ä¸­æå–æ—¥æœŸï¼Œè¯·æ‰‹åŠ¨æŒ‡å®š date å‚æ•°")
            return False
        print(f"ğŸ“… ä»æ•°æ®ä¸­æå–æ—¥æœŸ: {date}")
    
    # ç¡®ä¿æ‰€æœ‰ cluster çš„æ—¥æœŸä¸€è‡´
    for cluster in clusters:
        cluster["æ—¥æœŸ"] = date
    
    # è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
    print("ğŸ”„ è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼...")
    result = convert_to_result_format(clusters, group_id, date, group_name)
    
    # ä¿å­˜è¾“å‡ºæ–‡ä»¶
    output_file = Path(output_path)
    output_file.parent.mkdir(parents=True, exist_ok=True)
    
    print(f"ğŸ’¾ ä¿å­˜åˆ°: {output_path}")
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(result, f, ensure_ascii=False, indent=2)
    
    # æ›´æ–°å¯¹åº”ç¾¤ç»„çš„ index.json
    print(f"\nğŸ“ æ›´æ–° group{group_id} çš„ index.json...")
    index_path = update_group_index(group_id, date, group_name)
    print(f"âœ… index.json å·²æ›´æ–°: {index_path}")
    
    # æ˜¾ç¤º summary ä¿¡æ¯
    summary = result["summary"]
    print("\n" + "=" * 60)
    print("âœ… è½¬æ¢å®Œæˆï¼")
    print("=" * 60)
    print(f"\nğŸ“Š Summary ä¿¡æ¯:")
    print(f"  - total_clusters: {summary['total_clusters']}")
    print(f"  - total_players: {summary['total_players']}")
    print(f"  - total_messages: {summary['total_messages']}")
    print(f"  - top_cluster: {summary['top_cluster']}")
    print(f"\nğŸ’¾ ç”Ÿæˆçš„æ–‡ä»¶:")
    print(f"  - ç»“æœæ–‡ä»¶: {output_path}")
    print(f"  - ç´¢å¼•æ–‡ä»¶: {index_path}")
    
    return True

def main():
    """ä¸»å‡½æ•° - æ”¯æŒå‘½ä»¤è¡Œå‚æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="å°†æ¯æ—¥è¾“å‡ºæ ¼å¼è½¬æ¢ä¸ºæ ‡å‡† JSON æ ¼å¼")
    parser.add_argument("input", help="è¾“å…¥æ–‡ä»¶è·¯å¾„ï¼ˆåŒ…å«å¤šä¸ª JSON å¯¹è±¡çš„æ–‡æœ¬æ–‡ä»¶ï¼‰")
    parser.add_argument("--output", "-o", help="è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤ï¼šé¢„è®¡ç®—æ–¹æ¡ˆ/results/group{group_id}/{date}.jsonï¼‰")
    parser.add_argument("--group", "-g", required=True, choices=["1", "2"], help="ç¾¤ç»„ID (1 æˆ– 2)")
    parser.add_argument("--date", "-d", help="æ—¥æœŸ (æ ¼å¼: YYYY-MM-DDï¼Œå¦‚æœä¸æŒ‡å®šä¼šä»æ•°æ®ä¸­æå–ï¼‰")
    parser.add_argument("--name", "-n", help="ç¾¤ç»„åç§°ï¼ˆå¯é€‰ï¼Œé»˜è®¤ï¼šåœ°çƒç¾¤{group_id}ï¼‰")
    
    args = parser.parse_args()
    
    # ç¡®å®šè¾“å‡ºè·¯å¾„
    if args.output:
        output_path = args.output
    else:
        if not args.date:
            # å¦‚æœæ²¡æŒ‡å®šæ—¥æœŸï¼Œéœ€è¦ä»è¾“å…¥æ–‡ä»¶ä¸­æå–
            with open(args.input, 'r', encoding='utf-8') as f:
                content = f.read()
            clusters = parse_multiple_json_objects(content)
            if clusters:
                args.date = clusters[0].get("æ—¥æœŸ", "")
            else:
                print("âŒ æ— æ³•ç¡®å®šæ—¥æœŸï¼Œè¯·ä½¿ç”¨ --date å‚æ•°æŒ‡å®š")
                return
        
        output_path = f"é¢„è®¡ç®—æ–¹æ¡ˆ/results/group{args.group}/{args.date}.json"
    
    # å¤„ç†æ–‡ä»¶
    success = process_input_file(
        args.input,
        output_path,
        args.group,
        args.date,
        args.name
    )
    
    if success:
        print("\nğŸ’¡ ä¸‹ä¸€æ­¥ï¼šè¿è¡Œä»¥ä¸‹å‘½ä»¤æ¨é€åˆ° GitHub")
        print(f"   python é¢„è®¡ç®—æ–¹æ¡ˆ/push_results_to_github.py")
    else:
        sys.exit(1)

if __name__ == "__main__":
    # å¦‚æœç›´æ¥è¿è¡Œä¸”æ²¡æœ‰å‚æ•°ï¼Œæ˜¾ç¤ºä½¿ç”¨è¯´æ˜
    if len(sys.argv) == 1:
        print("=" * 60)
        print("æ¯æ—¥è¾“å‡ºæ ¼å¼è½¬æ¢å·¥å…·")
        print("=" * 60)
        print("\nä½¿ç”¨æ–¹æ³•ï¼š")
        print("  python convert_daily_output.py <è¾“å…¥æ–‡ä»¶> --group <1|2> [é€‰é¡¹]")
        print("\né€‰é¡¹ï¼š")
        print("  --output, -o    è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰")
        print("  --date, -d      æ—¥æœŸ YYYY-MM-DDï¼ˆå¯é€‰ï¼Œä¼šä»æ•°æ®ä¸­æå–ï¼‰")
        print("  --name, -n      ç¾¤ç»„åç§°ï¼ˆå¯é€‰ï¼‰")
        print("\nç¤ºä¾‹ï¼š")
        print('  python convert_daily_output.py daily_output.txt --group 1 --date 2026-01-01')
        print('  python convert_daily_output.py group1_input.json --group 1')
        print("\nğŸ’¡ æç¤ºï¼šå°†ä½ çš„ JSON æ•°æ®ä¿å­˜åˆ°æ–‡æœ¬æ–‡ä»¶ï¼Œç„¶åè¿è¡Œæ­¤è„šæœ¬")
    else:
        main()
